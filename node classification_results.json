[["node classification", "feature", "NDCG", "ACM", "SGC", "ACM\nUsing ACM dataset\nEpoch: 0001 loss_train: 2.1887 acc_train: 0.1226 loss_val: 2.1669 acc_val: 0.2797 time: 0.5912s\nEpoch: 0002 loss_train: 2.1630 acc_train: 0.2864 loss_val: 2.1466 acc_val: 0.3805 time: 0.0025s\nEpoch: 0003 loss_train: 2.1376 acc_train: 0.4248 loss_val: 2.1265 acc_val: 0.4339 time: 0.0022s\nEpoch: 0004 loss_train: 2.1125 acc_train: 0.4964 loss_val: 2.1067 acc_val: 0.4654 time: 0.0020s\nEpoch: 0005 loss_train: 2.0877 acc_train: 0.5461 loss_val: 2.0871 acc_val: 0.5018 time: 0.0019s\nEpoch: 0006 loss_train: 2.0632 acc_train: 0.5850 loss_val: 2.0678 acc_val: 0.5261 time: 0.0019s\nEpoch: 0007 loss_train: 2.0390 acc_train: 0.6068 loss_val: 2.0487 acc_val: 0.5437 time: 0.0019s\nEpoch: 0008 loss_train: 2.0152 acc_train: 0.6347 loss_val: 2.0300 acc_val: 0.5528 time: 0.0019s\nEpoch: 0009 loss_train: 1.9916 acc_train: 0.6578 loss_val: 2.0115 acc_val: 0.5637 time: 0.0019s\nEpoch: 0010 loss_train: 1.9684 acc_train: 0.6699 loss_val: 1.9933 acc_val: 0.5710 time: 0.0018s\nEpoch: 0011 loss_train: 1.9455 acc_train: 0.6833 loss_val: 1.9754 acc_val: 0.5728 time: 0.0019s\nEpoch: 0012 loss_train: 1.9230 acc_train: 0.6893 loss_val: 1.9577 acc_val: 0.5795 time: 0.0019s\nEpoch: 0013 loss_train: 1.9007 acc_train: 0.6954 loss_val: 1.9403 acc_val: 0.5856 time: 0.0019s\nEpoch: 0014 loss_train: 1.8788 acc_train: 0.7002 loss_val: 1.9232 acc_val: 0.5922 time: 0.0018s\nEpoch: 0015 loss_train: 1.8573 acc_train: 0.7051 loss_val: 1.9064 acc_val: 0.5953 time: 0.0019s\nEpoch: 0016 loss_train: 1.8360 acc_train: 0.7063 loss_val: 1.8899 acc_val: 0.5965 time: 0.0019s\nEpoch: 0017 loss_train: 1.8151 acc_train: 0.7075 loss_val: 1.8736 acc_val: 0.5953 time: 0.0019s\nEpoch: 0018 loss_train: 1.7946 acc_train: 0.7087 loss_val: 1.8576 acc_val: 0.5947 time: 0.0019s\nEpoch: 0019 loss_train: 1.7743 acc_train: 0.7136 loss_val: 1.8419 acc_val: 0.5971 time: 0.0019s\nEpoch: 0020 loss_train: 1.7544 acc_train: 0.7172 loss_val: 1.8265 acc_val: 0.6013 time: 0.0019s\nEpoch: 0021 loss_train: 1.7348 acc_train: 0.7172 loss_val: 1.8113 acc_val: 0.6050 time: 0.0020s\nEpoch: 0022 loss_train: 1.7156 acc_train: 0.7233 loss_val: 1.7964 acc_val: 0.6092 time: 0.0020s\nEpoch: 0023 loss_train: 1.6967 acc_train: 0.7245 loss_val: 1.7818 acc_val: 0.6110 time: 0.0020s\nEpoch: 0024 loss_train: 1.6781 acc_train: 0.7257 loss_val: 1.7674 acc_val: 0.6135 time: 0.0019s\nEpoch: 0025 loss_train: 1.6598 acc_train: 0.7257 loss_val: 1.7533 acc_val: 0.6147 time: 0.0019s\nEpoch: 0026 loss_train: 1.6418 acc_train: 0.7282 loss_val: 1.7395 acc_val: 0.6195 time: 0.0019s\nEpoch: 0027 loss_train: 1.6242 acc_train: 0.7294 loss_val: 1.7259 acc_val: 0.6214 time: 0.0020s\nEpoch: 0028 loss_train: 1.6069 acc_train: 0.7342 loss_val: 1.7126 acc_val: 0.6226 time: 0.0019s\nEpoch: 0029 loss_train: 1.5899 acc_train: 0.7379 loss_val: 1.6996 acc_val: 0.6232 time: 0.0020s\nEpoch: 0030 loss_train: 1.5733 acc_train: 0.7379 loss_val: 1.6868 acc_val: 0.6250 time: 0.0019s\nEpoch: 0031 loss_train: 1.5569 acc_train: 0.7379 loss_val: 1.6742 acc_val: 0.6262 time: 0.0020s\nEpoch: 0032 loss_train: 1.5408 acc_train: 0.7415 loss_val: 1.6619 acc_val: 0.6268 time: 0.0019s\nEpoch: 0033 loss_train: 1.5250 acc_train: 0.7415 loss_val: 1.6498 acc_val: 0.6292 time: 0.0019s\nEpoch: 0034 loss_train: 1.5096 acc_train: 0.7439 loss_val: 1.6380 acc_val: 0.6299 time: 0.0019s\nEpoch: 0035 loss_train: 1.4944 acc_train: 0.7464 loss_val: 1.6264 acc_val: 0.6299 time: 0.0019s\nEpoch: 0036 loss_train: 1.4794 acc_train: 0.7500 loss_val: 1.6150 acc_val: 0.6311 time: 0.0019s\nEpoch: 0037 loss_train: 1.4648 acc_train: 0.7512 loss_val: 1.6038 acc_val: 0.6317 time: 0.0018s\nEpoch: 0038 loss_train: 1.4504 acc_train: 0.7512 loss_val: 1.5929 acc_val: 0.6317 time: 0.0019s\nEpoch: 0039 loss_train: 1.4363 acc_train: 0.7524 loss_val: 1.5822 acc_val: 0.6335 time: 0.0018s\nEpoch: 0040 loss_train: 1.4225 acc_train: 0.7524 loss_val: 1.5717 acc_val: 0.6347 time: 0.0018s\nEpoch: 0041 loss_train: 1.4089 acc_train: 0.7561 loss_val: 1.5614 acc_val: 0.6371 time: 0.0018s\nEpoch: 0042 loss_train: 1.3955 acc_train: 0.7573 loss_val: 1.5514 acc_val: 0.6383 time: 0.0020s\nEpoch: 0043 loss_train: 1.3824 acc_train: 0.7585 loss_val: 1.5415 acc_val: 0.6390 time: 0.0019s\nEpoch: 0044 loss_train: 1.3696 acc_train: 0.7646 loss_val: 1.5318 acc_val: 0.6402 time: 0.0020s\nEpoch: 0045 loss_train: 1.3569 acc_train: 0.7633 loss_val: 1.5224 acc_val: 0.6408 time: 0.0019s\nEpoch: 0046 loss_train: 1.3445 acc_train: 0.7646 loss_val: 1.5131 acc_val: 0.6420 time: 0.0020s\nEpoch: 0047 loss_train: 1.3323 acc_train: 0.7670 loss_val: 1.5041 acc_val: 0.6420 time: 0.0019s\nEpoch: 0048 loss_train: 1.3204 acc_train: 0.7682 loss_val: 1.4952 acc_val: 0.6450 time: 0.0020s\nEpoch: 0049 loss_train: 1.3086 acc_train: 0.7682 loss_val: 1.4865 acc_val: 0.6481 time: 0.0019s\nEpoch: 0050 loss_train: 1.2971 acc_train: 0.7682 loss_val: 1.4780 acc_val: 0.6499 time: 0.0020s\nEpoch: 0051 loss_train: 1.2858 acc_train: 0.7682 loss_val: 1.4697 acc_val: 0.6529 time: 0.0019s\nEpoch: 0052 loss_train: 1.2746 acc_train: 0.7682 loss_val: 1.4615 acc_val: 0.6529 time: 0.0019s\nEpoch: 0053 loss_train: 1.2637 acc_train: 0.7694 loss_val: 1.4535 acc_val: 0.6529 time: 0.0019s\nEpoch: 0054 loss_train: 1.2529 acc_train: 0.7718 loss_val: 1.4457 acc_val: 0.6523 time: 0.0019s\nEpoch: 0055 loss_train: 1.2424 acc_train: 0.7731 loss_val: 1.4380 acc_val: 0.6541 time: 0.0018s\nEpoch: 0056 loss_train: 1.2320 acc_train: 0.7731 loss_val: 1.4305 acc_val: 0.6559 time: 0.0019s\nEpoch: 0057 loss_train: 1.2218 acc_train: 0.7743 loss_val: 1.4231 acc_val: 0.6553 time: 0.0019s\nEpoch: 0058 loss_train: 1.2117 acc_train: 0.7755 loss_val: 1.4159 acc_val: 0.6559 time: 0.0019s\nEpoch: 0059 loss_train: 1.2019 acc_train: 0.7767 loss_val: 1.4089 acc_val: 0.6578 time: 0.0019s\nEpoch: 0060 loss_train: 1.1922 acc_train: 0.7779 loss_val: 1.4019 acc_val: 0.6590 time: 0.0019s\nEpoch: 0061 loss_train: 1.1826 acc_train: 0.7779 loss_val: 1.3951 acc_val: 0.6590 time: 0.0018s\nEpoch: 0062 loss_train: 1.1733 acc_train: 0.7803 loss_val: 1.3885 acc_val: 0.6602 time: 0.0020s\nEpoch: 0063 loss_train: 1.1640 acc_train: 0.7816 loss_val: 1.3819 acc_val: 0.6596 time: 0.0019s\nEpoch: 0064 loss_train: 1.1550 acc_train: 0.7816 loss_val: 1.3755 acc_val: 0.6626 time: 0.0018s\nEpoch: 0065 loss_train: 1.1460 acc_train: 0.7852 loss_val: 1.3692 acc_val: 0.6638 time: 0.0019s\nEpoch: 0066 loss_train: 1.1373 acc_train: 0.7864 loss_val: 1.3631 acc_val: 0.6632 time: 0.0018s\nEpoch: 0067 loss_train: 1.1286 acc_train: 0.7900 loss_val: 1.3570 acc_val: 0.6644 time: 0.0019s\nEpoch: 0068 loss_train: 1.1201 acc_train: 0.7925 loss_val: 1.3511 acc_val: 0.6650 time: 0.0019s\nEpoch: 0069 loss_train: 1.1118 acc_train: 0.7937 loss_val: 1.3452 acc_val: 0.6644 time: 0.0019s\nEpoch: 0070 loss_train: 1.1035 acc_train: 0.7949 loss_val: 1.3395 acc_val: 0.6644 time: 0.0019s\nEpoch: 0071 loss_train: 1.0954 acc_train: 0.7961 loss_val: 1.3339 acc_val: 0.6663 time: 0.0020s\nEpoch: 0072 loss_train: 1.0874 acc_train: 0.7985 loss_val: 1.3284 acc_val: 0.6663 time: 0.0019s\nEpoch: 0073 loss_train: 1.0796 acc_train: 0.7998 loss_val: 1.3230 acc_val: 0.6663 time: 0.0020s\nEpoch: 0074 loss_train: 1.0718 acc_train: 0.8010 loss_val: 1.3177 acc_val: 0.6675 time: 0.0019s\nEpoch: 0075 loss_train: 1.0642 acc_train: 0.8010 loss_val: 1.3125 acc_val: 0.6675 time: 0.0019s\nEpoch: 0076 loss_train: 1.0567 acc_train: 0.8034 loss_val: 1.3073 acc_val: 0.6669 time: 0.0019s\nEpoch: 0077 loss_train: 1.0493 acc_train: 0.8034 loss_val: 1.3023 acc_val: 0.6675 time: 0.0019s\nEpoch: 0078 loss_train: 1.0420 acc_train: 0.8022 loss_val: 1.2974 acc_val: 0.6681 time: 0.0018s\nEpoch: 0079 loss_train: 1.0349 acc_train: 0.8034 loss_val: 1.2925 acc_val: 0.6675 time: 0.0019s\nEpoch: 0080 loss_train: 1.0278 acc_train: 0.8046 loss_val: 1.2878 acc_val: 0.6675 time: 0.0018s\nEpoch: 0081 loss_train: 1.0208 acc_train: 0.8046 loss_val: 1.2831 acc_val: 0.6687 time: 0.0019s\nEpoch: 0082 loss_train: 1.0140 acc_train: 0.8070 loss_val: 1.2785 acc_val: 0.6705 time: 0.0018s\nEpoch: 0083 loss_train: 1.0072 acc_train: 0.8083 loss_val: 1.2740 acc_val: 0.6699 time: 0.0018s\nEpoch: 0084 loss_train: 1.0006 acc_train: 0.8095 loss_val: 1.2696 acc_val: 0.6705 time: 0.0019s\nEpoch: 0085 loss_train: 0.9940 acc_train: 0.8095 loss_val: 1.2653 acc_val: 0.6711 time: 0.0019s\nEpoch: 0086 loss_train: 0.9875 acc_train: 0.8119 loss_val: 1.2610 acc_val: 0.6717 time: 0.0019s\nEpoch: 0087 loss_train: 0.9811 acc_train: 0.8119 loss_val: 1.2569 acc_val: 0.6723 time: 0.0019s\nEpoch: 0088 loss_train: 0.9748 acc_train: 0.8143 loss_val: 1.2527 acc_val: 0.6717 time: 0.0019s\nEpoch: 0089 loss_train: 0.9686 acc_train: 0.8155 loss_val: 1.2487 acc_val: 0.6729 time: 0.0019s\nEpoch: 0090 loss_train: 0.9625 acc_train: 0.8155 loss_val: 1.2448 acc_val: 0.6729 time: 0.0019s\nEpoch: 0091 loss_train: 0.9565 acc_train: 0.8180 loss_val: 1.2409 acc_val: 0.6742 time: 0.0019s\nEpoch: 0092 loss_train: 0.9505 acc_train: 0.8180 loss_val: 1.2370 acc_val: 0.6748 time: 0.0019s\nEpoch: 0093 loss_train: 0.9447 acc_train: 0.8192 loss_val: 1.2333 acc_val: 0.6748 time: 0.0019s\nEpoch: 0094 loss_train: 0.9389 acc_train: 0.8204 loss_val: 1.2296 acc_val: 0.6748 time: 0.0019s\nEpoch: 0095 loss_train: 0.9331 acc_train: 0.8216 loss_val: 1.2260 acc_val: 0.6748 time: 0.0019s\nEpoch: 0096 loss_train: 0.9275 acc_train: 0.8228 loss_val: 1.2224 acc_val: 0.6748 time: 0.0019s\nEpoch: 0097 loss_train: 0.9219 acc_train: 0.8228 loss_val: 1.2189 acc_val: 0.6748 time: 0.0019s\nEpoch: 0098 loss_train: 0.9165 acc_train: 0.8240 loss_val: 1.2155 acc_val: 0.6754 time: 0.0019s\nEpoch: 0099 loss_train: 0.9110 acc_train: 0.8252 loss_val: 1.2121 acc_val: 0.6760 time: 0.0018s\nEpoch: 0100 loss_train: 0.9057 acc_train: 0.8265 loss_val: 1.2088 acc_val: 0.6760 time: 0.0019s\nEpoch: 0101 loss_train: 0.9004 acc_train: 0.8265 loss_val: 1.2055 acc_val: 0.6766 time: 0.0018s\nEpoch: 0102 loss_train: 0.8952 acc_train: 0.8289 loss_val: 1.2023 acc_val: 0.6766 time: 0.0019s\nEpoch: 0103 loss_train: 0.8901 acc_train: 0.8301 loss_val: 1.1991 acc_val: 0.6766 time: 0.0018s\nEpoch: 0104 loss_train: 0.8850 acc_train: 0.8313 loss_val: 1.1960 acc_val: 0.6772 time: 0.0019s\nEpoch: 0105 loss_train: 0.8800 acc_train: 0.8313 loss_val: 1.1930 acc_val: 0.6778 time: 0.0018s\nEpoch: 0106 loss_train: 0.8750 acc_train: 0.8325 loss_val: 1.1900 acc_val: 0.6772 time: 0.0019s\nEpoch: 0107 loss_train: 0.8701 acc_train: 0.8325 loss_val: 1.1870 acc_val: 0.6784 time: 0.0018s\nEpoch: 0108 loss_train: 0.8653 acc_train: 0.8325 loss_val: 1.1841 acc_val: 0.6796 time: 0.0019s\nEpoch: 0109 loss_train: 0.8605 acc_train: 0.8337 loss_val: 1.1813 acc_val: 0.6790 time: 0.0018s\nEpoch: 0110 loss_train: 0.8558 acc_train: 0.8350 loss_val: 1.1785 acc_val: 0.6802 time: 0.0019s\nEpoch: 0111 loss_train: 0.8512 acc_train: 0.8350 loss_val: 1.1757 acc_val: 0.6802 time: 0.0020s\nEpoch: 0112 loss_train: 0.8466 acc_train: 0.8374 loss_val: 1.1730 acc_val: 0.6802 time: 0.0020s\nEpoch: 0113 loss_train: 0.8420 acc_train: 0.8374 loss_val: 1.1704 acc_val: 0.6802 time: 0.0020s\nEpoch: 0114 loss_train: 0.8376 acc_train: 0.8374 loss_val: 1.1677 acc_val: 0.6796 time: 0.0019s\nEpoch: 0115 loss_train: 0.8331 acc_train: 0.8386 loss_val: 1.1652 acc_val: 0.6802 time: 0.0020s\nEpoch: 0116 loss_train: 0.8287 acc_train: 0.8374 loss_val: 1.1626 acc_val: 0.6796 time: 0.0018s\nEpoch: 0117 loss_train: 0.8244 acc_train: 0.8398 loss_val: 1.1602 acc_val: 0.6802 time: 0.0019s\nEpoch: 0118 loss_train: 0.8201 acc_train: 0.8410 loss_val: 1.1577 acc_val: 0.6814 time: 0.0019s\nEpoch: 0119 loss_train: 0.8159 acc_train: 0.8410 loss_val: 1.1553 acc_val: 0.6820 time: 0.0019s\nEpoch: 0120 loss_train: 0.8117 acc_train: 0.8422 loss_val: 1.1529 acc_val: 0.6833 time: 0.0019s\nEpoch: 0121 loss_train: 0.8076 acc_train: 0.8422 loss_val: 1.1506 acc_val: 0.6833 time: 0.0019s\nEpoch: 0122 loss_train: 0.8035 acc_train: 0.8434 loss_val: 1.1483 acc_val: 0.6833 time: 0.0018s\nEpoch: 0123 loss_train: 0.7995 acc_train: 0.8447 loss_val: 1.1461 acc_val: 0.6833 time: 0.0019s\nEpoch: 0124 loss_train: 0.7955 acc_train: 0.8459 loss_val: 1.1439 acc_val: 0.6839 time: 0.0018s\nEpoch: 0125 loss_train: 0.7915 acc_train: 0.8459 loss_val: 1.1417 acc_val: 0.6851 time: 0.0019s\nEpoch: 0126 loss_train: 0.7876 acc_train: 0.8459 loss_val: 1.1395 acc_val: 0.6851 time: 0.0018s\nEpoch: 0127 loss_train: 0.7838 acc_train: 0.8459 loss_val: 1.1374 acc_val: 0.6863 time: 0.0019s\nEpoch: 0128 loss_train: 0.7800 acc_train: 0.8471 loss_val: 1.1354 acc_val: 0.6863 time: 0.0018s\nEpoch: 0129 loss_train: 0.7762 acc_train: 0.8471 loss_val: 1.1333 acc_val: 0.6863 time: 0.0019s\nEpoch: 0130 loss_train: 0.7725 acc_train: 0.8471 loss_val: 1.1313 acc_val: 0.6863 time: 0.0018s\nEpoch: 0131 loss_train: 0.7688 acc_train: 0.8471 loss_val: 1.1294 acc_val: 0.6857 time: 0.0020s\nEpoch: 0132 loss_train: 0.7651 acc_train: 0.8471 loss_val: 1.1274 acc_val: 0.6863 time: 0.0018s\nEpoch: 0133 loss_train: 0.7615 acc_train: 0.8471 loss_val: 1.1255 acc_val: 0.6863 time: 0.0019s\nEpoch: 0134 loss_train: 0.7579 acc_train: 0.8471 loss_val: 1.1236 acc_val: 0.6863 time: 0.0019s\nEpoch: 0135 loss_train: 0.7544 acc_train: 0.8495 loss_val: 1.1218 acc_val: 0.6875 time: 0.0018s\nEpoch: 0136 loss_train: 0.7509 acc_train: 0.8507 loss_val: 1.1200 acc_val: 0.6875 time: 0.0019s\nEpoch: 0137 loss_train: 0.7474 acc_train: 0.8519 loss_val: 1.1182 acc_val: 0.6875 time: 0.0018s\nEpoch: 0138 loss_train: 0.7440 acc_train: 0.8519 loss_val: 1.1164 acc_val: 0.6875 time: 0.0019s\nEpoch: 0139 loss_train: 0.7406 acc_train: 0.8519 loss_val: 1.1147 acc_val: 0.6869 time: 0.0018s\nEpoch: 0140 loss_train: 0.7373 acc_train: 0.8519 loss_val: 1.1130 acc_val: 0.6869 time: 0.0019s\nEpoch: 0141 loss_train: 0.7339 acc_train: 0.8519 loss_val: 1.1113 acc_val: 0.6869 time: 0.0019s\nEpoch: 0142 loss_train: 0.7307 acc_train: 0.8519 loss_val: 1.1097 acc_val: 0.6869 time: 0.0020s\nEpoch: 0143 loss_train: 0.7274 acc_train: 0.8532 loss_val: 1.1080 acc_val: 0.6869 time: 0.0019s\nEpoch: 0144 loss_train: 0.7242 acc_train: 0.8519 loss_val: 1.1064 acc_val: 0.6875 time: 0.0019s\nEpoch: 0145 loss_train: 0.7210 acc_train: 0.8519 loss_val: 1.1049 acc_val: 0.6875 time: 0.0019s\nEpoch: 0146 loss_train: 0.7178 acc_train: 0.8532 loss_val: 1.1033 acc_val: 0.6875 time: 0.0063s\nEpoch: 0147 loss_train: 0.7147 acc_train: 0.8544 loss_val: 1.1018 acc_val: 0.6869 time: 0.0023s\nEpoch: 0148 loss_train: 0.7116 acc_train: 0.8556 loss_val: 1.1003 acc_val: 0.6869 time: 0.0019s\nEpoch: 0149 loss_train: 0.7086 acc_train: 0.8556 loss_val: 1.0988 acc_val: 0.6869 time: 0.0019s\nEpoch: 0150 loss_train: 0.7055 acc_train: 0.8568 loss_val: 1.0974 acc_val: 0.6875 time: 0.0020s\nEpoch: 0151 loss_train: 0.7025 acc_train: 0.8568 loss_val: 1.0960 acc_val: 0.6869 time: 0.0019s\nEpoch: 0152 loss_train: 0.6995 acc_train: 0.8568 loss_val: 1.0946 acc_val: 0.6869 time: 0.0019s\nEpoch: 0153 loss_train: 0.6966 acc_train: 0.8580 loss_val: 1.0932 acc_val: 0.6875 time: 0.0019s\nEpoch: 0154 loss_train: 0.6937 acc_train: 0.8580 loss_val: 1.0918 acc_val: 0.6869 time: 0.0019s\nEpoch: 0155 loss_train: 0.6908 acc_train: 0.8592 loss_val: 1.0905 acc_val: 0.6869 time: 0.0019s\nEpoch: 0156 loss_train: 0.6879 acc_train: 0.8592 loss_val: 1.0892 acc_val: 0.6875 time: 0.0020s\nEpoch: 0157 loss_train: 0.6851 acc_train: 0.8592 loss_val: 1.0879 acc_val: 0.6875 time: 0.0019s\nEpoch: 0158 loss_train: 0.6823 acc_train: 0.8604 loss_val: 1.0866 acc_val: 0.6881 time: 0.0020s\nEpoch: 0159 loss_train: 0.6795 acc_train: 0.8617 loss_val: 1.0854 acc_val: 0.6881 time: 0.0019s\nEpoch: 0160 loss_train: 0.6768 acc_train: 0.8629 loss_val: 1.0842 acc_val: 0.6875 time: 0.0019s\nEpoch: 0161 loss_train: 0.6740 acc_train: 0.8629 loss_val: 1.0830 acc_val: 0.6875 time: 0.0020s\nEpoch: 0162 loss_train: 0.6713 acc_train: 0.8641 loss_val: 1.0818 acc_val: 0.6875 time: 0.0019s\nEpoch: 0163 loss_train: 0.6686 acc_train: 0.8653 loss_val: 1.0806 acc_val: 0.6875 time: 0.0019s\nEpoch: 0164 loss_train: 0.6660 acc_train: 0.8653 loss_val: 1.0794 acc_val: 0.6881 time: 0.0019s\nEpoch: 0165 loss_train: 0.6633 acc_train: 0.8653 loss_val: 1.0783 acc_val: 0.6881 time: 0.0019s\nEpoch: 0166 loss_train: 0.6607 acc_train: 0.8653 loss_val: 1.0772 acc_val: 0.6881 time: 0.0019s\nEpoch: 0167 loss_train: 0.6582 acc_train: 0.8653 loss_val: 1.0761 acc_val: 0.6881 time: 0.0018s\nEpoch: 0168 loss_train: 0.6556 acc_train: 0.8665 loss_val: 1.0750 acc_val: 0.6887 time: 0.0019s\nEpoch: 0169 loss_train: 0.6531 acc_train: 0.8665 loss_val: 1.0740 acc_val: 0.6881 time: 0.0018s\nEpoch: 0170 loss_train: 0.6505 acc_train: 0.8677 loss_val: 1.0729 acc_val: 0.6887 time: 0.0019s\nEpoch: 0171 loss_train: 0.6480 acc_train: 0.8677 loss_val: 1.0719 acc_val: 0.6887 time: 0.0019s\nEpoch: 0172 loss_train: 0.6456 acc_train: 0.8677 loss_val: 1.0709 acc_val: 0.6887 time: 0.0019s\nEpoch: 0173 loss_train: 0.6431 acc_train: 0.8677 loss_val: 1.0699 acc_val: 0.6887 time: 0.0018s\nEpoch: 0174 loss_train: 0.6407 acc_train: 0.8677 loss_val: 1.0689 acc_val: 0.6887 time: 0.0018s\nEpoch: 0175 loss_train: 0.6383 acc_train: 0.8677 loss_val: 1.0680 acc_val: 0.6887 time: 0.0019s\nEpoch: 0176 loss_train: 0.6359 acc_train: 0.8689 loss_val: 1.0670 acc_val: 0.6887 time: 0.0018s\nEpoch: 0177 loss_train: 0.6335 acc_train: 0.8701 loss_val: 1.0661 acc_val: 0.6887 time: 0.0019s\nEpoch: 0178 loss_train: 0.6312 acc_train: 0.8714 loss_val: 1.0652 acc_val: 0.6887 time: 0.0019s\nEpoch: 0179 loss_train: 0.6288 acc_train: 0.8714 loss_val: 1.0643 acc_val: 0.6893 time: 0.0019s\nEpoch: 0180 loss_train: 0.6265 acc_train: 0.8726 loss_val: 1.0634 acc_val: 0.6893 time: 0.0019s\nEpoch: 0181 loss_train: 0.6242 acc_train: 0.8738 loss_val: 1.0625 acc_val: 0.6893 time: 0.0019s\nEpoch: 0182 loss_train: 0.6220 acc_train: 0.8738 loss_val: 1.0617 acc_val: 0.6893 time: 0.0019s\nEpoch: 0183 loss_train: 0.6197 acc_train: 0.8738 loss_val: 1.0608 acc_val: 0.6893 time: 0.0019s\nEpoch: 0184 loss_train: 0.6175 acc_train: 0.8750 loss_val: 1.0600 acc_val: 0.6881 time: 0.0019s\nEpoch: 0185 loss_train: 0.6153 acc_train: 0.8750 loss_val: 1.0592 acc_val: 0.6881 time: 0.0019s\nEpoch: 0186 loss_train: 0.6131 acc_train: 0.8750 loss_val: 1.0584 acc_val: 0.6881 time: 0.0019s\nEpoch: 0187 loss_train: 0.6109 acc_train: 0.8762 loss_val: 1.0576 acc_val: 0.6881 time: 0.0019s\nEpoch: 0188 loss_train: 0.6087 acc_train: 0.8774 loss_val: 1.0568 acc_val: 0.6875 time: 0.0018s\nEpoch: 0189 loss_train: 0.6066 acc_train: 0.8774 loss_val: 1.0561 acc_val: 0.6869 time: 0.0019s\nEpoch: 0190 loss_train: 0.6045 acc_train: 0.8786 loss_val: 1.0553 acc_val: 0.6869 time: 0.0018s\nEpoch: 0191 loss_train: 0.6024 acc_train: 0.8786 loss_val: 1.0546 acc_val: 0.6875 time: 0.0019s\nEpoch: 0192 loss_train: 0.6003 acc_train: 0.8799 loss_val: 1.0539 acc_val: 0.6869 time: 0.0019s\nEpoch: 0193 loss_train: 0.5982 acc_train: 0.8799 loss_val: 1.0532 acc_val: 0.6869 time: 0.0019s\nEpoch: 0194 loss_train: 0.5961 acc_train: 0.8811 loss_val: 1.0525 acc_val: 0.6857 time: 0.0019s\nEpoch: 0195 loss_train: 0.5941 acc_train: 0.8823 loss_val: 1.0518 acc_val: 0.6863 time: 0.0019s\nEpoch: 0196 loss_train: 0.5921 acc_train: 0.8823 loss_val: 1.0511 acc_val: 0.6857 time: 0.0019s\nEpoch: 0197 loss_train: 0.5901 acc_train: 0.8823 loss_val: 1.0504 acc_val: 0.6857 time: 0.0021s\nEpoch: 0198 loss_train: 0.5881 acc_train: 0.8823 loss_val: 1.0498 acc_val: 0.6857 time: 0.0019s\nEpoch: 0199 loss_train: 0.5861 acc_train: 0.8823 loss_val: 1.0492 acc_val: 0.6857 time: 0.0020s\nEpoch: 0200 loss_train: 0.5841 acc_train: 0.8823 loss_val: 1.0485 acc_val: 0.6857 time: 0.0019s\nEpoch: 0201 loss_train: 0.5822 acc_train: 0.8823 loss_val: 1.0479 acc_val: 0.6857 time: 0.0020s\nEpoch: 0202 loss_train: 0.5802 acc_train: 0.8823 loss_val: 1.0473 acc_val: 0.6857 time: 0.0019s\nEpoch: 0203 loss_train: 0.5783 acc_train: 0.8823 loss_val: 1.0467 acc_val: 0.6857 time: 0.0020s\nEpoch: 0204 loss_train: 0.5764 acc_train: 0.8823 loss_val: 1.0461 acc_val: 0.6857 time: 0.0019s\nEpoch: 0205 loss_train: 0.5745 acc_train: 0.8823 loss_val: 1.0456 acc_val: 0.6857 time: 0.0020s\nEpoch: 0206 loss_train: 0.5726 acc_train: 0.8835 loss_val: 1.0450 acc_val: 0.6857 time: 0.0019s\nEpoch: 0207 loss_train: 0.5708 acc_train: 0.8847 loss_val: 1.0444 acc_val: 0.6857 time: 0.0019s\nEpoch: 0208 loss_train: 0.5689 acc_train: 0.8847 loss_val: 1.0439 acc_val: 0.6863 time: 0.0019s\nEpoch: 0209 loss_train: 0.5671 acc_train: 0.8847 loss_val: 1.0434 acc_val: 0.6863 time: 0.0019s\nEpoch: 0210 loss_train: 0.5653 acc_train: 0.8847 loss_val: 1.0428 acc_val: 0.6863 time: 0.0019s\nEpoch: 0211 loss_train: 0.5635 acc_train: 0.8871 loss_val: 1.0423 acc_val: 0.6857 time: 0.0018s\nEpoch: 0212 loss_train: 0.5617 acc_train: 0.8871 loss_val: 1.0418 acc_val: 0.6857 time: 0.0020s\nEpoch: 0213 loss_train: 0.5599 acc_train: 0.8871 loss_val: 1.0413 acc_val: 0.6857 time: 0.0019s\nEpoch: 0214 loss_train: 0.5581 acc_train: 0.8871 loss_val: 1.0408 acc_val: 0.6857 time: 0.0019s\nEpoch: 0215 loss_train: 0.5563 acc_train: 0.8871 loss_val: 1.0404 acc_val: 0.6851 time: 0.0018s\nEpoch: 0216 loss_train: 0.5546 acc_train: 0.8883 loss_val: 1.0399 acc_val: 0.6857 time: 0.0019s\nEpoch: 0217 loss_train: 0.5529 acc_train: 0.8883 loss_val: 1.0394 acc_val: 0.6863 time: 0.0018s\nEpoch: 0218 loss_train: 0.5511 acc_train: 0.8896 loss_val: 1.0390 acc_val: 0.6863 time: 0.0020s\nEpoch: 0219 loss_train: 0.5494 acc_train: 0.8920 loss_val: 1.0386 acc_val: 0.6863 time: 0.0019s\nEpoch: 0220 loss_train: 0.5477 acc_train: 0.8920 loss_val: 1.0381 acc_val: 0.6875 time: 0.0019s\nEpoch: 0221 loss_train: 0.5461 acc_train: 0.8920 loss_val: 1.0377 acc_val: 0.6875 time: 0.0019s\nEpoch: 0222 loss_train: 0.5444 acc_train: 0.8932 loss_val: 1.0373 acc_val: 0.6881 time: 0.0019s\nEpoch: 0223 loss_train: 0.5427 acc_train: 0.8932 loss_val: 1.0369 acc_val: 0.6875 time: 0.0020s\nEpoch: 0224 loss_train: 0.5411 acc_train: 0.8932 loss_val: 1.0365 acc_val: 0.6875 time: 0.0020s\nEpoch: 0225 loss_train: 0.5394 acc_train: 0.8932 loss_val: 1.0361 acc_val: 0.6875 time: 0.0019s\nEpoch: 0226 loss_train: 0.5378 acc_train: 0.8932 loss_val: 1.0357 acc_val: 0.6881 time: 0.0020s\nEpoch: 0227 loss_train: 0.5362 acc_train: 0.8932 loss_val: 1.0353 acc_val: 0.6893 time: 0.0019s\nEpoch: 0228 loss_train: 0.5346 acc_train: 0.8932 loss_val: 1.0350 acc_val: 0.6893 time: 0.0019s\nEpoch: 0229 loss_train: 0.5330 acc_train: 0.8932 loss_val: 1.0346 acc_val: 0.6893 time: 0.0019s\nEpoch: 0230 loss_train: 0.5314 acc_train: 0.8932 loss_val: 1.0342 acc_val: 0.6893 time: 0.0019s\nEpoch: 0231 loss_train: 0.5298 acc_train: 0.8932 loss_val: 1.0339 acc_val: 0.6899 time: 0.0019s\nEpoch: 0232 loss_train: 0.5283 acc_train: 0.8944 loss_val: 1.0336 acc_val: 0.6899 time: 0.0019s\nEpoch: 0233 loss_train: 0.5267 acc_train: 0.8944 loss_val: 1.0332 acc_val: 0.6899 time: 0.0019s\nEpoch: 0234 loss_train: 0.5252 acc_train: 0.8944 loss_val: 1.0329 acc_val: 0.6899 time: 0.0019s\nEpoch: 0235 loss_train: 0.5236 acc_train: 0.8956 loss_val: 1.0326 acc_val: 0.6893 time: 0.0019s\nEpoch: 0236 loss_train: 0.5221 acc_train: 0.8956 loss_val: 1.0323 acc_val: 0.6893 time: 0.0018s\nEpoch: 0237 loss_train: 0.5206 acc_train: 0.8968 loss_val: 1.0320 acc_val: 0.6893 time: 0.0019s\nEpoch: 0238 loss_train: 0.5191 acc_train: 0.8968 loss_val: 1.0317 acc_val: 0.6893 time: 0.0018s\nEpoch: 0239 loss_train: 0.5176 acc_train: 0.8968 loss_val: 1.0314 acc_val: 0.6887 time: 0.0020s\nEpoch: 0240 loss_train: 0.5161 acc_train: 0.8981 loss_val: 1.0311 acc_val: 0.6887 time: 0.0019s\nEpoch: 0241 loss_train: 0.5147 acc_train: 0.8981 loss_val: 1.0308 acc_val: 0.6887 time: 0.0019s\nEpoch: 0242 loss_train: 0.5132 acc_train: 0.8981 loss_val: 1.0306 acc_val: 0.6887 time: 0.0019s\nEpoch: 0243 loss_train: 0.5117 acc_train: 0.8981 loss_val: 1.0303 acc_val: 0.6887 time: 0.0019s\nEpoch: 0244 loss_train: 0.5103 acc_train: 0.8981 loss_val: 1.0300 acc_val: 0.6887 time: 0.0019s\nEpoch: 0245 loss_train: 0.5089 acc_train: 0.8993 loss_val: 1.0298 acc_val: 0.6887 time: 0.0020s\nEpoch: 0246 loss_train: 0.5074 acc_train: 0.8993 loss_val: 1.0295 acc_val: 0.6881 time: 0.0019s\nEpoch: 0247 loss_train: 0.5060 acc_train: 0.9005 loss_val: 1.0293 acc_val: 0.6881 time: 0.0020s\nEpoch: 0248 loss_train: 0.5046 acc_train: 0.9005 loss_val: 1.0291 acc_val: 0.6887 time: 0.0019s\nEpoch: 0249 loss_train: 0.5032 acc_train: 0.8993 loss_val: 1.0288 acc_val: 0.6887 time: 0.0020s\nEpoch: 0250 loss_train: 0.5018 acc_train: 0.8993 loss_val: 1.0286 acc_val: 0.6881 time: 0.0019s\nEpoch: 0251 loss_train: 0.5004 acc_train: 0.8993 loss_val: 1.0284 acc_val: 0.6881 time: 0.0019s\nEpoch: 0252 loss_train: 0.4991 acc_train: 0.8993 loss_val: 1.0282 acc_val: 0.6887 time: 0.0019s\nEpoch: 0253 loss_train: 0.4977 acc_train: 0.8993 loss_val: 1.0280 acc_val: 0.6893 time: 0.0019s\nEpoch: 0254 loss_train: 0.4963 acc_train: 0.8993 loss_val: 1.0278 acc_val: 0.6893 time: 0.0019s\nEpoch: 0255 loss_train: 0.4950 acc_train: 0.8993 loss_val: 1.0276 acc_val: 0.6893 time: 0.0019s\nEpoch: 0256 loss_train: 0.4936 acc_train: 0.8993 loss_val: 1.0274 acc_val: 0.6893 time: 0.0019s\nEpoch: 0257 loss_train: 0.4923 acc_train: 0.8993 loss_val: 1.0272 acc_val: 0.6893 time: 0.0019s\nEpoch: 0258 loss_train: 0.4910 acc_train: 0.8993 loss_val: 1.0271 acc_val: 0.6905 time: 0.0018s\nEpoch: 0259 loss_train: 0.4897 acc_train: 0.8993 loss_val: 1.0269 acc_val: 0.6905 time: 0.0019s\nEpoch: 0260 loss_train: 0.4884 acc_train: 0.8993 loss_val: 1.0267 acc_val: 0.6905 time: 0.0018s\nEpoch: 0261 loss_train: 0.4871 acc_train: 0.8993 loss_val: 1.0266 acc_val: 0.6905 time: 0.0019s\nEpoch: 0262 loss_train: 0.4858 acc_train: 0.8993 loss_val: 1.0264 acc_val: 0.6905 time: 0.0019s\nEpoch: 0263 loss_train: 0.4845 acc_train: 0.9005 loss_val: 1.0263 acc_val: 0.6905 time: 0.0018s\nEpoch: 0264 loss_train: 0.4832 acc_train: 0.9017 loss_val: 1.0261 acc_val: 0.6905 time: 0.0020s\nEpoch: 0265 loss_train: 0.4819 acc_train: 0.9017 loss_val: 1.0260 acc_val: 0.6899 time: 0.0020s\nEpoch: 0266 loss_train: 0.4807 acc_train: 0.9029 loss_val: 1.0258 acc_val: 0.6893 time: 0.0019s\nEpoch: 0267 loss_train: 0.4794 acc_train: 0.9041 loss_val: 1.0257 acc_val: 0.6899 time: 0.0018s\nEpoch: 0268 loss_train: 0.4782 acc_train: 0.9041 loss_val: 1.0256 acc_val: 0.6905 time: 0.0019s\nEpoch: 0269 loss_train: 0.4769 acc_train: 0.9041 loss_val: 1.0255 acc_val: 0.6911 time: 0.0018s\nEpoch: 0270 loss_train: 0.4757 acc_train: 0.9053 loss_val: 1.0253 acc_val: 0.6905 time: 0.0019s\nEpoch: 0271 loss_train: 0.4745 acc_train: 0.9053 loss_val: 1.0252 acc_val: 0.6905 time: 0.0018s\nEpoch: 0272 loss_train: 0.4732 acc_train: 0.9053 loss_val: 1.0251 acc_val: 0.6917 time: 0.0019s\nEpoch: 0273 loss_train: 0.4720 acc_train: 0.9066 loss_val: 1.0250 acc_val: 0.6917 time: 0.0018s\nEpoch: 0274 loss_train: 0.4708 acc_train: 0.9066 loss_val: 1.0249 acc_val: 0.6917 time: 0.0019s\nEpoch: 0275 loss_train: 0.4696 acc_train: 0.9078 loss_val: 1.0248 acc_val: 0.6924 time: 0.0018s\nEpoch: 0276 loss_train: 0.4684 acc_train: 0.9078 loss_val: 1.0247 acc_val: 0.6924 time: 0.0020s\nEpoch: 0277 loss_train: 0.4672 acc_train: 0.9078 loss_val: 1.0247 acc_val: 0.6917 time: 0.0019s\nEpoch: 0278 loss_train: 0.4661 acc_train: 0.9078 loss_val: 1.0246 acc_val: 0.6917 time: 0.0019s\nEpoch: 0279 loss_train: 0.4649 acc_train: 0.9078 loss_val: 1.0245 acc_val: 0.6917 time: 0.0019s\nEpoch: 0280 loss_train: 0.4637 acc_train: 0.9078 loss_val: 1.0244 acc_val: 0.6917 time: 0.0020s\nEpoch: 0281 loss_train: 0.4626 acc_train: 0.9078 loss_val: 1.0244 acc_val: 0.6924 time: 0.0019s\nEpoch: 0282 loss_train: 0.4614 acc_train: 0.9078 loss_val: 1.0243 acc_val: 0.6924 time: 0.0019s\nEpoch: 0283 loss_train: 0.4603 acc_train: 0.9090 loss_val: 1.0242 acc_val: 0.6924 time: 0.0019s\nEpoch: 0284 loss_train: 0.4591 acc_train: 0.9090 loss_val: 1.0242 acc_val: 0.6924 time: 0.0019s\nEpoch: 0285 loss_train: 0.4580 acc_train: 0.9102 loss_val: 1.0241 acc_val: 0.6924 time: 0.0020s\nEpoch: 0286 loss_train: 0.4569 acc_train: 0.9102 loss_val: 1.0241 acc_val: 0.6917 time: 0.0019s\nEpoch: 0287 loss_train: 0.4557 acc_train: 0.9114 loss_val: 1.0240 acc_val: 0.6917 time: 0.0018s\nEpoch: 0288 loss_train: 0.4546 acc_train: 0.9114 loss_val: 1.0240 acc_val: 0.6917 time: 0.0019s\nEpoch: 0289 loss_train: 0.4535 acc_train: 0.9126 loss_val: 1.0239 acc_val: 0.6911 time: 0.0019s\nEpoch: 0290 loss_train: 0.4524 acc_train: 0.9126 loss_val: 1.0239 acc_val: 0.6911 time: 0.0019s\nEpoch: 0291 loss_train: 0.4513 acc_train: 0.9126 loss_val: 1.0239 acc_val: 0.6911 time: 0.0019s\nEpoch: 0292 loss_train: 0.4502 acc_train: 0.9126 loss_val: 1.0239 acc_val: 0.6911 time: 0.0018s\nEpoch: 0293 loss_train: 0.4491 acc_train: 0.9126 loss_val: 1.0238 acc_val: 0.6911 time: 0.0019s\nEpoch: 0294 loss_train: 0.4480 acc_train: 0.9138 loss_val: 1.0238 acc_val: 0.6911 time: 0.0018s\nEpoch: 0295 loss_train: 0.4470 acc_train: 0.9138 loss_val: 1.0238 acc_val: 0.6911 time: 0.0019s\nEpoch: 0296 loss_train: 0.4459 acc_train: 0.9138 loss_val: 1.0238 acc_val: 0.6911 time: 0.0018s\nEpoch: 0297 loss_train: 0.4448 acc_train: 0.9138 loss_val: 1.0238 acc_val: 0.6911 time: 0.0020s\nEpoch: 0298 loss_train: 0.4438 acc_train: 0.9138 loss_val: 1.0238 acc_val: 0.6905 time: 0.0019s\nEpoch: 0299 loss_train: 0.4427 acc_train: 0.9150 loss_val: 1.0238 acc_val: 0.6911 time: 0.0020s\nEpoch: 0300 loss_train: 0.4417 acc_train: 0.9150 loss_val: 1.0238 acc_val: 0.6899 time: 0.0019s\nEpoch: 0001 loss_train: 0.4406 acc_train: 0.9150 loss_val: 1.0238 acc_val: 0.6899 time: 0.0017s\nRanking optimizing... \nNow Average NDCG@k =  0.5588052272796631\nEpoch: 0002 loss_train: 0.4396 acc_train: 0.9150 loss_val: 1.0244 acc_val: 0.6887 time: 0.0031s\nRanking optimizing... \nNow Average NDCG@k =  0.5598166584968567\nEpoch: 0003 loss_train: 0.4388 acc_train: 0.9138 loss_val: 1.0255 acc_val: 0.6893 time: 0.0026s\nRanking optimizing... \nNow Average NDCG@k =  0.5614158511161804\nEpoch: 0004 loss_train: 0.4382 acc_train: 0.9126 loss_val: 1.0270 acc_val: 0.6899 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.5635141730308533\nEpoch: 0005 loss_train: 0.4378 acc_train: 0.9114 loss_val: 1.0288 acc_val: 0.6899 time: 0.0031s\nRanking optimizing... \nNow Average NDCG@k =  0.5660178065299988\nEpoch: 0006 loss_train: 0.4378 acc_train: 0.9090 loss_val: 1.0309 acc_val: 0.6899 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.5684875845909119\nEpoch: 0007 loss_train: 0.4381 acc_train: 0.9114 loss_val: 1.0334 acc_val: 0.6881 time: 0.0032s\nRanking optimizing... \nNow Average NDCG@k =  0.571519672870636\nEpoch: 0008 loss_train: 0.4388 acc_train: 0.9126 loss_val: 1.0363 acc_val: 0.6905 time: 0.0040s\nRanking optimizing... \nNow Average NDCG@k =  0.5744092464447021\nEpoch: 0009 loss_train: 0.4399 acc_train: 0.9102 loss_val: 1.0394 acc_val: 0.6893 time: 0.0051s\nRanking optimizing... \nNow Average NDCG@k =  0.5774250626564026\nEpoch: 0010 loss_train: 0.4414 acc_train: 0.9102 loss_val: 1.0430 acc_val: 0.6881 time: 0.0036s\nRanking optimizing... \nNow Average NDCG@k =  0.5803457498550415\nEpoch: 0011 loss_train: 0.4433 acc_train: 0.9090 loss_val: 1.0469 acc_val: 0.6887 time: 0.0038s\nRanking optimizing... \nNow Average NDCG@k =  0.5835087895393372\nEpoch: 0012 loss_train: 0.4456 acc_train: 0.9053 loss_val: 1.0512 acc_val: 0.6863 time: 0.0036s\nRanking optimizing... \nNow Average NDCG@k =  0.5865392684936523\nEpoch: 0013 loss_train: 0.4482 acc_train: 0.9053 loss_val: 1.0558 acc_val: 0.6839 time: 0.0030s\nRanking optimizing... \nNow Average NDCG@k =  0.5894070863723755\nEpoch: 0014 loss_train: 0.4513 acc_train: 0.9066 loss_val: 1.0607 acc_val: 0.6808 time: 0.0037s\nRanking optimizing... \nNow Average NDCG@k =  0.592185378074646\nEpoch: 0015 loss_train: 0.4547 acc_train: 0.9078 loss_val: 1.0661 acc_val: 0.6802 time: 0.0031s\nRanking optimizing... \nNow Average NDCG@k =  0.5953867435455322\nTest set results: loss= 1.0867 accuracy= 0.6738\n"], ["node classification", "feature", "NDCG", "ACM", "GCN", "ACM\nUsing ACM dataset\nEpoch: 0001 loss_train: 2.1606 acc_train: 0.1468 loss_val: 2.1570 acc_val: 0.1408 time: 3.4989s\nRanking optimizing... \nNow Average NDCG@k =  0.27596989274024963\nEpoch: 0002 loss_train: 2.1358 acc_train: 0.1893 loss_val: 2.1359 acc_val: 0.1711 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.2777729034423828\nEpoch: 0003 loss_train: 2.1130 acc_train: 0.2306 loss_val: 2.1153 acc_val: 0.2130 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.2821357548236847\nEpoch: 0004 loss_train: 2.0904 acc_train: 0.2488 loss_val: 2.0949 acc_val: 0.2342 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.28283175826072693\nEpoch: 0005 loss_train: 2.0689 acc_train: 0.2646 loss_val: 2.0744 acc_val: 0.2585 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.2877839505672455\nEpoch: 0006 loss_train: 2.0419 acc_train: 0.3131 loss_val: 2.0536 acc_val: 0.2822 time: 0.0064s\nRanking optimizing... \nNow Average NDCG@k =  0.2902393639087677\nEpoch: 0007 loss_train: 2.0205 acc_train: 0.3228 loss_val: 2.0323 acc_val: 0.3101 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.2896975576877594\nEpoch: 0008 loss_train: 1.9915 acc_train: 0.3774 loss_val: 2.0104 acc_val: 0.3513 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.29462623596191406\nEpoch: 0009 loss_train: 1.9670 acc_train: 0.4078 loss_val: 1.9877 acc_val: 0.3829 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.29520371556282043\nEpoch: 0010 loss_train: 1.9410 acc_train: 0.4575 loss_val: 1.9643 acc_val: 0.4211 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.2938480079174042\nEpoch: 0011 loss_train: 1.9142 acc_train: 0.4939 loss_val: 1.9400 acc_val: 0.4587 time: 0.0093s\nRanking optimizing... \nNow Average NDCG@k =  0.29682135581970215\nEpoch: 0012 loss_train: 1.8814 acc_train: 0.5364 loss_val: 1.9150 acc_val: 0.4909 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.2990795373916626\nEpoch: 0013 loss_train: 1.8585 acc_train: 0.5570 loss_val: 1.8891 acc_val: 0.5212 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.2987264096736908\nEpoch: 0014 loss_train: 1.8247 acc_train: 0.5631 loss_val: 1.8625 acc_val: 0.5413 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.2993418574333191\nEpoch: 0015 loss_train: 1.7913 acc_train: 0.5789 loss_val: 1.8350 acc_val: 0.5564 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.3001362979412079\nEpoch: 0016 loss_train: 1.7562 acc_train: 0.5959 loss_val: 1.8068 acc_val: 0.5728 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.3028438687324524\nEpoch: 0017 loss_train: 1.7224 acc_train: 0.6129 loss_val: 1.7778 acc_val: 0.5850 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.30019310116767883\nEpoch: 0018 loss_train: 1.6918 acc_train: 0.6335 loss_val: 1.7482 acc_val: 0.5977 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.3009694218635559\nEpoch: 0019 loss_train: 1.6560 acc_train: 0.6335 loss_val: 1.7179 acc_val: 0.6068 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.3019193410873413\nEpoch: 0020 loss_train: 1.6168 acc_train: 0.6541 loss_val: 1.6870 acc_val: 0.6117 time: 0.0107s\nRanking optimizing... \nNow Average NDCG@k =  0.30120059847831726\nEpoch: 0021 loss_train: 1.5782 acc_train: 0.6541 loss_val: 1.6555 acc_val: 0.6165 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.30217498540878296\nEpoch: 0022 loss_train: 1.5413 acc_train: 0.6711 loss_val: 1.6236 acc_val: 0.6238 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.30170178413391113\nEpoch: 0023 loss_train: 1.5082 acc_train: 0.6772 loss_val: 1.5913 acc_val: 0.6317 time: 0.0115s\nRanking optimizing... \nNow Average NDCG@k =  0.3025188744068146\nEpoch: 0024 loss_train: 1.4778 acc_train: 0.6869 loss_val: 1.5587 acc_val: 0.6390 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.30373406410217285\nEpoch: 0025 loss_train: 1.4287 acc_train: 0.6833 loss_val: 1.5260 acc_val: 0.6517 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.303396999835968\nEpoch: 0026 loss_train: 1.3821 acc_train: 0.7075 loss_val: 1.4931 acc_val: 0.6566 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.30212923884391785\nEpoch: 0027 loss_train: 1.3565 acc_train: 0.7197 loss_val: 1.4603 acc_val: 0.6584 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.3039093017578125\nEpoch: 0028 loss_train: 1.3147 acc_train: 0.7136 loss_val: 1.4277 acc_val: 0.6614 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.3030618727207184\nEpoch: 0029 loss_train: 1.2799 acc_train: 0.7257 loss_val: 1.3954 acc_val: 0.6675 time: 0.0173s\nRanking optimizing... \nNow Average NDCG@k =  0.30089589953422546\nEpoch: 0030 loss_train: 1.2359 acc_train: 0.7294 loss_val: 1.3635 acc_val: 0.6735 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.3019338846206665\nEpoch: 0031 loss_train: 1.2014 acc_train: 0.7245 loss_val: 1.3323 acc_val: 0.6760 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.30216163396835327\nEpoch: 0032 loss_train: 1.1721 acc_train: 0.7403 loss_val: 1.3017 acc_val: 0.6820 time: 0.0108s\nRanking optimizing... \nNow Average NDCG@k =  0.304759681224823\nEpoch: 0033 loss_train: 1.1448 acc_train: 0.7415 loss_val: 1.2721 acc_val: 0.6814 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.30235055088996887\nEpoch: 0034 loss_train: 1.1107 acc_train: 0.7464 loss_val: 1.2434 acc_val: 0.6808 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.3006313145160675\nEpoch: 0035 loss_train: 1.0622 acc_train: 0.7682 loss_val: 1.2159 acc_val: 0.6839 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.30314671993255615\nEpoch: 0036 loss_train: 1.0398 acc_train: 0.7536 loss_val: 1.1896 acc_val: 0.6863 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.3017647862434387\nEpoch: 0037 loss_train: 1.0106 acc_train: 0.7536 loss_val: 1.1645 acc_val: 0.6881 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.3032630681991577\nEpoch: 0038 loss_train: 0.9809 acc_train: 0.7718 loss_val: 1.1408 acc_val: 0.6905 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.3009212911128998\nEpoch: 0039 loss_train: 0.9562 acc_train: 0.7718 loss_val: 1.1183 acc_val: 0.6905 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.30256879329681396\nEpoch: 0040 loss_train: 0.9098 acc_train: 0.7718 loss_val: 1.0972 acc_val: 0.6930 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.3007429838180542\nEpoch: 0041 loss_train: 0.9021 acc_train: 0.7597 loss_val: 1.0774 acc_val: 0.6948 time: 0.0067s\nRanking optimizing... \nNow Average NDCG@k =  0.2999626398086548\nEpoch: 0042 loss_train: 0.8852 acc_train: 0.7706 loss_val: 1.0590 acc_val: 0.6954 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.2999413013458252\nEpoch: 0043 loss_train: 0.8510 acc_train: 0.7670 loss_val: 1.0419 acc_val: 0.6972 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.30130377411842346\nEpoch: 0044 loss_train: 0.8348 acc_train: 0.7816 loss_val: 1.0260 acc_val: 0.6972 time: 0.0093s\nRanking optimizing... \nNow Average NDCG@k =  0.30242323875427246\nEpoch: 0045 loss_train: 0.8114 acc_train: 0.7852 loss_val: 1.0114 acc_val: 0.6972 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.30134308338165283\nEpoch: 0046 loss_train: 0.7970 acc_train: 0.7876 loss_val: 0.9979 acc_val: 0.6966 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.3018266558647156\nEpoch: 0047 loss_train: 0.7840 acc_train: 0.7779 loss_val: 0.9856 acc_val: 0.6984 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.3008258640766144\nEpoch: 0048 loss_train: 0.7542 acc_train: 0.7828 loss_val: 0.9744 acc_val: 0.7021 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.3018726408481598\nEpoch: 0049 loss_train: 0.7428 acc_train: 0.7816 loss_val: 0.9643 acc_val: 0.7039 time: 0.0064s\nRanking optimizing... \nNow Average NDCG@k =  0.2998111844062805\nEpoch: 0050 loss_train: 0.7236 acc_train: 0.7900 loss_val: 0.9552 acc_val: 0.7051 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.3009020984172821\nEpoch: 0051 loss_train: 0.6957 acc_train: 0.8143 loss_val: 0.9469 acc_val: 0.7051 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.30069470405578613\nEpoch: 0052 loss_train: 0.7012 acc_train: 0.7937 loss_val: 0.9393 acc_val: 0.7057 time: 0.0059s\nRanking optimizing... \nNow Average NDCG@k =  0.2999589741230011\nEpoch: 0053 loss_train: 0.6860 acc_train: 0.8010 loss_val: 0.9326 acc_val: 0.7051 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.2997123599052429\nEpoch: 0054 loss_train: 0.6671 acc_train: 0.8022 loss_val: 0.9266 acc_val: 0.7039 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.29981228709220886\nEpoch: 0055 loss_train: 0.6584 acc_train: 0.8034 loss_val: 0.9211 acc_val: 0.7057 time: 0.0108s\nRanking optimizing... \nNow Average NDCG@k =  0.3005596101284027\nEpoch: 0056 loss_train: 0.6268 acc_train: 0.8107 loss_val: 0.9162 acc_val: 0.7045 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.3022750914096832\nEpoch: 0057 loss_train: 0.6362 acc_train: 0.8131 loss_val: 0.9117 acc_val: 0.7069 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.3016366958618164\nEpoch: 0058 loss_train: 0.6211 acc_train: 0.8143 loss_val: 0.9077 acc_val: 0.7093 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.3019249439239502\nEpoch: 0059 loss_train: 0.5967 acc_train: 0.8192 loss_val: 0.9040 acc_val: 0.7081 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.30119001865386963\nEpoch: 0060 loss_train: 0.5980 acc_train: 0.8107 loss_val: 0.9007 acc_val: 0.7093 time: 0.0093s\nRanking optimizing... \nNow Average NDCG@k =  0.30097007751464844\nEpoch: 0061 loss_train: 0.5993 acc_train: 0.8119 loss_val: 0.8978 acc_val: 0.7118 time: 0.0059s\nRanking optimizing... \nNow Average NDCG@k =  0.30185797810554504\nEpoch: 0062 loss_train: 0.5886 acc_train: 0.8265 loss_val: 0.8952 acc_val: 0.7093 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.3012534976005554\nEpoch: 0063 loss_train: 0.5750 acc_train: 0.8216 loss_val: 0.8929 acc_val: 0.7093 time: 0.0116s\nRanking optimizing... \nNow Average NDCG@k =  0.3012818694114685\nEpoch: 0064 loss_train: 0.5588 acc_train: 0.8301 loss_val: 0.8909 acc_val: 0.7093 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.3023551106452942\nEpoch: 0065 loss_train: 0.5627 acc_train: 0.8398 loss_val: 0.8893 acc_val: 0.7100 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.3024666905403137\nEpoch: 0066 loss_train: 0.5244 acc_train: 0.8350 loss_val: 0.8879 acc_val: 0.7081 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.3008396029472351\nEpoch: 0067 loss_train: 0.5308 acc_train: 0.8204 loss_val: 0.8868 acc_val: 0.7081 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.3021439015865326\nEpoch: 0068 loss_train: 0.5462 acc_train: 0.8216 loss_val: 0.8859 acc_val: 0.7075 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.3028804063796997\nEpoch: 0069 loss_train: 0.5235 acc_train: 0.8337 loss_val: 0.8853 acc_val: 0.7069 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.30259332060813904\nEpoch: 0070 loss_train: 0.5085 acc_train: 0.8337 loss_val: 0.8848 acc_val: 0.7063 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.3029285669326782\nEpoch: 0071 loss_train: 0.4994 acc_train: 0.8410 loss_val: 0.8845 acc_val: 0.7045 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.30116304755210876\nEpoch: 0072 loss_train: 0.5065 acc_train: 0.8422 loss_val: 0.8843 acc_val: 0.7063 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.30305853486061096\nEpoch: 0073 loss_train: 0.4951 acc_train: 0.8544 loss_val: 0.8842 acc_val: 0.7069 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.30391913652420044\nEpoch: 0074 loss_train: 0.4788 acc_train: 0.8568 loss_val: 0.8843 acc_val: 0.7081 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.3025275766849518\nEpoch: 0075 loss_train: 0.4783 acc_train: 0.8580 loss_val: 0.8846 acc_val: 0.7081 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.3026760518550873\nEpoch: 0076 loss_train: 0.4778 acc_train: 0.8519 loss_val: 0.8850 acc_val: 0.7087 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.30275601148605347\nEpoch: 0077 loss_train: 0.4620 acc_train: 0.8507 loss_val: 0.8853 acc_val: 0.7081 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.30393925309181213\nEpoch: 0078 loss_train: 0.4560 acc_train: 0.8556 loss_val: 0.8857 acc_val: 0.7087 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.3038501739501953\nEpoch: 0079 loss_train: 0.4559 acc_train: 0.8532 loss_val: 0.8865 acc_val: 0.7100 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.3028337061405182\nEpoch: 0080 loss_train: 0.4486 acc_train: 0.8617 loss_val: 0.8876 acc_val: 0.7100 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.30223289132118225\nEpoch: 0081 loss_train: 0.4276 acc_train: 0.8629 loss_val: 0.8889 acc_val: 0.7112 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.30312028527259827\nEpoch: 0082 loss_train: 0.4390 acc_train: 0.8568 loss_val: 0.8904 acc_val: 0.7118 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.3030957579612732\nEpoch: 0083 loss_train: 0.4319 acc_train: 0.8641 loss_val: 0.8920 acc_val: 0.7112 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.3042548596858978\nEpoch: 0084 loss_train: 0.4182 acc_train: 0.8665 loss_val: 0.8936 acc_val: 0.7106 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.3041881322860718\nEpoch: 0085 loss_train: 0.4201 acc_train: 0.8665 loss_val: 0.8955 acc_val: 0.7106 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.3051578104496002\nEpoch: 0086 loss_train: 0.4069 acc_train: 0.8738 loss_val: 0.8974 acc_val: 0.7106 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.30360081791877747\nEpoch: 0087 loss_train: 0.4247 acc_train: 0.8641 loss_val: 0.8994 acc_val: 0.7100 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.3036249876022339\nEpoch: 0088 loss_train: 0.4109 acc_train: 0.8714 loss_val: 0.9014 acc_val: 0.7075 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.3051770031452179\nEpoch: 0089 loss_train: 0.3968 acc_train: 0.8920 loss_val: 0.9034 acc_val: 0.7063 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.3045375645160675\nEpoch: 0090 loss_train: 0.4089 acc_train: 0.8629 loss_val: 0.9057 acc_val: 0.7063 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.3044978082180023\nEpoch: 0091 loss_train: 0.3908 acc_train: 0.8774 loss_val: 0.9080 acc_val: 0.7051 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.30459854006767273\nEpoch: 0092 loss_train: 0.3898 acc_train: 0.8835 loss_val: 0.9106 acc_val: 0.7075 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.3044900596141815\nEpoch: 0093 loss_train: 0.3813 acc_train: 0.8799 loss_val: 0.9132 acc_val: 0.7075 time: 0.0093s\nRanking optimizing... \nNow Average NDCG@k =  0.3058284521102905\nEpoch: 0094 loss_train: 0.3735 acc_train: 0.8714 loss_val: 0.9158 acc_val: 0.7069 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.3050044775009155\nEpoch: 0095 loss_train: 0.3698 acc_train: 0.8871 loss_val: 0.9184 acc_val: 0.7069 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.303852379322052\nEpoch: 0096 loss_train: 0.3630 acc_train: 0.8871 loss_val: 0.9207 acc_val: 0.7081 time: 0.0128s\nRanking optimizing... \nNow Average NDCG@k =  0.30621325969696045\nEpoch: 0097 loss_train: 0.3559 acc_train: 0.9029 loss_val: 0.9230 acc_val: 0.7069 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.3053447902202606\nEpoch: 0098 loss_train: 0.3572 acc_train: 0.8920 loss_val: 0.9252 acc_val: 0.7069 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.30748724937438965\nEpoch: 0099 loss_train: 0.3551 acc_train: 0.8786 loss_val: 0.9272 acc_val: 0.7069 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.30475181341171265\nEpoch: 0100 loss_train: 0.3447 acc_train: 0.8896 loss_val: 0.9294 acc_val: 0.7069 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.30489659309387207\nEpoch: 0101 loss_train: 0.3358 acc_train: 0.8908 loss_val: 0.9317 acc_val: 0.7063 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.3062313199043274\nEpoch: 0102 loss_train: 0.3438 acc_train: 0.8920 loss_val: 0.9339 acc_val: 0.7081 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.30461880564689636\nEpoch: 0103 loss_train: 0.3454 acc_train: 0.8896 loss_val: 0.9361 acc_val: 0.7081 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.30578604340553284\nEpoch: 0104 loss_train: 0.3270 acc_train: 0.9066 loss_val: 0.9383 acc_val: 0.7069 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.30607908964157104\nEpoch: 0105 loss_train: 0.3289 acc_train: 0.8981 loss_val: 0.9407 acc_val: 0.7069 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.3050581216812134\nEpoch: 0106 loss_train: 0.3155 acc_train: 0.9005 loss_val: 0.9432 acc_val: 0.7081 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.30571410059928894\nEpoch: 0107 loss_train: 0.3170 acc_train: 0.9114 loss_val: 0.9458 acc_val: 0.7051 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.3063499331474304\nEpoch: 0108 loss_train: 0.3286 acc_train: 0.8956 loss_val: 0.9486 acc_val: 0.7063 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.30495813488960266\nEpoch: 0109 loss_train: 0.3191 acc_train: 0.8932 loss_val: 0.9516 acc_val: 0.7039 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.30695176124572754\nEpoch: 0110 loss_train: 0.3187 acc_train: 0.9066 loss_val: 0.9545 acc_val: 0.7015 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.3059956431388855\nEpoch: 0111 loss_train: 0.3138 acc_train: 0.9090 loss_val: 0.9577 acc_val: 0.6996 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.3052181005477905\nEpoch: 0112 loss_train: 0.3094 acc_train: 0.9017 loss_val: 0.9602 acc_val: 0.7002 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.30486270785331726\nEpoch: 0113 loss_train: 0.3078 acc_train: 0.9114 loss_val: 0.9626 acc_val: 0.7008 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.30673325061798096\nEpoch: 0114 loss_train: 0.3244 acc_train: 0.8968 loss_val: 0.9646 acc_val: 0.7002 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.30715882778167725\nEpoch: 0115 loss_train: 0.2977 acc_train: 0.9078 loss_val: 0.9665 acc_val: 0.7015 time: 0.0108s\nRanking optimizing... \nNow Average NDCG@k =  0.3066120147705078\nEpoch: 0116 loss_train: 0.2960 acc_train: 0.9078 loss_val: 0.9687 acc_val: 0.7033 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.30739036202430725\nEpoch: 0117 loss_train: 0.2836 acc_train: 0.9163 loss_val: 0.9714 acc_val: 0.7033 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.30613696575164795\nEpoch: 0118 loss_train: 0.2896 acc_train: 0.9138 loss_val: 0.9742 acc_val: 0.7039 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.30648306012153625\nEpoch: 0119 loss_train: 0.2946 acc_train: 0.9053 loss_val: 0.9775 acc_val: 0.7021 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.3078213930130005\nEpoch: 0120 loss_train: 0.2795 acc_train: 0.9223 loss_val: 0.9808 acc_val: 0.7021 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.3055282235145569\nEpoch: 0121 loss_train: 0.2733 acc_train: 0.9150 loss_val: 0.9840 acc_val: 0.7008 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.3065611720085144\nEpoch: 0122 loss_train: 0.2901 acc_train: 0.9138 loss_val: 0.9875 acc_val: 0.6996 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.30660536885261536\nEpoch: 0123 loss_train: 0.2679 acc_train: 0.9223 loss_val: 0.9910 acc_val: 0.7008 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.3051609396934509\nEpoch: 0124 loss_train: 0.2569 acc_train: 0.9320 loss_val: 0.9944 acc_val: 0.7015 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.306325763463974\nEpoch: 0125 loss_train: 0.2723 acc_train: 0.9138 loss_val: 0.9980 acc_val: 0.7008 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.30681896209716797\nEpoch: 0126 loss_train: 0.2634 acc_train: 0.9272 loss_val: 1.0015 acc_val: 0.7015 time: 0.0088s\nRanking optimizing... \nNow Average NDCG@k =  0.3058541417121887\nEpoch: 0127 loss_train: 0.2689 acc_train: 0.9248 loss_val: 1.0045 acc_val: 0.7015 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.3063511252403259\nEpoch: 0128 loss_train: 0.2382 acc_train: 0.9333 loss_val: 1.0072 acc_val: 0.7015 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.3052482008934021\nEpoch: 0129 loss_train: 0.2651 acc_train: 0.9163 loss_val: 1.0095 acc_val: 0.7008 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.3082662522792816\nEpoch: 0130 loss_train: 0.2488 acc_train: 0.9430 loss_val: 1.0119 acc_val: 0.7002 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.3067443370819092\nEpoch: 0131 loss_train: 0.2546 acc_train: 0.9320 loss_val: 1.0142 acc_val: 0.6990 time: 0.0115s\nRanking optimizing... \nNow Average NDCG@k =  0.3065755367279053\nEpoch: 0132 loss_train: 0.2515 acc_train: 0.9150 loss_val: 1.0165 acc_val: 0.6984 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.30535241961479187\nEpoch: 0133 loss_train: 0.2706 acc_train: 0.9138 loss_val: 1.0191 acc_val: 0.6990 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.3054187595844269\nEpoch: 0134 loss_train: 0.2418 acc_train: 0.9235 loss_val: 1.0219 acc_val: 0.6984 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.3047317564487457\nEpoch: 0135 loss_train: 0.2497 acc_train: 0.9357 loss_val: 1.0249 acc_val: 0.6984 time: 0.0093s\nRanking optimizing... \nNow Average NDCG@k =  0.30711421370506287\nEpoch: 0136 loss_train: 0.2482 acc_train: 0.9272 loss_val: 1.0277 acc_val: 0.6984 time: 0.0088s\nRanking optimizing... \nNow Average NDCG@k =  0.30704638361930847\nEpoch: 0137 loss_train: 0.2517 acc_train: 0.9235 loss_val: 1.0305 acc_val: 0.6996 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.3065429627895355\nEpoch: 0138 loss_train: 0.2371 acc_train: 0.9296 loss_val: 1.0332 acc_val: 0.6990 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.3063865900039673\nEpoch: 0139 loss_train: 0.2425 acc_train: 0.9430 loss_val: 1.0359 acc_val: 0.6972 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.306509405374527\nEpoch: 0140 loss_train: 0.2459 acc_train: 0.9308 loss_val: 1.0387 acc_val: 0.6972 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.3063008785247803\nEpoch: 0141 loss_train: 0.2321 acc_train: 0.9296 loss_val: 1.0411 acc_val: 0.6966 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.30719685554504395\nEpoch: 0142 loss_train: 0.2444 acc_train: 0.9296 loss_val: 1.0437 acc_val: 0.6972 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.30852198600769043\nEpoch: 0143 loss_train: 0.2252 acc_train: 0.9345 loss_val: 1.0465 acc_val: 0.6984 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.3054240643978119\nEpoch: 0144 loss_train: 0.2309 acc_train: 0.9320 loss_val: 1.0495 acc_val: 0.6966 time: 0.0063s\nRanking optimizing... \nNow Average NDCG@k =  0.3077315390110016\nEpoch: 0145 loss_train: 0.2151 acc_train: 0.9369 loss_val: 1.0526 acc_val: 0.6960 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.3074435293674469\nEpoch: 0146 loss_train: 0.2216 acc_train: 0.9393 loss_val: 1.0557 acc_val: 0.6984 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.3062055706977844\nEpoch: 0147 loss_train: 0.2393 acc_train: 0.9320 loss_val: 1.0589 acc_val: 0.6978 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.3056705594062805\nEpoch: 0148 loss_train: 0.2204 acc_train: 0.9405 loss_val: 1.0620 acc_val: 0.6966 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.30555590987205505\nEpoch: 0149 loss_train: 0.2273 acc_train: 0.9320 loss_val: 1.0650 acc_val: 0.6960 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.3051426410675049\nEpoch: 0150 loss_train: 0.2108 acc_train: 0.9478 loss_val: 1.0685 acc_val: 0.6966 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.30577582120895386\nTest set results: loss= 1.0697 accuracy= 0.7039\n"], ["node classification", "feature", "NDCG", "coauthor-cs", "SGC", "coauthor-cs\nTotal size :  18333\nUsing coauthor-cs dataset\nEpoch: 0001 loss_train: 2.7082 acc_train: 0.0404 loss_val: 2.6902 acc_val: 0.3273 time: 0.7304s\nEpoch: 0002 loss_train: 2.6896 acc_train: 0.3417 loss_val: 2.6722 acc_val: 0.5488 time: 0.0043s\nEpoch: 0003 loss_train: 2.6711 acc_train: 0.5721 loss_val: 2.6544 acc_val: 0.6143 time: 0.0039s\nEpoch: 0004 loss_train: 2.6528 acc_train: 0.6299 loss_val: 2.6368 acc_val: 0.6350 time: 0.0035s\nEpoch: 0005 loss_train: 2.6347 acc_train: 0.6452 loss_val: 2.6194 acc_val: 0.6432 time: 0.0035s\nEpoch: 0006 loss_train: 2.6168 acc_train: 0.6539 loss_val: 2.6022 acc_val: 0.6454 time: 0.0035s\nEpoch: 0007 loss_train: 2.5991 acc_train: 0.6561 loss_val: 2.5852 acc_val: 0.6432 time: 0.0035s\nEpoch: 0008 loss_train: 2.5817 acc_train: 0.6616 loss_val: 2.5685 acc_val: 0.6410 time: 0.0034s\nEpoch: 0009 loss_train: 2.5644 acc_train: 0.6627 loss_val: 2.5519 acc_val: 0.6416 time: 0.0034s\nEpoch: 0010 loss_train: 2.5473 acc_train: 0.6638 loss_val: 2.5356 acc_val: 0.6372 time: 0.0034s\nEpoch: 0011 loss_train: 2.5305 acc_train: 0.6572 loss_val: 2.5196 acc_val: 0.6345 time: 0.0034s\nEpoch: 0012 loss_train: 2.5138 acc_train: 0.6539 loss_val: 2.5037 acc_val: 0.6307 time: 0.0034s\nEpoch: 0013 loss_train: 2.4974 acc_train: 0.6517 loss_val: 2.4881 acc_val: 0.6258 time: 0.0034s\nEpoch: 0014 loss_train: 2.4812 acc_train: 0.6496 loss_val: 2.4727 acc_val: 0.6241 time: 0.0034s\nEpoch: 0015 loss_train: 2.4652 acc_train: 0.6485 loss_val: 2.4575 acc_val: 0.6197 time: 0.0034s\nEpoch: 0016 loss_train: 2.4494 acc_train: 0.6474 loss_val: 2.4425 acc_val: 0.6154 time: 0.0033s\nEpoch: 0017 loss_train: 2.4338 acc_train: 0.6441 loss_val: 2.4278 acc_val: 0.6116 time: 0.0034s\nEpoch: 0018 loss_train: 2.4184 acc_train: 0.6408 loss_val: 2.4132 acc_val: 0.6110 time: 0.0034s\nEpoch: 0019 loss_train: 2.4033 acc_train: 0.6386 loss_val: 2.3989 acc_val: 0.6083 time: 0.0033s\nEpoch: 0020 loss_train: 2.3883 acc_train: 0.6321 loss_val: 2.3847 acc_val: 0.6061 time: 0.0033s\nEpoch: 0021 loss_train: 2.3736 acc_train: 0.6321 loss_val: 2.3708 acc_val: 0.6045 time: 0.0033s\nEpoch: 0022 loss_train: 2.3590 acc_train: 0.6321 loss_val: 2.3570 acc_val: 0.6034 time: 0.0033s\nEpoch: 0023 loss_train: 2.3447 acc_train: 0.6299 loss_val: 2.3435 acc_val: 0.6001 time: 0.0034s\nEpoch: 0024 loss_train: 2.3306 acc_train: 0.6288 loss_val: 2.3301 acc_val: 0.5990 time: 0.0034s\nEpoch: 0025 loss_train: 2.3166 acc_train: 0.6277 loss_val: 2.3169 acc_val: 0.5979 time: 0.0034s\nEpoch: 0026 loss_train: 2.3029 acc_train: 0.6288 loss_val: 2.3038 acc_val: 0.5985 time: 0.0033s\nEpoch: 0027 loss_train: 2.2893 acc_train: 0.6299 loss_val: 2.2910 acc_val: 0.5985 time: 0.0033s\nEpoch: 0028 loss_train: 2.2759 acc_train: 0.6310 loss_val: 2.2783 acc_val: 0.5979 time: 0.0033s\nEpoch: 0029 loss_train: 2.2627 acc_train: 0.6288 loss_val: 2.2658 acc_val: 0.5968 time: 0.0033s\nEpoch: 0030 loss_train: 2.2497 acc_train: 0.6277 loss_val: 2.2534 acc_val: 0.5952 time: 0.0033s\nEpoch: 0031 loss_train: 2.2368 acc_train: 0.6266 loss_val: 2.2412 acc_val: 0.5963 time: 0.0033s\nEpoch: 0032 loss_train: 2.2241 acc_train: 0.6245 loss_val: 2.2291 acc_val: 0.5952 time: 0.0032s\nEpoch: 0033 loss_train: 2.2116 acc_train: 0.6223 loss_val: 2.2172 acc_val: 0.5952 time: 0.0032s\nEpoch: 0034 loss_train: 2.1993 acc_train: 0.6223 loss_val: 2.2055 acc_val: 0.5930 time: 0.0032s\nEpoch: 0035 loss_train: 2.1871 acc_train: 0.6201 loss_val: 2.1939 acc_val: 0.5914 time: 0.0032s\nEpoch: 0036 loss_train: 2.1750 acc_train: 0.6179 loss_val: 2.1825 acc_val: 0.5914 time: 0.0032s\nEpoch: 0037 loss_train: 2.1631 acc_train: 0.6179 loss_val: 2.1712 acc_val: 0.5908 time: 0.0032s\nEpoch: 0038 loss_train: 2.1514 acc_train: 0.6190 loss_val: 2.1601 acc_val: 0.5887 time: 0.0032s\nEpoch: 0039 loss_train: 2.1398 acc_train: 0.6190 loss_val: 2.1491 acc_val: 0.5865 time: 0.0032s\nEpoch: 0040 loss_train: 2.1283 acc_train: 0.6190 loss_val: 2.1382 acc_val: 0.5881 time: 0.0032s\nEpoch: 0041 loss_train: 2.1170 acc_train: 0.6190 loss_val: 2.1275 acc_val: 0.5876 time: 0.0032s\nEpoch: 0042 loss_train: 2.1058 acc_train: 0.6157 loss_val: 2.1169 acc_val: 0.5870 time: 0.0032s\nEpoch: 0043 loss_train: 2.0948 acc_train: 0.6168 loss_val: 2.1064 acc_val: 0.5865 time: 0.0032s\nEpoch: 0044 loss_train: 2.0839 acc_train: 0.6212 loss_val: 2.0961 acc_val: 0.5859 time: 0.0032s\nEpoch: 0045 loss_train: 2.0731 acc_train: 0.6223 loss_val: 2.0859 acc_val: 0.5848 time: 0.0032s\nEpoch: 0046 loss_train: 2.0624 acc_train: 0.6201 loss_val: 2.0758 acc_val: 0.5843 time: 0.0032s\nEpoch: 0047 loss_train: 2.0519 acc_train: 0.6212 loss_val: 2.0658 acc_val: 0.5854 time: 0.0032s\nEpoch: 0048 loss_train: 2.0414 acc_train: 0.6212 loss_val: 2.0560 acc_val: 0.5859 time: 0.0032s\nEpoch: 0049 loss_train: 2.0311 acc_train: 0.6190 loss_val: 2.0462 acc_val: 0.5870 time: 0.0033s\nEpoch: 0050 loss_train: 2.0209 acc_train: 0.6190 loss_val: 2.0366 acc_val: 0.5887 time: 0.0032s\nEpoch: 0051 loss_train: 2.0108 acc_train: 0.6201 loss_val: 2.0270 acc_val: 0.5903 time: 0.0032s\nEpoch: 0052 loss_train: 2.0008 acc_train: 0.6223 loss_val: 2.0176 acc_val: 0.5919 time: 0.0032s\nEpoch: 0053 loss_train: 1.9909 acc_train: 0.6223 loss_val: 2.0083 acc_val: 0.5930 time: 0.0032s\nEpoch: 0054 loss_train: 1.9811 acc_train: 0.6234 loss_val: 1.9990 acc_val: 0.5947 time: 0.0032s\nEpoch: 0055 loss_train: 1.9715 acc_train: 0.6234 loss_val: 1.9899 acc_val: 0.5968 time: 0.0032s\nEpoch: 0056 loss_train: 1.9619 acc_train: 0.6255 loss_val: 1.9808 acc_val: 0.5979 time: 0.0032s\nEpoch: 0057 loss_train: 1.9524 acc_train: 0.6266 loss_val: 1.9718 acc_val: 0.6001 time: 0.0032s\nEpoch: 0058 loss_train: 1.9430 acc_train: 0.6288 loss_val: 1.9630 acc_val: 0.6028 time: 0.0032s\nEpoch: 0059 loss_train: 1.9337 acc_train: 0.6310 loss_val: 1.9542 acc_val: 0.6023 time: 0.0032s\nEpoch: 0060 loss_train: 1.9245 acc_train: 0.6332 loss_val: 1.9455 acc_val: 0.6034 time: 0.0032s\nEpoch: 0061 loss_train: 1.9154 acc_train: 0.6365 loss_val: 1.9369 acc_val: 0.6056 time: 0.0032s\nEpoch: 0062 loss_train: 1.9063 acc_train: 0.6376 loss_val: 1.9283 acc_val: 0.6105 time: 0.0032s\nEpoch: 0063 loss_train: 1.8974 acc_train: 0.6376 loss_val: 1.9199 acc_val: 0.6110 time: 0.0032s\nEpoch: 0064 loss_train: 1.8885 acc_train: 0.6386 loss_val: 1.9115 acc_val: 0.6127 time: 0.0032s\nEpoch: 0065 loss_train: 1.8797 acc_train: 0.6430 loss_val: 1.9032 acc_val: 0.6154 time: 0.0032s\nEpoch: 0066 loss_train: 1.8710 acc_train: 0.6430 loss_val: 1.8950 acc_val: 0.6165 time: 0.0032s\nEpoch: 0067 loss_train: 1.8624 acc_train: 0.6485 loss_val: 1.8869 acc_val: 0.6181 time: 0.0032s\nEpoch: 0068 loss_train: 1.8539 acc_train: 0.6507 loss_val: 1.8789 acc_val: 0.6187 time: 0.0032s\nEpoch: 0069 loss_train: 1.8454 acc_train: 0.6528 loss_val: 1.8709 acc_val: 0.6208 time: 0.0032s\nEpoch: 0070 loss_train: 1.8370 acc_train: 0.6539 loss_val: 1.8630 acc_val: 0.6214 time: 0.0032s\nEpoch: 0071 loss_train: 1.8287 acc_train: 0.6539 loss_val: 1.8552 acc_val: 0.6241 time: 0.0032s\nEpoch: 0072 loss_train: 1.8205 acc_train: 0.6572 loss_val: 1.8474 acc_val: 0.6263 time: 0.0038s\nEpoch: 0073 loss_train: 1.8123 acc_train: 0.6594 loss_val: 1.8397 acc_val: 0.6279 time: 0.0042s\nEpoch: 0074 loss_train: 1.8042 acc_train: 0.6605 loss_val: 1.8321 acc_val: 0.6296 time: 0.0041s\nEpoch: 0075 loss_train: 1.7962 acc_train: 0.6605 loss_val: 1.8246 acc_val: 0.6301 time: 0.0040s\nEpoch: 0076 loss_train: 1.7883 acc_train: 0.6627 loss_val: 1.8171 acc_val: 0.6318 time: 0.0038s\nEpoch: 0077 loss_train: 1.7804 acc_train: 0.6627 loss_val: 1.8097 acc_val: 0.6339 time: 0.0034s\nEpoch: 0078 loss_train: 1.7726 acc_train: 0.6659 loss_val: 1.8023 acc_val: 0.6350 time: 0.0036s\nEpoch: 0079 loss_train: 1.7648 acc_train: 0.6681 loss_val: 1.7950 acc_val: 0.6361 time: 0.0034s\nEpoch: 0080 loss_train: 1.7572 acc_train: 0.6714 loss_val: 1.7878 acc_val: 0.6388 time: 0.0033s\nEpoch: 0081 loss_train: 1.7496 acc_train: 0.6736 loss_val: 1.7806 acc_val: 0.6421 time: 0.0033s\nEpoch: 0082 loss_train: 1.7420 acc_train: 0.6736 loss_val: 1.7735 acc_val: 0.6438 time: 0.0033s\nEpoch: 0083 loss_train: 1.7345 acc_train: 0.6779 loss_val: 1.7664 acc_val: 0.6492 time: 0.0032s\nEpoch: 0084 loss_train: 1.7271 acc_train: 0.6823 loss_val: 1.7594 acc_val: 0.6514 time: 0.0032s\nEpoch: 0085 loss_train: 1.7197 acc_train: 0.6856 loss_val: 1.7525 acc_val: 0.6530 time: 0.0032s\nEpoch: 0086 loss_train: 1.7124 acc_train: 0.6878 loss_val: 1.7456 acc_val: 0.6558 time: 0.0032s\nEpoch: 0087 loss_train: 1.7052 acc_train: 0.6900 loss_val: 1.7388 acc_val: 0.6563 time: 0.0032s\nEpoch: 0088 loss_train: 1.6980 acc_train: 0.6921 loss_val: 1.7320 acc_val: 0.6601 time: 0.0032s\nEpoch: 0089 loss_train: 1.6909 acc_train: 0.6943 loss_val: 1.7253 acc_val: 0.6634 time: 0.0032s\nEpoch: 0090 loss_train: 1.6838 acc_train: 0.6954 loss_val: 1.7187 acc_val: 0.6650 time: 0.0032s\nEpoch: 0091 loss_train: 1.6768 acc_train: 0.6976 loss_val: 1.7121 acc_val: 0.6667 time: 0.0032s\nEpoch: 0092 loss_train: 1.6698 acc_train: 0.6998 loss_val: 1.7055 acc_val: 0.6683 time: 0.0032s\nEpoch: 0093 loss_train: 1.6629 acc_train: 0.7020 loss_val: 1.6990 acc_val: 0.6710 time: 0.0032s\nEpoch: 0094 loss_train: 1.6561 acc_train: 0.7031 loss_val: 1.6926 acc_val: 0.6748 time: 0.0032s\nEpoch: 0095 loss_train: 1.6493 acc_train: 0.7041 loss_val: 1.6862 acc_val: 0.6781 time: 0.0032s\nEpoch: 0096 loss_train: 1.6426 acc_train: 0.7074 loss_val: 1.6798 acc_val: 0.6781 time: 0.0032s\nEpoch: 0097 loss_train: 1.6359 acc_train: 0.7096 loss_val: 1.6735 acc_val: 0.6819 time: 0.0032s\nEpoch: 0098 loss_train: 1.6293 acc_train: 0.7129 loss_val: 1.6673 acc_val: 0.6836 time: 0.0032s\nEpoch: 0099 loss_train: 1.6227 acc_train: 0.7172 loss_val: 1.6611 acc_val: 0.6874 time: 0.0032s\nEpoch: 0100 loss_train: 1.6161 acc_train: 0.7172 loss_val: 1.6550 acc_val: 0.6890 time: 0.0032s\nEpoch: 0101 loss_train: 1.6097 acc_train: 0.7183 loss_val: 1.6489 acc_val: 0.6929 time: 0.0032s\nEpoch: 0102 loss_train: 1.6032 acc_train: 0.7216 loss_val: 1.6428 acc_val: 0.6929 time: 0.0032s\nEpoch: 0103 loss_train: 1.5968 acc_train: 0.7227 loss_val: 1.6368 acc_val: 0.6961 time: 0.0032s\nEpoch: 0104 loss_train: 1.5905 acc_train: 0.7249 loss_val: 1.6308 acc_val: 0.6978 time: 0.0032s\nEpoch: 0105 loss_train: 1.5842 acc_train: 0.7303 loss_val: 1.6249 acc_val: 0.7010 time: 0.0032s\nEpoch: 0106 loss_train: 1.5780 acc_train: 0.7314 loss_val: 1.6190 acc_val: 0.7027 time: 0.0032s\nEpoch: 0107 loss_train: 1.5718 acc_train: 0.7358 loss_val: 1.6132 acc_val: 0.7043 time: 0.0032s\nEpoch: 0108 loss_train: 1.5657 acc_train: 0.7413 loss_val: 1.6074 acc_val: 0.7076 time: 0.0032s\nEpoch: 0109 loss_train: 1.5596 acc_train: 0.7434 loss_val: 1.6017 acc_val: 0.7087 time: 0.0032s\nEpoch: 0110 loss_train: 1.5535 acc_train: 0.7445 loss_val: 1.5960 acc_val: 0.7103 time: 0.0032s\nEpoch: 0111 loss_train: 1.5475 acc_train: 0.7445 loss_val: 1.5903 acc_val: 0.7136 time: 0.0032s\nEpoch: 0112 loss_train: 1.5415 acc_train: 0.7478 loss_val: 1.5847 acc_val: 0.7152 time: 0.0032s\nEpoch: 0113 loss_train: 1.5356 acc_train: 0.7478 loss_val: 1.5791 acc_val: 0.7169 time: 0.0032s\nEpoch: 0114 loss_train: 1.5297 acc_train: 0.7500 loss_val: 1.5736 acc_val: 0.7201 time: 0.0032s\nEpoch: 0115 loss_train: 1.5239 acc_train: 0.7533 loss_val: 1.5681 acc_val: 0.7234 time: 0.0032s\nEpoch: 0116 loss_train: 1.5181 acc_train: 0.7566 loss_val: 1.5626 acc_val: 0.7261 time: 0.0032s\nEpoch: 0117 loss_train: 1.5123 acc_train: 0.7631 loss_val: 1.5572 acc_val: 0.7289 time: 0.0032s\nEpoch: 0118 loss_train: 1.5066 acc_train: 0.7675 loss_val: 1.5518 acc_val: 0.7310 time: 0.0032s\nEpoch: 0119 loss_train: 1.5010 acc_train: 0.7686 loss_val: 1.5465 acc_val: 0.7354 time: 0.0032s\nEpoch: 0120 loss_train: 1.4953 acc_train: 0.7686 loss_val: 1.5412 acc_val: 0.7370 time: 0.0032s\nEpoch: 0121 loss_train: 1.4898 acc_train: 0.7707 loss_val: 1.5359 acc_val: 0.7392 time: 0.0032s\nEpoch: 0122 loss_train: 1.4842 acc_train: 0.7718 loss_val: 1.5307 acc_val: 0.7420 time: 0.0032s\nEpoch: 0123 loss_train: 1.4787 acc_train: 0.7729 loss_val: 1.5255 acc_val: 0.7425 time: 0.0032s\nEpoch: 0124 loss_train: 1.4732 acc_train: 0.7773 loss_val: 1.5204 acc_val: 0.7436 time: 0.0032s\nEpoch: 0125 loss_train: 1.4678 acc_train: 0.7773 loss_val: 1.5152 acc_val: 0.7452 time: 0.0032s\nEpoch: 0126 loss_train: 1.4624 acc_train: 0.7795 loss_val: 1.5102 acc_val: 0.7447 time: 0.0032s\nEpoch: 0127 loss_train: 1.4571 acc_train: 0.7795 loss_val: 1.5051 acc_val: 0.7474 time: 0.0032s\nEpoch: 0128 loss_train: 1.4518 acc_train: 0.7817 loss_val: 1.5001 acc_val: 0.7485 time: 0.0032s\nEpoch: 0129 loss_train: 1.4465 acc_train: 0.7838 loss_val: 1.4951 acc_val: 0.7507 time: 0.0032s\nEpoch: 0130 loss_train: 1.4412 acc_train: 0.7838 loss_val: 1.4902 acc_val: 0.7518 time: 0.0032s\nEpoch: 0131 loss_train: 1.4360 acc_train: 0.7871 loss_val: 1.4853 acc_val: 0.7523 time: 0.0032s\nEpoch: 0132 loss_train: 1.4309 acc_train: 0.7882 loss_val: 1.4804 acc_val: 0.7545 time: 0.0032s\nEpoch: 0133 loss_train: 1.4257 acc_train: 0.7904 loss_val: 1.4756 acc_val: 0.7567 time: 0.0032s\nEpoch: 0134 loss_train: 1.4206 acc_train: 0.7915 loss_val: 1.4708 acc_val: 0.7572 time: 0.0032s\nEpoch: 0135 loss_train: 1.4156 acc_train: 0.7937 loss_val: 1.4660 acc_val: 0.7589 time: 0.0032s\nEpoch: 0136 loss_train: 1.4106 acc_train: 0.7991 loss_val: 1.4613 acc_val: 0.7610 time: 0.0032s\nEpoch: 0137 loss_train: 1.4056 acc_train: 0.8024 loss_val: 1.4566 acc_val: 0.7632 time: 0.0032s\nEpoch: 0138 loss_train: 1.4006 acc_train: 0.8035 loss_val: 1.4519 acc_val: 0.7638 time: 0.0032s\nEpoch: 0139 loss_train: 1.3957 acc_train: 0.8046 loss_val: 1.4473 acc_val: 0.7654 time: 0.0032s\nEpoch: 0140 loss_train: 1.3908 acc_train: 0.8068 loss_val: 1.4427 acc_val: 0.7670 time: 0.0032s\nEpoch: 0141 loss_train: 1.3860 acc_train: 0.8079 loss_val: 1.4381 acc_val: 0.7692 time: 0.0032s\nEpoch: 0142 loss_train: 1.3812 acc_train: 0.8079 loss_val: 1.4335 acc_val: 0.7703 time: 0.0032s\nEpoch: 0143 loss_train: 1.3764 acc_train: 0.8079 loss_val: 1.4290 acc_val: 0.7720 time: 0.0032s\nEpoch: 0144 loss_train: 1.3716 acc_train: 0.8090 loss_val: 1.4245 acc_val: 0.7741 time: 0.0032s\nEpoch: 0145 loss_train: 1.3669 acc_train: 0.8111 loss_val: 1.4201 acc_val: 0.7741 time: 0.0032s\nEpoch: 0146 loss_train: 1.3622 acc_train: 0.8122 loss_val: 1.4157 acc_val: 0.7769 time: 0.0032s\nEpoch: 0147 loss_train: 1.3576 acc_train: 0.8133 loss_val: 1.4113 acc_val: 0.7785 time: 0.0032s\nEpoch: 0148 loss_train: 1.3529 acc_train: 0.8133 loss_val: 1.4069 acc_val: 0.7801 time: 0.0032s\nEpoch: 0149 loss_train: 1.3483 acc_train: 0.8133 loss_val: 1.4026 acc_val: 0.7823 time: 0.0032s\nEpoch: 0150 loss_train: 1.3438 acc_train: 0.8166 loss_val: 1.3983 acc_val: 0.7834 time: 0.0032s\nEpoch: 0151 loss_train: 1.3392 acc_train: 0.8177 loss_val: 1.3940 acc_val: 0.7840 time: 0.0032s\nEpoch: 0152 loss_train: 1.3347 acc_train: 0.8210 loss_val: 1.3897 acc_val: 0.7872 time: 0.0032s\nEpoch: 0153 loss_train: 1.3303 acc_train: 0.8221 loss_val: 1.3855 acc_val: 0.7889 time: 0.0032s\nEpoch: 0154 loss_train: 1.3258 acc_train: 0.8231 loss_val: 1.3813 acc_val: 0.7900 time: 0.0032s\nEpoch: 0155 loss_train: 1.3214 acc_train: 0.8242 loss_val: 1.3772 acc_val: 0.7916 time: 0.0032s\nEpoch: 0156 loss_train: 1.3170 acc_train: 0.8253 loss_val: 1.3730 acc_val: 0.7927 time: 0.0032s\nEpoch: 0157 loss_train: 1.3127 acc_train: 0.8253 loss_val: 1.3689 acc_val: 0.7927 time: 0.0032s\nEpoch: 0158 loss_train: 1.3084 acc_train: 0.8253 loss_val: 1.3648 acc_val: 0.7927 time: 0.0032s\nEpoch: 0159 loss_train: 1.3041 acc_train: 0.8253 loss_val: 1.3608 acc_val: 0.7949 time: 0.0032s\nEpoch: 0160 loss_train: 1.2998 acc_train: 0.8264 loss_val: 1.3568 acc_val: 0.7949 time: 0.0032s\nEpoch: 0161 loss_train: 1.2956 acc_train: 0.8275 loss_val: 1.3528 acc_val: 0.7949 time: 0.0032s\nEpoch: 0162 loss_train: 1.2914 acc_train: 0.8275 loss_val: 1.3488 acc_val: 0.7960 time: 0.0032s\nEpoch: 0163 loss_train: 1.2872 acc_train: 0.8275 loss_val: 1.3448 acc_val: 0.7965 time: 0.0032s\nEpoch: 0164 loss_train: 1.2830 acc_train: 0.8286 loss_val: 1.3409 acc_val: 0.7976 time: 0.0032s\nEpoch: 0165 loss_train: 1.2789 acc_train: 0.8297 loss_val: 1.3370 acc_val: 0.7987 time: 0.0032s\nEpoch: 0166 loss_train: 1.2748 acc_train: 0.8308 loss_val: 1.3331 acc_val: 0.7998 time: 0.0032s\nEpoch: 0167 loss_train: 1.2707 acc_train: 0.8319 loss_val: 1.3293 acc_val: 0.8014 time: 0.0032s\nEpoch: 0168 loss_train: 1.2667 acc_train: 0.8330 loss_val: 1.3255 acc_val: 0.8025 time: 0.0032s\nEpoch: 0169 loss_train: 1.2627 acc_train: 0.8362 loss_val: 1.3217 acc_val: 0.8031 time: 0.0032s\nEpoch: 0170 loss_train: 1.2587 acc_train: 0.8362 loss_val: 1.3179 acc_val: 0.8041 time: 0.0032s\nEpoch: 0171 loss_train: 1.2547 acc_train: 0.8384 loss_val: 1.3142 acc_val: 0.8041 time: 0.0032s\nEpoch: 0172 loss_train: 1.2508 acc_train: 0.8417 loss_val: 1.3104 acc_val: 0.8041 time: 0.0032s\nEpoch: 0173 loss_train: 1.2469 acc_train: 0.8439 loss_val: 1.3067 acc_val: 0.8047 time: 0.0032s\nEpoch: 0174 loss_train: 1.2430 acc_train: 0.8450 loss_val: 1.3030 acc_val: 0.8058 time: 0.0032s\nEpoch: 0175 loss_train: 1.2391 acc_train: 0.8450 loss_val: 1.2994 acc_val: 0.8069 time: 0.0032s\nEpoch: 0176 loss_train: 1.2353 acc_train: 0.8461 loss_val: 1.2958 acc_val: 0.8085 time: 0.0032s\nEpoch: 0177 loss_train: 1.2315 acc_train: 0.8472 loss_val: 1.2922 acc_val: 0.8091 time: 0.0032s\nEpoch: 0178 loss_train: 1.2277 acc_train: 0.8493 loss_val: 1.2886 acc_val: 0.8101 time: 0.0032s\nEpoch: 0179 loss_train: 1.2239 acc_train: 0.8493 loss_val: 1.2850 acc_val: 0.8118 time: 0.0032s\nEpoch: 0180 loss_train: 1.2202 acc_train: 0.8515 loss_val: 1.2815 acc_val: 0.8129 time: 0.0032s\nEpoch: 0181 loss_train: 1.2165 acc_train: 0.8526 loss_val: 1.2780 acc_val: 0.8145 time: 0.0032s\nEpoch: 0182 loss_train: 1.2128 acc_train: 0.8526 loss_val: 1.2745 acc_val: 0.8145 time: 0.0032s\nEpoch: 0183 loss_train: 1.2091 acc_train: 0.8526 loss_val: 1.2710 acc_val: 0.8151 time: 0.0032s\nEpoch: 0184 loss_train: 1.2055 acc_train: 0.8526 loss_val: 1.2675 acc_val: 0.8167 time: 0.0032s\nEpoch: 0185 loss_train: 1.2019 acc_train: 0.8537 loss_val: 1.2641 acc_val: 0.8178 time: 0.0032s\nEpoch: 0186 loss_train: 1.1983 acc_train: 0.8537 loss_val: 1.2607 acc_val: 0.8183 time: 0.0032s\nEpoch: 0187 loss_train: 1.1947 acc_train: 0.8537 loss_val: 1.2573 acc_val: 0.8205 time: 0.0032s\nEpoch: 0188 loss_train: 1.1912 acc_train: 0.8537 loss_val: 1.2540 acc_val: 0.8216 time: 0.0032s\nEpoch: 0189 loss_train: 1.1876 acc_train: 0.8570 loss_val: 1.2506 acc_val: 0.8221 time: 0.0032s\nEpoch: 0190 loss_train: 1.1841 acc_train: 0.8570 loss_val: 1.2473 acc_val: 0.8221 time: 0.0032s\nEpoch: 0191 loss_train: 1.1806 acc_train: 0.8570 loss_val: 1.2440 acc_val: 0.8221 time: 0.0032s\nEpoch: 0192 loss_train: 1.1772 acc_train: 0.8592 loss_val: 1.2407 acc_val: 0.8216 time: 0.0032s\nEpoch: 0193 loss_train: 1.1737 acc_train: 0.8592 loss_val: 1.2375 acc_val: 0.8221 time: 0.0032s\nEpoch: 0194 loss_train: 1.1703 acc_train: 0.8592 loss_val: 1.2342 acc_val: 0.8232 time: 0.0032s\nEpoch: 0195 loss_train: 1.1669 acc_train: 0.8592 loss_val: 1.2310 acc_val: 0.8238 time: 0.0032s\nEpoch: 0196 loss_train: 1.1636 acc_train: 0.8592 loss_val: 1.2278 acc_val: 0.8249 time: 0.0032s\nEpoch: 0197 loss_train: 1.1602 acc_train: 0.8592 loss_val: 1.2246 acc_val: 0.8265 time: 0.0032s\nEpoch: 0198 loss_train: 1.1569 acc_train: 0.8592 loss_val: 1.2215 acc_val: 0.8271 time: 0.0032s\nEpoch: 0199 loss_train: 1.1536 acc_train: 0.8614 loss_val: 1.2183 acc_val: 0.8276 time: 0.0032s\nEpoch: 0200 loss_train: 1.1503 acc_train: 0.8614 loss_val: 1.2152 acc_val: 0.8276 time: 0.0032s\nEpoch: 0201 loss_train: 1.1470 acc_train: 0.8614 loss_val: 1.2121 acc_val: 0.8287 time: 0.0032s\nEpoch: 0202 loss_train: 1.1438 acc_train: 0.8624 loss_val: 1.2090 acc_val: 0.8292 time: 0.0032s\nEpoch: 0203 loss_train: 1.1405 acc_train: 0.8624 loss_val: 1.2060 acc_val: 0.8298 time: 0.0032s\nEpoch: 0204 loss_train: 1.1373 acc_train: 0.8635 loss_val: 1.2029 acc_val: 0.8303 time: 0.0032s\nEpoch: 0205 loss_train: 1.1341 acc_train: 0.8646 loss_val: 1.1999 acc_val: 0.8309 time: 0.0032s\nEpoch: 0206 loss_train: 1.1310 acc_train: 0.8657 loss_val: 1.1969 acc_val: 0.8314 time: 0.0032s\nEpoch: 0207 loss_train: 1.1278 acc_train: 0.8657 loss_val: 1.1939 acc_val: 0.8314 time: 0.0032s\nEpoch: 0208 loss_train: 1.1247 acc_train: 0.8657 loss_val: 1.1909 acc_val: 0.8314 time: 0.0032s\nEpoch: 0209 loss_train: 1.1216 acc_train: 0.8668 loss_val: 1.1880 acc_val: 0.8325 time: 0.0032s\nEpoch: 0210 loss_train: 1.1185 acc_train: 0.8668 loss_val: 1.1850 acc_val: 0.8342 time: 0.0032s\nEpoch: 0211 loss_train: 1.1154 acc_train: 0.8668 loss_val: 1.1821 acc_val: 0.8342 time: 0.0032s\nEpoch: 0212 loss_train: 1.1124 acc_train: 0.8668 loss_val: 1.1792 acc_val: 0.8358 time: 0.0032s\nEpoch: 0213 loss_train: 1.1093 acc_train: 0.8679 loss_val: 1.1763 acc_val: 0.8369 time: 0.0032s\nEpoch: 0214 loss_train: 1.1063 acc_train: 0.8679 loss_val: 1.1735 acc_val: 0.8374 time: 0.0032s\nEpoch: 0215 loss_train: 1.1033 acc_train: 0.8690 loss_val: 1.1706 acc_val: 0.8363 time: 0.0032s\nEpoch: 0216 loss_train: 1.1004 acc_train: 0.8690 loss_val: 1.1678 acc_val: 0.8374 time: 0.0032s\nEpoch: 0217 loss_train: 1.0974 acc_train: 0.8701 loss_val: 1.1650 acc_val: 0.8369 time: 0.0032s\nEpoch: 0218 loss_train: 1.0945 acc_train: 0.8701 loss_val: 1.1622 acc_val: 0.8374 time: 0.0032s\nEpoch: 0219 loss_train: 1.0915 acc_train: 0.8701 loss_val: 1.1594 acc_val: 0.8391 time: 0.0032s\nEpoch: 0220 loss_train: 1.0886 acc_train: 0.8723 loss_val: 1.1567 acc_val: 0.8391 time: 0.0032s\nEpoch: 0221 loss_train: 1.0857 acc_train: 0.8734 loss_val: 1.1539 acc_val: 0.8396 time: 0.0032s\nEpoch: 0222 loss_train: 1.0829 acc_train: 0.8745 loss_val: 1.1512 acc_val: 0.8396 time: 0.0032s\nEpoch: 0223 loss_train: 1.0800 acc_train: 0.8745 loss_val: 1.1485 acc_val: 0.8402 time: 0.0032s\nEpoch: 0224 loss_train: 1.0772 acc_train: 0.8745 loss_val: 1.1458 acc_val: 0.8407 time: 0.0032s\nEpoch: 0225 loss_train: 1.0744 acc_train: 0.8745 loss_val: 1.1431 acc_val: 0.8407 time: 0.0032s\nEpoch: 0226 loss_train: 1.0716 acc_train: 0.8745 loss_val: 1.1404 acc_val: 0.8407 time: 0.0032s\nEpoch: 0227 loss_train: 1.0688 acc_train: 0.8755 loss_val: 1.1378 acc_val: 0.8412 time: 0.0032s\nEpoch: 0228 loss_train: 1.0660 acc_train: 0.8777 loss_val: 1.1351 acc_val: 0.8412 time: 0.0032s\nEpoch: 0229 loss_train: 1.0633 acc_train: 0.8777 loss_val: 1.1325 acc_val: 0.8412 time: 0.0032s\nEpoch: 0230 loss_train: 1.0605 acc_train: 0.8777 loss_val: 1.1299 acc_val: 0.8418 time: 0.0032s\nEpoch: 0231 loss_train: 1.0578 acc_train: 0.8788 loss_val: 1.1273 acc_val: 0.8418 time: 0.0032s\nEpoch: 0232 loss_train: 1.0551 acc_train: 0.8799 loss_val: 1.1248 acc_val: 0.8429 time: 0.0032s\nEpoch: 0233 loss_train: 1.0524 acc_train: 0.8810 loss_val: 1.1222 acc_val: 0.8429 time: 0.0032s\nEpoch: 0234 loss_train: 1.0498 acc_train: 0.8810 loss_val: 1.1197 acc_val: 0.8429 time: 0.0032s\nEpoch: 0235 loss_train: 1.0471 acc_train: 0.8810 loss_val: 1.1171 acc_val: 0.8429 time: 0.0032s\nEpoch: 0236 loss_train: 1.0445 acc_train: 0.8810 loss_val: 1.1146 acc_val: 0.8429 time: 0.0032s\nEpoch: 0237 loss_train: 1.0419 acc_train: 0.8821 loss_val: 1.1121 acc_val: 0.8434 time: 0.0032s\nEpoch: 0238 loss_train: 1.0393 acc_train: 0.8821 loss_val: 1.1096 acc_val: 0.8434 time: 0.0032s\nEpoch: 0239 loss_train: 1.0367 acc_train: 0.8821 loss_val: 1.1072 acc_val: 0.8440 time: 0.0032s\nEpoch: 0240 loss_train: 1.0341 acc_train: 0.8821 loss_val: 1.1047 acc_val: 0.8440 time: 0.0032s\nEpoch: 0241 loss_train: 1.0315 acc_train: 0.8821 loss_val: 1.1023 acc_val: 0.8440 time: 0.0032s\nEpoch: 0242 loss_train: 1.0290 acc_train: 0.8821 loss_val: 1.0999 acc_val: 0.8440 time: 0.0032s\nEpoch: 0243 loss_train: 1.0265 acc_train: 0.8832 loss_val: 1.0974 acc_val: 0.8440 time: 0.0032s\nEpoch: 0244 loss_train: 1.0239 acc_train: 0.8832 loss_val: 1.0950 acc_val: 0.8445 time: 0.0032s\nEpoch: 0245 loss_train: 1.0214 acc_train: 0.8832 loss_val: 1.0927 acc_val: 0.8451 time: 0.0032s\nEpoch: 0246 loss_train: 1.0190 acc_train: 0.8832 loss_val: 1.0903 acc_val: 0.8451 time: 0.0032s\nEpoch: 0247 loss_train: 1.0165 acc_train: 0.8832 loss_val: 1.0879 acc_val: 0.8456 time: 0.0032s\nEpoch: 0248 loss_train: 1.0140 acc_train: 0.8843 loss_val: 1.0856 acc_val: 0.8462 time: 0.0032s\nEpoch: 0249 loss_train: 1.0116 acc_train: 0.8843 loss_val: 1.0833 acc_val: 0.8472 time: 0.0032s\nEpoch: 0250 loss_train: 1.0092 acc_train: 0.8843 loss_val: 1.0809 acc_val: 0.8472 time: 0.0032s\nEpoch: 0251 loss_train: 1.0068 acc_train: 0.8843 loss_val: 1.0786 acc_val: 0.8472 time: 0.0032s\nEpoch: 0252 loss_train: 1.0044 acc_train: 0.8843 loss_val: 1.0763 acc_val: 0.8478 time: 0.0032s\nEpoch: 0253 loss_train: 1.0020 acc_train: 0.8843 loss_val: 1.0741 acc_val: 0.8478 time: 0.0032s\nEpoch: 0254 loss_train: 0.9996 acc_train: 0.8854 loss_val: 1.0718 acc_val: 0.8489 time: 0.0032s\nEpoch: 0255 loss_train: 0.9972 acc_train: 0.8865 loss_val: 1.0695 acc_val: 0.8494 time: 0.0032s\nEpoch: 0256 loss_train: 0.9949 acc_train: 0.8865 loss_val: 1.0673 acc_val: 0.8494 time: 0.0032s\nEpoch: 0257 loss_train: 0.9926 acc_train: 0.8876 loss_val: 1.0651 acc_val: 0.8500 time: 0.0032s\nEpoch: 0258 loss_train: 0.9902 acc_train: 0.8876 loss_val: 1.0629 acc_val: 0.8500 time: 0.0032s\nEpoch: 0259 loss_train: 0.9879 acc_train: 0.8876 loss_val: 1.0607 acc_val: 0.8500 time: 0.0032s\nEpoch: 0260 loss_train: 0.9857 acc_train: 0.8876 loss_val: 1.0585 acc_val: 0.8500 time: 0.0032s\nEpoch: 0261 loss_train: 0.9834 acc_train: 0.8886 loss_val: 1.0563 acc_val: 0.8500 time: 0.0032s\nEpoch: 0262 loss_train: 0.9811 acc_train: 0.8886 loss_val: 1.0541 acc_val: 0.8500 time: 0.0032s\nEpoch: 0263 loss_train: 0.9789 acc_train: 0.8886 loss_val: 1.0520 acc_val: 0.8511 time: 0.0032s\nEpoch: 0264 loss_train: 0.9766 acc_train: 0.8886 loss_val: 1.0498 acc_val: 0.8511 time: 0.0032s\nEpoch: 0265 loss_train: 0.9744 acc_train: 0.8897 loss_val: 1.0477 acc_val: 0.8522 time: 0.0032s\nEpoch: 0266 loss_train: 0.9722 acc_train: 0.8919 loss_val: 1.0456 acc_val: 0.8522 time: 0.0032s\nEpoch: 0267 loss_train: 0.9700 acc_train: 0.8930 loss_val: 1.0435 acc_val: 0.8522 time: 0.0032s\nEpoch: 0268 loss_train: 0.9678 acc_train: 0.8930 loss_val: 1.0414 acc_val: 0.8522 time: 0.0032s\nEpoch: 0269 loss_train: 0.9656 acc_train: 0.8930 loss_val: 1.0393 acc_val: 0.8527 time: 0.0032s\nEpoch: 0270 loss_train: 0.9635 acc_train: 0.8930 loss_val: 1.0372 acc_val: 0.8532 time: 0.0032s\nEpoch: 0271 loss_train: 0.9613 acc_train: 0.8930 loss_val: 1.0352 acc_val: 0.8549 time: 0.0032s\nEpoch: 0272 loss_train: 0.9592 acc_train: 0.8930 loss_val: 1.0331 acc_val: 0.8554 time: 0.0032s\nEpoch: 0273 loss_train: 0.9570 acc_train: 0.8941 loss_val: 1.0311 acc_val: 0.8560 time: 0.0032s\nEpoch: 0274 loss_train: 0.9549 acc_train: 0.8941 loss_val: 1.0291 acc_val: 0.8571 time: 0.0032s\nEpoch: 0275 loss_train: 0.9528 acc_train: 0.8952 loss_val: 1.0271 acc_val: 0.8571 time: 0.0032s\nEpoch: 0276 loss_train: 0.9507 acc_train: 0.8941 loss_val: 1.0250 acc_val: 0.8576 time: 0.0032s\nEpoch: 0277 loss_train: 0.9486 acc_train: 0.8941 loss_val: 1.0231 acc_val: 0.8582 time: 0.0032s\nEpoch: 0278 loss_train: 0.9466 acc_train: 0.8941 loss_val: 1.0211 acc_val: 0.8582 time: 0.0032s\nEpoch: 0279 loss_train: 0.9445 acc_train: 0.8941 loss_val: 1.0191 acc_val: 0.8582 time: 0.0032s\nEpoch: 0280 loss_train: 0.9425 acc_train: 0.8952 loss_val: 1.0171 acc_val: 0.8582 time: 0.0032s\nEpoch: 0281 loss_train: 0.9404 acc_train: 0.8952 loss_val: 1.0152 acc_val: 0.8587 time: 0.0032s\nEpoch: 0282 loss_train: 0.9384 acc_train: 0.8952 loss_val: 1.0133 acc_val: 0.8592 time: 0.0032s\nEpoch: 0283 loss_train: 0.9364 acc_train: 0.8952 loss_val: 1.0113 acc_val: 0.8614 time: 0.0032s\nEpoch: 0284 loss_train: 0.9344 acc_train: 0.8963 loss_val: 1.0094 acc_val: 0.8620 time: 0.0032s\nEpoch: 0285 loss_train: 0.9324 acc_train: 0.8974 loss_val: 1.0075 acc_val: 0.8625 time: 0.0032s\nEpoch: 0286 loss_train: 0.9304 acc_train: 0.8974 loss_val: 1.0056 acc_val: 0.8631 time: 0.0032s\nEpoch: 0287 loss_train: 0.9285 acc_train: 0.8974 loss_val: 1.0037 acc_val: 0.8631 time: 0.0032s\nEpoch: 0288 loss_train: 0.9265 acc_train: 0.8963 loss_val: 1.0018 acc_val: 0.8647 time: 0.0032s\nEpoch: 0289 loss_train: 0.9246 acc_train: 0.8974 loss_val: 1.0000 acc_val: 0.8647 time: 0.0032s\nEpoch: 0290 loss_train: 0.9226 acc_train: 0.8974 loss_val: 0.9981 acc_val: 0.8652 time: 0.0032s\nEpoch: 0291 loss_train: 0.9207 acc_train: 0.8974 loss_val: 0.9963 acc_val: 0.8658 time: 0.0032s\nEpoch: 0292 loss_train: 0.9188 acc_train: 0.8974 loss_val: 0.9944 acc_val: 0.8658 time: 0.0032s\nEpoch: 0293 loss_train: 0.9169 acc_train: 0.8974 loss_val: 0.9926 acc_val: 0.8652 time: 0.0032s\nEpoch: 0294 loss_train: 0.9150 acc_train: 0.8974 loss_val: 0.9908 acc_val: 0.8652 time: 0.0032s\nEpoch: 0295 loss_train: 0.9131 acc_train: 0.8985 loss_val: 0.9890 acc_val: 0.8652 time: 0.0032s\nEpoch: 0296 loss_train: 0.9112 acc_train: 0.8985 loss_val: 0.9872 acc_val: 0.8658 time: 0.0032s\nEpoch: 0297 loss_train: 0.9094 acc_train: 0.8996 loss_val: 0.9854 acc_val: 0.8652 time: 0.0032s\nEpoch: 0298 loss_train: 0.9075 acc_train: 0.8996 loss_val: 0.9836 acc_val: 0.8663 time: 0.0032s\nEpoch: 0299 loss_train: 0.9057 acc_train: 0.8996 loss_val: 0.9818 acc_val: 0.8674 time: 0.0032s\nEpoch: 0300 loss_train: 0.9038 acc_train: 0.8985 loss_val: 0.9801 acc_val: 0.8674 time: 0.0032s\nEpoch: 0301 loss_train: 0.9020 acc_train: 0.8985 loss_val: 0.9783 acc_val: 0.8674 time: 0.0032s\nEpoch: 0302 loss_train: 0.9002 acc_train: 0.8985 loss_val: 0.9766 acc_val: 0.8674 time: 0.0032s\nEpoch: 0303 loss_train: 0.8984 acc_train: 0.8996 loss_val: 0.9748 acc_val: 0.8674 time: 0.0032s\nEpoch: 0304 loss_train: 0.8966 acc_train: 0.8996 loss_val: 0.9731 acc_val: 0.8674 time: 0.0032s\nEpoch: 0305 loss_train: 0.8948 acc_train: 0.8996 loss_val: 0.9714 acc_val: 0.8674 time: 0.0032s\nEpoch: 0306 loss_train: 0.8931 acc_train: 0.8996 loss_val: 0.9697 acc_val: 0.8680 time: 0.0032s\nEpoch: 0307 loss_train: 0.8913 acc_train: 0.9007 loss_val: 0.9680 acc_val: 0.8691 time: 0.0032s\nEpoch: 0308 loss_train: 0.8895 acc_train: 0.9007 loss_val: 0.9663 acc_val: 0.8696 time: 0.0032s\nEpoch: 0309 loss_train: 0.8878 acc_train: 0.9007 loss_val: 0.9646 acc_val: 0.8696 time: 0.0032s\nEpoch: 0310 loss_train: 0.8860 acc_train: 0.9007 loss_val: 0.9630 acc_val: 0.8696 time: 0.0032s\nEpoch: 0311 loss_train: 0.8843 acc_train: 0.9007 loss_val: 0.9613 acc_val: 0.8696 time: 0.0032s\nEpoch: 0312 loss_train: 0.8826 acc_train: 0.9007 loss_val: 0.9596 acc_val: 0.8696 time: 0.0032s\nEpoch: 0313 loss_train: 0.8809 acc_train: 0.9007 loss_val: 0.9580 acc_val: 0.8702 time: 0.0032s\nEpoch: 0314 loss_train: 0.8792 acc_train: 0.9007 loss_val: 0.9563 acc_val: 0.8707 time: 0.0032s\nEpoch: 0315 loss_train: 0.8775 acc_train: 0.9007 loss_val: 0.9547 acc_val: 0.8712 time: 0.0032s\nEpoch: 0316 loss_train: 0.8758 acc_train: 0.9007 loss_val: 0.9531 acc_val: 0.8712 time: 0.0032s\nEpoch: 0317 loss_train: 0.8741 acc_train: 0.9007 loss_val: 0.9515 acc_val: 0.8712 time: 0.0032s\nEpoch: 0318 loss_train: 0.8725 acc_train: 0.9007 loss_val: 0.9499 acc_val: 0.8712 time: 0.0032s\nEpoch: 0319 loss_train: 0.8708 acc_train: 0.9007 loss_val: 0.9483 acc_val: 0.8712 time: 0.0032s\nEpoch: 0320 loss_train: 0.8692 acc_train: 0.9007 loss_val: 0.9467 acc_val: 0.8718 time: 0.0032s\nEpoch: 0321 loss_train: 0.8675 acc_train: 0.9007 loss_val: 0.9451 acc_val: 0.8718 time: 0.0032s\nEpoch: 0322 loss_train: 0.8659 acc_train: 0.9007 loss_val: 0.9435 acc_val: 0.8718 time: 0.0032s\nEpoch: 0323 loss_train: 0.8643 acc_train: 0.9007 loss_val: 0.9420 acc_val: 0.8718 time: 0.0032s\nEpoch: 0324 loss_train: 0.8626 acc_train: 0.9028 loss_val: 0.9404 acc_val: 0.8718 time: 0.0032s\nEpoch: 0325 loss_train: 0.8610 acc_train: 0.9028 loss_val: 0.9389 acc_val: 0.8723 time: 0.0032s\nEpoch: 0326 loss_train: 0.8594 acc_train: 0.9028 loss_val: 0.9373 acc_val: 0.8723 time: 0.0032s\nEpoch: 0327 loss_train: 0.8578 acc_train: 0.9028 loss_val: 0.9358 acc_val: 0.8723 time: 0.0032s\nEpoch: 0328 loss_train: 0.8563 acc_train: 0.9028 loss_val: 0.9343 acc_val: 0.8729 time: 0.0032s\nEpoch: 0329 loss_train: 0.8547 acc_train: 0.9028 loss_val: 0.9328 acc_val: 0.8723 time: 0.0032s\nEpoch: 0330 loss_train: 0.8531 acc_train: 0.9028 loss_val: 0.9312 acc_val: 0.8723 time: 0.0032s\nEpoch: 0331 loss_train: 0.8516 acc_train: 0.9039 loss_val: 0.9297 acc_val: 0.8723 time: 0.0032s\nEpoch: 0332 loss_train: 0.8500 acc_train: 0.9039 loss_val: 0.9282 acc_val: 0.8723 time: 0.0032s\nEpoch: 0333 loss_train: 0.8485 acc_train: 0.9039 loss_val: 0.9268 acc_val: 0.8723 time: 0.0032s\nEpoch: 0334 loss_train: 0.8469 acc_train: 0.9039 loss_val: 0.9253 acc_val: 0.8723 time: 0.0032s\nEpoch: 0335 loss_train: 0.8454 acc_train: 0.9039 loss_val: 0.9238 acc_val: 0.8723 time: 0.0032s\nEpoch: 0336 loss_train: 0.8439 acc_train: 0.9039 loss_val: 0.9223 acc_val: 0.8723 time: 0.0032s\nEpoch: 0337 loss_train: 0.8424 acc_train: 0.9050 loss_val: 0.9209 acc_val: 0.8723 time: 0.0032s\nEpoch: 0338 loss_train: 0.8409 acc_train: 0.9050 loss_val: 0.9194 acc_val: 0.8723 time: 0.0032s\nEpoch: 0339 loss_train: 0.8394 acc_train: 0.9050 loss_val: 0.9180 acc_val: 0.8723 time: 0.0032s\nEpoch: 0340 loss_train: 0.8379 acc_train: 0.9050 loss_val: 0.9165 acc_val: 0.8723 time: 0.0032s\nEpoch: 0341 loss_train: 0.8364 acc_train: 0.9050 loss_val: 0.9151 acc_val: 0.8723 time: 0.0032s\nEpoch: 0342 loss_train: 0.8349 acc_train: 0.9050 loss_val: 0.9137 acc_val: 0.8729 time: 0.0032s\nEpoch: 0343 loss_train: 0.8335 acc_train: 0.9050 loss_val: 0.9123 acc_val: 0.8729 time: 0.0032s\nEpoch: 0344 loss_train: 0.8320 acc_train: 0.9050 loss_val: 0.9109 acc_val: 0.8729 time: 0.0032s\nEpoch: 0345 loss_train: 0.8306 acc_train: 0.9050 loss_val: 0.9095 acc_val: 0.8729 time: 0.0032s\nEpoch: 0346 loss_train: 0.8291 acc_train: 0.9061 loss_val: 0.9081 acc_val: 0.8729 time: 0.0032s\nEpoch: 0347 loss_train: 0.8277 acc_train: 0.9061 loss_val: 0.9067 acc_val: 0.8729 time: 0.0032s\nEpoch: 0348 loss_train: 0.8262 acc_train: 0.9061 loss_val: 0.9053 acc_val: 0.8729 time: 0.0032s\nEpoch: 0349 loss_train: 0.8248 acc_train: 0.9061 loss_val: 0.9039 acc_val: 0.8729 time: 0.0032s\nEpoch: 0350 loss_train: 0.8234 acc_train: 0.9061 loss_val: 0.9025 acc_val: 0.8729 time: 0.0032s\nEpoch: 0351 loss_train: 0.8220 acc_train: 0.9061 loss_val: 0.9012 acc_val: 0.8729 time: 0.0032s\nEpoch: 0352 loss_train: 0.8206 acc_train: 0.9061 loss_val: 0.8998 acc_val: 0.8734 time: 0.0032s\nEpoch: 0353 loss_train: 0.8192 acc_train: 0.9061 loss_val: 0.8985 acc_val: 0.8734 time: 0.0032s\nEpoch: 0354 loss_train: 0.8178 acc_train: 0.9061 loss_val: 0.8971 acc_val: 0.8734 time: 0.0032s\nEpoch: 0355 loss_train: 0.8164 acc_train: 0.9061 loss_val: 0.8958 acc_val: 0.8734 time: 0.0032s\nEpoch: 0356 loss_train: 0.8151 acc_train: 0.9061 loss_val: 0.8945 acc_val: 0.8734 time: 0.0032s\nEpoch: 0357 loss_train: 0.8137 acc_train: 0.9061 loss_val: 0.8931 acc_val: 0.8740 time: 0.0032s\nEpoch: 0358 loss_train: 0.8123 acc_train: 0.9061 loss_val: 0.8918 acc_val: 0.8740 time: 0.0032s\nEpoch: 0359 loss_train: 0.8110 acc_train: 0.9061 loss_val: 0.8905 acc_val: 0.8745 time: 0.0032s\nEpoch: 0360 loss_train: 0.8096 acc_train: 0.9061 loss_val: 0.8892 acc_val: 0.8745 time: 0.0032s\nEpoch: 0361 loss_train: 0.8083 acc_train: 0.9061 loss_val: 0.8879 acc_val: 0.8745 time: 0.0032s\nEpoch: 0362 loss_train: 0.8069 acc_train: 0.9061 loss_val: 0.8866 acc_val: 0.8745 time: 0.0032s\nEpoch: 0363 loss_train: 0.8056 acc_train: 0.9061 loss_val: 0.8853 acc_val: 0.8745 time: 0.0032s\nEpoch: 0364 loss_train: 0.8043 acc_train: 0.9061 loss_val: 0.8840 acc_val: 0.8745 time: 0.0032s\nEpoch: 0365 loss_train: 0.8030 acc_train: 0.9061 loss_val: 0.8828 acc_val: 0.8751 time: 0.0032s\nEpoch: 0366 loss_train: 0.8017 acc_train: 0.9061 loss_val: 0.8815 acc_val: 0.8751 time: 0.0032s\nEpoch: 0367 loss_train: 0.8004 acc_train: 0.9061 loss_val: 0.8802 acc_val: 0.8762 time: 0.0032s\nEpoch: 0368 loss_train: 0.7991 acc_train: 0.9061 loss_val: 0.8790 acc_val: 0.8762 time: 0.0032s\nEpoch: 0369 loss_train: 0.7978 acc_train: 0.9061 loss_val: 0.8777 acc_val: 0.8762 time: 0.0032s\nEpoch: 0370 loss_train: 0.7965 acc_train: 0.9072 loss_val: 0.8765 acc_val: 0.8762 time: 0.0032s\nEpoch: 0371 loss_train: 0.7952 acc_train: 0.9072 loss_val: 0.8752 acc_val: 0.8767 time: 0.0032s\nEpoch: 0372 loss_train: 0.7939 acc_train: 0.9072 loss_val: 0.8740 acc_val: 0.8767 time: 0.0032s\nEpoch: 0373 loss_train: 0.7927 acc_train: 0.9072 loss_val: 0.8728 acc_val: 0.8767 time: 0.0032s\nEpoch: 0374 loss_train: 0.7914 acc_train: 0.9072 loss_val: 0.8715 acc_val: 0.8773 time: 0.0032s\nEpoch: 0375 loss_train: 0.7901 acc_train: 0.9072 loss_val: 0.8703 acc_val: 0.8773 time: 0.0032s\nEpoch: 0376 loss_train: 0.7889 acc_train: 0.9072 loss_val: 0.8691 acc_val: 0.8773 time: 0.0032s\nEpoch: 0377 loss_train: 0.7877 acc_train: 0.9072 loss_val: 0.8679 acc_val: 0.8773 time: 0.0032s\nEpoch: 0378 loss_train: 0.7864 acc_train: 0.9072 loss_val: 0.8667 acc_val: 0.8773 time: 0.0032s\nEpoch: 0379 loss_train: 0.7852 acc_train: 0.9083 loss_val: 0.8655 acc_val: 0.8767 time: 0.0032s\nEpoch: 0380 loss_train: 0.7840 acc_train: 0.9094 loss_val: 0.8643 acc_val: 0.8767 time: 0.0032s\nEpoch: 0381 loss_train: 0.7827 acc_train: 0.9094 loss_val: 0.8631 acc_val: 0.8767 time: 0.0032s\nEpoch: 0382 loss_train: 0.7815 acc_train: 0.9094 loss_val: 0.8620 acc_val: 0.8767 time: 0.0032s\nEpoch: 0383 loss_train: 0.7803 acc_train: 0.9094 loss_val: 0.8608 acc_val: 0.8767 time: 0.0032s\nEpoch: 0384 loss_train: 0.7791 acc_train: 0.9105 loss_val: 0.8596 acc_val: 0.8767 time: 0.0032s\nEpoch: 0385 loss_train: 0.7779 acc_train: 0.9105 loss_val: 0.8585 acc_val: 0.8773 time: 0.0032s\nEpoch: 0386 loss_train: 0.7767 acc_train: 0.9105 loss_val: 0.8573 acc_val: 0.8778 time: 0.0032s\nEpoch: 0387 loss_train: 0.7755 acc_train: 0.9105 loss_val: 0.8562 acc_val: 0.8783 time: 0.0032s\nEpoch: 0388 loss_train: 0.7744 acc_train: 0.9105 loss_val: 0.8550 acc_val: 0.8783 time: 0.0032s\nEpoch: 0389 loss_train: 0.7732 acc_train: 0.9105 loss_val: 0.8539 acc_val: 0.8783 time: 0.0032s\nEpoch: 0390 loss_train: 0.7720 acc_train: 0.9105 loss_val: 0.8527 acc_val: 0.8783 time: 0.0032s\nEpoch: 0391 loss_train: 0.7708 acc_train: 0.9105 loss_val: 0.8516 acc_val: 0.8783 time: 0.0032s\nEpoch: 0392 loss_train: 0.7697 acc_train: 0.9105 loss_val: 0.8505 acc_val: 0.8783 time: 0.0032s\nEpoch: 0393 loss_train: 0.7685 acc_train: 0.9105 loss_val: 0.8493 acc_val: 0.8783 time: 0.0032s\nEpoch: 0394 loss_train: 0.7674 acc_train: 0.9105 loss_val: 0.8482 acc_val: 0.8783 time: 0.0032s\nEpoch: 0395 loss_train: 0.7662 acc_train: 0.9105 loss_val: 0.8471 acc_val: 0.8783 time: 0.0032s\nEpoch: 0396 loss_train: 0.7651 acc_train: 0.9105 loss_val: 0.8460 acc_val: 0.8783 time: 0.0032s\nEpoch: 0397 loss_train: 0.7640 acc_train: 0.9105 loss_val: 0.8449 acc_val: 0.8783 time: 0.0032s\nEpoch: 0398 loss_train: 0.7628 acc_train: 0.9105 loss_val: 0.8438 acc_val: 0.8789 time: 0.0032s\nEpoch: 0399 loss_train: 0.7617 acc_train: 0.9105 loss_val: 0.8427 acc_val: 0.8794 time: 0.0032s\nEpoch: 0400 loss_train: 0.7606 acc_train: 0.9105 loss_val: 0.8416 acc_val: 0.8794 time: 0.0032s\nEpoch: 0401 loss_train: 0.7595 acc_train: 0.9105 loss_val: 0.8405 acc_val: 0.8794 time: 0.0032s\nEpoch: 0402 loss_train: 0.7584 acc_train: 0.9105 loss_val: 0.8395 acc_val: 0.8794 time: 0.0068s\nEpoch: 0403 loss_train: 0.7573 acc_train: 0.9105 loss_val: 0.8384 acc_val: 0.8794 time: 0.0032s\nEpoch: 0404 loss_train: 0.7562 acc_train: 0.9105 loss_val: 0.8373 acc_val: 0.8794 time: 0.0032s\nEpoch: 0405 loss_train: 0.7551 acc_train: 0.9105 loss_val: 0.8363 acc_val: 0.8794 time: 0.0032s\nEpoch: 0406 loss_train: 0.7540 acc_train: 0.9105 loss_val: 0.8352 acc_val: 0.8794 time: 0.0032s\nEpoch: 0407 loss_train: 0.7529 acc_train: 0.9116 loss_val: 0.8341 acc_val: 0.8794 time: 0.0032s\nEpoch: 0408 loss_train: 0.7518 acc_train: 0.9138 loss_val: 0.8331 acc_val: 0.8794 time: 0.0032s\nEpoch: 0409 loss_train: 0.7507 acc_train: 0.9138 loss_val: 0.8321 acc_val: 0.8789 time: 0.0032s\nEpoch: 0410 loss_train: 0.7497 acc_train: 0.9148 loss_val: 0.8310 acc_val: 0.8789 time: 0.0032s\nEpoch: 0411 loss_train: 0.7486 acc_train: 0.9148 loss_val: 0.8300 acc_val: 0.8794 time: 0.0032s\nEpoch: 0412 loss_train: 0.7476 acc_train: 0.9148 loss_val: 0.8289 acc_val: 0.8800 time: 0.0032s\nEpoch: 0413 loss_train: 0.7465 acc_train: 0.9148 loss_val: 0.8279 acc_val: 0.8800 time: 0.0032s\nEpoch: 0414 loss_train: 0.7454 acc_train: 0.9148 loss_val: 0.8269 acc_val: 0.8800 time: 0.0032s\nEpoch: 0415 loss_train: 0.7444 acc_train: 0.9148 loss_val: 0.8259 acc_val: 0.8800 time: 0.0032s\nEpoch: 0416 loss_train: 0.7434 acc_train: 0.9138 loss_val: 0.8249 acc_val: 0.8805 time: 0.0032s\nEpoch: 0417 loss_train: 0.7423 acc_train: 0.9138 loss_val: 0.8239 acc_val: 0.8811 time: 0.0032s\nEpoch: 0418 loss_train: 0.7413 acc_train: 0.9148 loss_val: 0.8228 acc_val: 0.8816 time: 0.0032s\nEpoch: 0419 loss_train: 0.7403 acc_train: 0.9148 loss_val: 0.8218 acc_val: 0.8816 time: 0.0032s\nEpoch: 0420 loss_train: 0.7392 acc_train: 0.9138 loss_val: 0.8208 acc_val: 0.8816 time: 0.0032s\nEpoch: 0421 loss_train: 0.7382 acc_train: 0.9138 loss_val: 0.8199 acc_val: 0.8816 time: 0.0032s\nEpoch: 0422 loss_train: 0.7372 acc_train: 0.9138 loss_val: 0.8189 acc_val: 0.8816 time: 0.0032s\nEpoch: 0423 loss_train: 0.7362 acc_train: 0.9138 loss_val: 0.8179 acc_val: 0.8816 time: 0.0032s\nEpoch: 0424 loss_train: 0.7352 acc_train: 0.9138 loss_val: 0.8169 acc_val: 0.8816 time: 0.0032s\nEpoch: 0425 loss_train: 0.7342 acc_train: 0.9138 loss_val: 0.8159 acc_val: 0.8816 time: 0.0032s\nEpoch: 0426 loss_train: 0.7332 acc_train: 0.9138 loss_val: 0.8150 acc_val: 0.8822 time: 0.0032s\nEpoch: 0427 loss_train: 0.7322 acc_train: 0.9138 loss_val: 0.8140 acc_val: 0.8822 time: 0.0032s\nEpoch: 0428 loss_train: 0.7312 acc_train: 0.9148 loss_val: 0.8130 acc_val: 0.8822 time: 0.0032s\nEpoch: 0429 loss_train: 0.7302 acc_train: 0.9148 loss_val: 0.8121 acc_val: 0.8822 time: 0.0032s\nEpoch: 0430 loss_train: 0.7293 acc_train: 0.9148 loss_val: 0.8111 acc_val: 0.8822 time: 0.0032s\nEpoch: 0431 loss_train: 0.7283 acc_train: 0.9148 loss_val: 0.8102 acc_val: 0.8822 time: 0.0032s\nEpoch: 0432 loss_train: 0.7273 acc_train: 0.9148 loss_val: 0.8092 acc_val: 0.8822 time: 0.0032s\nEpoch: 0433 loss_train: 0.7263 acc_train: 0.9148 loss_val: 0.8083 acc_val: 0.8822 time: 0.0032s\nEpoch: 0434 loss_train: 0.7254 acc_train: 0.9148 loss_val: 0.8073 acc_val: 0.8827 time: 0.0032s\nEpoch: 0435 loss_train: 0.7244 acc_train: 0.9148 loss_val: 0.8064 acc_val: 0.8827 time: 0.0032s\nEpoch: 0436 loss_train: 0.7235 acc_train: 0.9148 loss_val: 0.8055 acc_val: 0.8833 time: 0.0032s\nEpoch: 0437 loss_train: 0.7225 acc_train: 0.9148 loss_val: 0.8045 acc_val: 0.8833 time: 0.0032s\nEpoch: 0438 loss_train: 0.7216 acc_train: 0.9148 loss_val: 0.8036 acc_val: 0.8833 time: 0.0032s\nEpoch: 0439 loss_train: 0.7206 acc_train: 0.9159 loss_val: 0.8027 acc_val: 0.8833 time: 0.0032s\nEpoch: 0440 loss_train: 0.7197 acc_train: 0.9159 loss_val: 0.8018 acc_val: 0.8833 time: 0.0032s\nEpoch: 0441 loss_train: 0.7187 acc_train: 0.9159 loss_val: 0.8009 acc_val: 0.8833 time: 0.0032s\nEpoch: 0442 loss_train: 0.7178 acc_train: 0.9159 loss_val: 0.7999 acc_val: 0.8838 time: 0.0032s\nEpoch: 0443 loss_train: 0.7169 acc_train: 0.9159 loss_val: 0.7990 acc_val: 0.8838 time: 0.0032s\nEpoch: 0444 loss_train: 0.7160 acc_train: 0.9159 loss_val: 0.7981 acc_val: 0.8838 time: 0.0032s\nEpoch: 0445 loss_train: 0.7150 acc_train: 0.9159 loss_val: 0.7972 acc_val: 0.8838 time: 0.0032s\nEpoch: 0446 loss_train: 0.7141 acc_train: 0.9159 loss_val: 0.7963 acc_val: 0.8838 time: 0.0032s\nEpoch: 0447 loss_train: 0.7132 acc_train: 0.9159 loss_val: 0.7955 acc_val: 0.8838 time: 0.0032s\nEpoch: 0448 loss_train: 0.7123 acc_train: 0.9159 loss_val: 0.7946 acc_val: 0.8838 time: 0.0032s\nEpoch: 0449 loss_train: 0.7114 acc_train: 0.9159 loss_val: 0.7937 acc_val: 0.8838 time: 0.0032s\nEpoch: 0450 loss_train: 0.7105 acc_train: 0.9159 loss_val: 0.7928 acc_val: 0.8838 time: 0.0032s\nEpoch: 0451 loss_train: 0.7096 acc_train: 0.9159 loss_val: 0.7919 acc_val: 0.8838 time: 0.0032s\nEpoch: 0452 loss_train: 0.7087 acc_train: 0.9170 loss_val: 0.7910 acc_val: 0.8838 time: 0.0032s\nEpoch: 0453 loss_train: 0.7078 acc_train: 0.9170 loss_val: 0.7902 acc_val: 0.8838 time: 0.0032s\nEpoch: 0454 loss_train: 0.7069 acc_train: 0.9170 loss_val: 0.7893 acc_val: 0.8838 time: 0.0032s\nEpoch: 0455 loss_train: 0.7061 acc_train: 0.9170 loss_val: 0.7885 acc_val: 0.8838 time: 0.0032s\nEpoch: 0456 loss_train: 0.7052 acc_train: 0.9181 loss_val: 0.7876 acc_val: 0.8838 time: 0.0032s\nEpoch: 0457 loss_train: 0.7043 acc_train: 0.9181 loss_val: 0.7867 acc_val: 0.8838 time: 0.0032s\nEpoch: 0458 loss_train: 0.7034 acc_train: 0.9181 loss_val: 0.7859 acc_val: 0.8843 time: 0.0032s\nEpoch: 0459 loss_train: 0.7026 acc_train: 0.9181 loss_val: 0.7850 acc_val: 0.8843 time: 0.0032s\nEpoch: 0460 loss_train: 0.7017 acc_train: 0.9181 loss_val: 0.7842 acc_val: 0.8849 time: 0.0032s\nEpoch: 0461 loss_train: 0.7008 acc_train: 0.9181 loss_val: 0.7833 acc_val: 0.8849 time: 0.0032s\nEpoch: 0462 loss_train: 0.7000 acc_train: 0.9181 loss_val: 0.7825 acc_val: 0.8849 time: 0.0032s\nEpoch: 0463 loss_train: 0.6991 acc_train: 0.9181 loss_val: 0.7817 acc_val: 0.8854 time: 0.0032s\nEpoch: 0464 loss_train: 0.6983 acc_train: 0.9181 loss_val: 0.7808 acc_val: 0.8854 time: 0.0032s\nEpoch: 0465 loss_train: 0.6974 acc_train: 0.9181 loss_val: 0.7800 acc_val: 0.8854 time: 0.0032s\nEpoch: 0466 loss_train: 0.6966 acc_train: 0.9181 loss_val: 0.7792 acc_val: 0.8854 time: 0.0032s\nEpoch: 0467 loss_train: 0.6957 acc_train: 0.9181 loss_val: 0.7784 acc_val: 0.8854 time: 0.0032s\nEpoch: 0468 loss_train: 0.6949 acc_train: 0.9192 loss_val: 0.7775 acc_val: 0.8849 time: 0.0032s\nEpoch: 0469 loss_train: 0.6941 acc_train: 0.9192 loss_val: 0.7767 acc_val: 0.8849 time: 0.0032s\nEpoch: 0470 loss_train: 0.6932 acc_train: 0.9192 loss_val: 0.7759 acc_val: 0.8854 time: 0.0032s\nEpoch: 0471 loss_train: 0.6924 acc_train: 0.9192 loss_val: 0.7751 acc_val: 0.8854 time: 0.0032s\nEpoch: 0472 loss_train: 0.6916 acc_train: 0.9192 loss_val: 0.7743 acc_val: 0.8854 time: 0.0032s\nEpoch: 0473 loss_train: 0.6908 acc_train: 0.9192 loss_val: 0.7735 acc_val: 0.8854 time: 0.0032s\nEpoch: 0474 loss_train: 0.6900 acc_train: 0.9192 loss_val: 0.7727 acc_val: 0.8854 time: 0.0032s\nEpoch: 0475 loss_train: 0.6891 acc_train: 0.9192 loss_val: 0.7719 acc_val: 0.8860 time: 0.0032s\nEpoch: 0476 loss_train: 0.6883 acc_train: 0.9192 loss_val: 0.7711 acc_val: 0.8860 time: 0.0032s\nEpoch: 0477 loss_train: 0.6875 acc_train: 0.9192 loss_val: 0.7703 acc_val: 0.8860 time: 0.0032s\nEpoch: 0478 loss_train: 0.6867 acc_train: 0.9192 loss_val: 0.7695 acc_val: 0.8860 time: 0.0032s\nEpoch: 0479 loss_train: 0.6859 acc_train: 0.9192 loss_val: 0.7687 acc_val: 0.8871 time: 0.0032s\nEpoch: 0480 loss_train: 0.6851 acc_train: 0.9192 loss_val: 0.7680 acc_val: 0.8871 time: 0.0032s\nEpoch: 0481 loss_train: 0.6843 acc_train: 0.9192 loss_val: 0.7672 acc_val: 0.8871 time: 0.0032s\nEpoch: 0482 loss_train: 0.6835 acc_train: 0.9192 loss_val: 0.7664 acc_val: 0.8871 time: 0.0032s\nEpoch: 0483 loss_train: 0.6828 acc_train: 0.9192 loss_val: 0.7656 acc_val: 0.8871 time: 0.0032s\nEpoch: 0484 loss_train: 0.6820 acc_train: 0.9203 loss_val: 0.7649 acc_val: 0.8871 time: 0.0032s\nEpoch: 0485 loss_train: 0.6812 acc_train: 0.9203 loss_val: 0.7641 acc_val: 0.8876 time: 0.0032s\nEpoch: 0486 loss_train: 0.6804 acc_train: 0.9203 loss_val: 0.7633 acc_val: 0.8876 time: 0.0032s\nEpoch: 0487 loss_train: 0.6796 acc_train: 0.9203 loss_val: 0.7626 acc_val: 0.8876 time: 0.0032s\nEpoch: 0488 loss_train: 0.6789 acc_train: 0.9203 loss_val: 0.7618 acc_val: 0.8876 time: 0.0032s\nEpoch: 0489 loss_train: 0.6781 acc_train: 0.9214 loss_val: 0.7611 acc_val: 0.8876 time: 0.0032s\nEpoch: 0490 loss_train: 0.6773 acc_train: 0.9214 loss_val: 0.7603 acc_val: 0.8876 time: 0.0032s\nEpoch: 0491 loss_train: 0.6766 acc_train: 0.9214 loss_val: 0.7596 acc_val: 0.8876 time: 0.0032s\nEpoch: 0492 loss_train: 0.6758 acc_train: 0.9214 loss_val: 0.7588 acc_val: 0.8876 time: 0.0032s\nEpoch: 0493 loss_train: 0.6750 acc_train: 0.9214 loss_val: 0.7581 acc_val: 0.8876 time: 0.0032s\nEpoch: 0494 loss_train: 0.6743 acc_train: 0.9214 loss_val: 0.7573 acc_val: 0.8882 time: 0.0032s\nEpoch: 0495 loss_train: 0.6735 acc_train: 0.9214 loss_val: 0.7566 acc_val: 0.8882 time: 0.0032s\nEpoch: 0496 loss_train: 0.6728 acc_train: 0.9214 loss_val: 0.7559 acc_val: 0.8882 time: 0.0032s\nEpoch: 0497 loss_train: 0.6720 acc_train: 0.9225 loss_val: 0.7551 acc_val: 0.8882 time: 0.0032s\nEpoch: 0498 loss_train: 0.6713 acc_train: 0.9225 loss_val: 0.7544 acc_val: 0.8893 time: 0.0032s\nEpoch: 0499 loss_train: 0.6705 acc_train: 0.9225 loss_val: 0.7537 acc_val: 0.8893 time: 0.0032s\nEpoch: 0500 loss_train: 0.6698 acc_train: 0.9225 loss_val: 0.7529 acc_val: 0.8898 time: 0.0032s\nEpoch: 0001 loss_train: 0.6691 acc_train: 0.9225 loss_val: 0.7529 acc_val: 0.8898 time: 0.0030s\nRanking optimizing... \nNow Average NDCG@k =  0.7403905391693115\nEpoch: 0002 loss_train: 0.6684 acc_train: 0.9225 loss_val: 0.7521 acc_val: 0.8898 time: 0.0052s\nRanking optimizing... \nNow Average NDCG@k =  0.7405476570129395\nEpoch: 0003 loss_train: 0.6677 acc_train: 0.9225 loss_val: 0.7513 acc_val: 0.8898 time: 0.0043s\nRanking optimizing... \nNow Average NDCG@k =  0.7408432364463806\nEpoch: 0004 loss_train: 0.6671 acc_train: 0.9214 loss_val: 0.7505 acc_val: 0.8909 time: 0.0037s\nRanking optimizing... \nNow Average NDCG@k =  0.7412011623382568\nEpoch: 0005 loss_train: 0.6665 acc_train: 0.9214 loss_val: 0.7498 acc_val: 0.8914 time: 0.0049s\nRanking optimizing... \nNow Average NDCG@k =  0.7416362166404724\nEpoch: 0006 loss_train: 0.6660 acc_train: 0.9214 loss_val: 0.7491 acc_val: 0.8903 time: 0.0041s\nRanking optimizing... \nNow Average NDCG@k =  0.7420823574066162\nEpoch: 0007 loss_train: 0.6656 acc_train: 0.9214 loss_val: 0.7485 acc_val: 0.8898 time: 0.0046s\nRanking optimizing... \nNow Average NDCG@k =  0.7425470948219299\nEpoch: 0008 loss_train: 0.6652 acc_train: 0.9214 loss_val: 0.7480 acc_val: 0.8893 time: 0.0044s\nRanking optimizing... \nNow Average NDCG@k =  0.7430533170700073\nEpoch: 0009 loss_train: 0.6649 acc_train: 0.9214 loss_val: 0.7475 acc_val: 0.8893 time: 0.0042s\nRanking optimizing... \nNow Average NDCG@k =  0.7436717748641968\nEpoch: 0010 loss_train: 0.6647 acc_train: 0.9236 loss_val: 0.7472 acc_val: 0.8909 time: 0.0040s\nRanking optimizing... \nNow Average NDCG@k =  0.744343638420105\nEpoch: 0011 loss_train: 0.6645 acc_train: 0.9258 loss_val: 0.7469 acc_val: 0.8920 time: 0.0043s\nRanking optimizing... \nNow Average NDCG@k =  0.7449952960014343\nEpoch: 0012 loss_train: 0.6643 acc_train: 0.9269 loss_val: 0.7466 acc_val: 0.8925 time: 0.0044s\nRanking optimizing... \nNow Average NDCG@k =  0.7455838322639465\nEpoch: 0013 loss_train: 0.6642 acc_train: 0.9258 loss_val: 0.7465 acc_val: 0.8920 time: 0.0044s\nRanking optimizing... \nNow Average NDCG@k =  0.7463658452033997\nEpoch: 0014 loss_train: 0.6641 acc_train: 0.9247 loss_val: 0.7464 acc_val: 0.8931 time: 0.0042s\nRanking optimizing... \nNow Average NDCG@k =  0.7471101880073547\nEpoch: 0015 loss_train: 0.6641 acc_train: 0.9247 loss_val: 0.7463 acc_val: 0.8925 time: 0.0043s\nRanking optimizing... \nNow Average NDCG@k =  0.7478619813919067\nEpoch: 0016 loss_train: 0.6642 acc_train: 0.9247 loss_val: 0.7464 acc_val: 0.8920 time: 0.0045s\nRanking optimizing... \nNow Average NDCG@k =  0.748491108417511\nEpoch: 0017 loss_train: 0.6644 acc_train: 0.9247 loss_val: 0.7465 acc_val: 0.8931 time: 0.0040s\nRanking optimizing... \nNow Average NDCG@k =  0.7490537762641907\nEpoch: 0018 loss_train: 0.6646 acc_train: 0.9258 loss_val: 0.7467 acc_val: 0.8925 time: 0.0042s\nRanking optimizing... \nNow Average NDCG@k =  0.7496964931488037\nEpoch: 0019 loss_train: 0.6649 acc_train: 0.9258 loss_val: 0.7468 acc_val: 0.8936 time: 0.0041s\nRanking optimizing... \nNow Average NDCG@k =  0.7503882050514221\nEpoch: 0020 loss_train: 0.6653 acc_train: 0.9269 loss_val: 0.7470 acc_val: 0.8925 time: 0.0038s\nRanking optimizing... \nNow Average NDCG@k =  0.7510835528373718\nEpoch: 0021 loss_train: 0.6656 acc_train: 0.9279 loss_val: 0.7472 acc_val: 0.8925 time: 0.0041s\nRanking optimizing... \nNow Average NDCG@k =  0.7517444491386414\nEpoch: 0022 loss_train: 0.6660 acc_train: 0.9290 loss_val: 0.7473 acc_val: 0.8942 time: 0.0039s\nRanking optimizing... \nNow Average NDCG@k =  0.7524380087852478\nEpoch: 0023 loss_train: 0.6663 acc_train: 0.9290 loss_val: 0.7474 acc_val: 0.8958 time: 0.0042s\nRanking optimizing... \nNow Average NDCG@k =  0.7533292174339294\nEpoch: 0024 loss_train: 0.6667 acc_train: 0.9301 loss_val: 0.7474 acc_val: 0.8963 time: 0.0041s\nRanking optimizing... \nNow Average NDCG@k =  0.7541739344596863\nEpoch: 0025 loss_train: 0.6670 acc_train: 0.9301 loss_val: 0.7475 acc_val: 0.8980 time: 0.0044s\nRanking optimizing... \nNow Average NDCG@k =  0.7548393607139587\nEpoch: 0026 loss_train: 0.6673 acc_train: 0.9301 loss_val: 0.7474 acc_val: 0.8969 time: 0.0051s\nRanking optimizing... \nNow Average NDCG@k =  0.755466103553772\nEpoch: 0027 loss_train: 0.6676 acc_train: 0.9290 loss_val: 0.7472 acc_val: 0.8974 time: 0.0041s\nRanking optimizing... \nNow Average NDCG@k =  0.7562322616577148\nEpoch: 0028 loss_train: 0.6677 acc_train: 0.9301 loss_val: 0.7471 acc_val: 0.8974 time: 0.0043s\nRanking optimizing... \nNow Average NDCG@k =  0.7570379376411438\nEpoch: 0029 loss_train: 0.6678 acc_train: 0.9301 loss_val: 0.7468 acc_val: 0.8980 time: 0.0043s\nRanking optimizing... \nNow Average NDCG@k =  0.7576237916946411\nEpoch: 0030 loss_train: 0.6677 acc_train: 0.9312 loss_val: 0.7466 acc_val: 0.8980 time: 0.0040s\nRanking optimizing... \nNow Average NDCG@k =  0.75829017162323\nEpoch: 0031 loss_train: 0.6677 acc_train: 0.9312 loss_val: 0.7463 acc_val: 0.8980 time: 0.0041s\nRanking optimizing... \nNow Average NDCG@k =  0.7589644193649292\nEpoch: 0032 loss_train: 0.6676 acc_train: 0.9312 loss_val: 0.7461 acc_val: 0.8980 time: 0.0038s\nRanking optimizing... \nNow Average NDCG@k =  0.7595926523208618\nEpoch: 0033 loss_train: 0.6675 acc_train: 0.9301 loss_val: 0.7459 acc_val: 0.8980 time: 0.0042s\nRanking optimizing... \nNow Average NDCG@k =  0.7601405382156372\nEpoch: 0034 loss_train: 0.6675 acc_train: 0.9279 loss_val: 0.7458 acc_val: 0.8985 time: 0.0039s\nRanking optimizing... \nNow Average NDCG@k =  0.760871410369873\nEpoch: 0035 loss_train: 0.6675 acc_train: 0.9279 loss_val: 0.7457 acc_val: 0.8985 time: 0.0040s\nRanking optimizing... \nNow Average NDCG@k =  0.7613745331764221\nEpoch: 0036 loss_train: 0.6676 acc_train: 0.9269 loss_val: 0.7456 acc_val: 0.8985 time: 0.0040s\nRanking optimizing... \nNow Average NDCG@k =  0.7618222832679749\nEpoch: 0037 loss_train: 0.6676 acc_train: 0.9258 loss_val: 0.7455 acc_val: 0.8980 time: 0.0039s\nRanking optimizing... \nNow Average NDCG@k =  0.7622014284133911\nEpoch: 0038 loss_train: 0.6677 acc_train: 0.9247 loss_val: 0.7454 acc_val: 0.8991 time: 0.0038s\nRanking optimizing... \nNow Average NDCG@k =  0.7627370953559875\nEpoch: 0039 loss_train: 0.6678 acc_train: 0.9258 loss_val: 0.7452 acc_val: 0.9002 time: 0.0039s\nRanking optimizing... \nNow Average NDCG@k =  0.7632331252098083\nEpoch: 0040 loss_train: 0.6679 acc_train: 0.9258 loss_val: 0.7450 acc_val: 0.9007 time: 0.0037s\nRanking optimizing... \nNow Average NDCG@k =  0.7636820673942566\nTest set results: loss= 0.7671 accuracy= 0.8926\n"], ["node classification", "feature", "NDCG", "coauthor-cs", "GCN", "coauthor-cs\nTotal size :  18333\nUsing coauthor-cs dataset\nEpoch: 0001 loss_train: 2.6759 acc_train: 0.0841 loss_val: 2.6800 acc_val: 0.0551 time: 0.8811s\nRanking optimizing... \nNow Average NDCG@k =  0.257588267326355\nEpoch: 0002 loss_train: 2.6593 acc_train: 0.1266 loss_val: 2.6635 acc_val: 0.0971 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.25575315952301025\nEpoch: 0003 loss_train: 2.6434 acc_train: 0.1223 loss_val: 2.6485 acc_val: 0.0966 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.25999072194099426\nEpoch: 0004 loss_train: 2.6264 acc_train: 0.1234 loss_val: 2.6343 acc_val: 0.0966 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.2716394066810608\nEpoch: 0005 loss_train: 2.6126 acc_train: 0.1223 loss_val: 2.6194 acc_val: 0.0966 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.27752166986465454\nEpoch: 0006 loss_train: 2.5942 acc_train: 0.1223 loss_val: 2.6035 acc_val: 0.0966 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.2889925241470337\nEpoch: 0007 loss_train: 2.5770 acc_train: 0.1223 loss_val: 2.5869 acc_val: 0.0966 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.29808342456817627\nEpoch: 0008 loss_train: 2.5604 acc_train: 0.1234 loss_val: 2.5695 acc_val: 0.0966 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.3053966164588928\nEpoch: 0009 loss_train: 2.5376 acc_train: 0.1245 loss_val: 2.5514 acc_val: 0.0966 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.312385231256485\nEpoch: 0010 loss_train: 2.5188 acc_train: 0.1223 loss_val: 2.5327 acc_val: 0.0966 time: 0.0120s\nRanking optimizing... \nNow Average NDCG@k =  0.31923994421958923\nEpoch: 0011 loss_train: 2.4983 acc_train: 0.1234 loss_val: 2.5133 acc_val: 0.0966 time: 0.0105s\nRanking optimizing... \nNow Average NDCG@k =  0.3234022259712219\nEpoch: 0012 loss_train: 2.4762 acc_train: 0.1255 loss_val: 2.4935 acc_val: 0.0966 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.3293176293373108\nEpoch: 0013 loss_train: 2.4559 acc_train: 0.1277 loss_val: 2.4730 acc_val: 0.0966 time: 0.0108s\nRanking optimizing... \nNow Average NDCG@k =  0.3354843854904175\nEpoch: 0014 loss_train: 2.4320 acc_train: 0.1430 loss_val: 2.4521 acc_val: 0.0966 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.33758723735809326\nEpoch: 0015 loss_train: 2.4101 acc_train: 0.1517 loss_val: 2.4308 acc_val: 0.0966 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.34166011214256287\nEpoch: 0016 loss_train: 2.3884 acc_train: 0.1736 loss_val: 2.4091 acc_val: 0.1058 time: 0.0105s\nRanking optimizing... \nNow Average NDCG@k =  0.344510555267334\nEpoch: 0017 loss_train: 2.3634 acc_train: 0.1889 loss_val: 2.3871 acc_val: 0.1577 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.3450702130794525\nEpoch: 0018 loss_train: 2.3409 acc_train: 0.2500 loss_val: 2.3648 acc_val: 0.2275 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.35031282901763916\nEpoch: 0019 loss_train: 2.3130 acc_train: 0.2729 loss_val: 2.3423 acc_val: 0.2711 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.35040009021759033\nEpoch: 0020 loss_train: 2.2914 acc_train: 0.3286 loss_val: 2.3195 acc_val: 0.3093 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.3541456460952759\nEpoch: 0021 loss_train: 2.2665 acc_train: 0.3592 loss_val: 2.2964 acc_val: 0.3382 time: 0.0088s\nRanking optimizing... \nNow Average NDCG@k =  0.3582989275455475\nEpoch: 0022 loss_train: 2.2466 acc_train: 0.3930 loss_val: 2.2730 acc_val: 0.3917 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.3585122227668762\nEpoch: 0023 loss_train: 2.2220 acc_train: 0.4170 loss_val: 2.2492 acc_val: 0.4212 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.35702741146087646\nEpoch: 0024 loss_train: 2.1975 acc_train: 0.4094 loss_val: 2.2251 acc_val: 0.4223 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.35873934626579285\nEpoch: 0025 loss_train: 2.1749 acc_train: 0.3908 loss_val: 2.2006 acc_val: 0.4135 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.36127230525016785\nEpoch: 0026 loss_train: 2.1482 acc_train: 0.3985 loss_val: 2.1755 acc_val: 0.3977 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.3642314672470093\nEpoch: 0027 loss_train: 2.1261 acc_train: 0.3450 loss_val: 2.1497 acc_val: 0.3530 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.36363694071769714\nEpoch: 0028 loss_train: 2.0959 acc_train: 0.3221 loss_val: 2.1232 acc_val: 0.3121 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.36470580101013184\nEpoch: 0029 loss_train: 2.0687 acc_train: 0.3188 loss_val: 2.0959 acc_val: 0.3006 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.36459049582481384\nEpoch: 0030 loss_train: 2.0380 acc_train: 0.3133 loss_val: 2.0677 acc_val: 0.3006 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.3663482964038849\nEpoch: 0031 loss_train: 2.0248 acc_train: 0.2969 loss_val: 2.0388 acc_val: 0.3039 time: 0.0114s\nRanking optimizing... \nNow Average NDCG@k =  0.36778947710990906\nEpoch: 0032 loss_train: 1.9829 acc_train: 0.3100 loss_val: 2.0089 acc_val: 0.3061 time: 0.0129s\nRanking optimizing... \nNow Average NDCG@k =  0.3679041862487793\nEpoch: 0033 loss_train: 1.9514 acc_train: 0.3264 loss_val: 1.9782 acc_val: 0.3121 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.3724304437637329\nEpoch: 0034 loss_train: 1.9307 acc_train: 0.3483 loss_val: 1.9467 acc_val: 0.3208 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.3719712495803833\nEpoch: 0035 loss_train: 1.8950 acc_train: 0.3635 loss_val: 1.9143 acc_val: 0.3372 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.37208688259124756\nEpoch: 0036 loss_train: 1.8717 acc_train: 0.3734 loss_val: 1.8812 acc_val: 0.3650 time: 0.0088s\nRanking optimizing... \nNow Average NDCG@k =  0.3736839294433594\nEpoch: 0037 loss_train: 1.8296 acc_train: 0.4061 loss_val: 1.8475 acc_val: 0.4070 time: 0.0119s\nRanking optimizing... \nNow Average NDCG@k =  0.37643784284591675\nEpoch: 0038 loss_train: 1.7995 acc_train: 0.4531 loss_val: 1.8133 acc_val: 0.4512 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.37910258769989014\nEpoch: 0039 loss_train: 1.7628 acc_train: 0.5000 loss_val: 1.7787 acc_val: 0.4921 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.37775561213493347\nEpoch: 0040 loss_train: 1.7331 acc_train: 0.5317 loss_val: 1.7439 acc_val: 0.5554 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.377706378698349\nEpoch: 0041 loss_train: 1.6913 acc_train: 0.5753 loss_val: 1.7089 acc_val: 0.6077 time: 0.0105s\nRanking optimizing... \nNow Average NDCG@k =  0.37894970178604126\nEpoch: 0042 loss_train: 1.6578 acc_train: 0.6255 loss_val: 1.6738 acc_val: 0.6345 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.3810160458087921\nEpoch: 0043 loss_train: 1.6230 acc_train: 0.6496 loss_val: 1.6388 acc_val: 0.6530 time: 0.0125s\nRanking optimizing... \nNow Average NDCG@k =  0.380739688873291\nEpoch: 0044 loss_train: 1.5887 acc_train: 0.6736 loss_val: 1.6038 acc_val: 0.6645 time: 0.0106s\nRanking optimizing... \nNow Average NDCG@k =  0.38331127166748047\nEpoch: 0045 loss_train: 1.5499 acc_train: 0.6801 loss_val: 1.5688 acc_val: 0.6781 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.3832889497280121\nEpoch: 0046 loss_train: 1.5117 acc_train: 0.6998 loss_val: 1.5339 acc_val: 0.6863 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.3847847580909729\nEpoch: 0047 loss_train: 1.4707 acc_train: 0.7162 loss_val: 1.4992 acc_val: 0.6945 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.38773518800735474\nEpoch: 0048 loss_train: 1.4407 acc_train: 0.7140 loss_val: 1.4648 acc_val: 0.6972 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.3849877715110779\nEpoch: 0049 loss_train: 1.4118 acc_train: 0.7162 loss_val: 1.4307 acc_val: 0.7043 time: 0.0106s\nRanking optimizing... \nNow Average NDCG@k =  0.38362911343574524\nEpoch: 0050 loss_train: 1.3744 acc_train: 0.7424 loss_val: 1.3970 acc_val: 0.7158 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.3859387934207916\nEpoch: 0051 loss_train: 1.3472 acc_train: 0.7424 loss_val: 1.3637 acc_val: 0.7218 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.38750159740448\nEpoch: 0052 loss_train: 1.3038 acc_train: 0.7555 loss_val: 1.3312 acc_val: 0.7272 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.388386070728302\nEpoch: 0053 loss_train: 1.2728 acc_train: 0.7478 loss_val: 1.2992 acc_val: 0.7305 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.38655292987823486\nEpoch: 0054 loss_train: 1.2348 acc_train: 0.7675 loss_val: 1.2677 acc_val: 0.7354 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.38939592242240906\nEpoch: 0055 loss_train: 1.2179 acc_train: 0.7664 loss_val: 1.2369 acc_val: 0.7452 time: 0.0128s\nRanking optimizing... \nNow Average NDCG@k =  0.38851282000541687\nEpoch: 0056 loss_train: 1.1803 acc_train: 0.7762 loss_val: 1.2067 acc_val: 0.7523 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.3869006633758545\nEpoch: 0057 loss_train: 1.1488 acc_train: 0.7806 loss_val: 1.1772 acc_val: 0.7632 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.38841602206230164\nEpoch: 0058 loss_train: 1.1305 acc_train: 0.7828 loss_val: 1.1484 acc_val: 0.7692 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.38926470279693604\nEpoch: 0059 loss_train: 1.1017 acc_train: 0.7980 loss_val: 1.1204 acc_val: 0.7741 time: 0.0108s\nRanking optimizing... \nNow Average NDCG@k =  0.38613730669021606\nEpoch: 0060 loss_train: 1.0689 acc_train: 0.7828 loss_val: 1.0932 acc_val: 0.7796 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.38772860169410706\nEpoch: 0061 loss_train: 1.0313 acc_train: 0.8057 loss_val: 1.0668 acc_val: 0.7823 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.3896771967411041\nEpoch: 0062 loss_train: 1.0340 acc_train: 0.7948 loss_val: 1.0413 acc_val: 0.7834 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.3875386714935303\nEpoch: 0063 loss_train: 0.9877 acc_train: 0.8111 loss_val: 1.0168 acc_val: 0.7872 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.388577401638031\nEpoch: 0064 loss_train: 0.9721 acc_train: 0.8057 loss_val: 0.9930 acc_val: 0.7938 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.38876795768737793\nEpoch: 0065 loss_train: 0.9458 acc_train: 0.8177 loss_val: 0.9702 acc_val: 0.7965 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.38886258006095886\nEpoch: 0066 loss_train: 0.9192 acc_train: 0.8199 loss_val: 0.9484 acc_val: 0.7992 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.38852444291114807\nEpoch: 0067 loss_train: 0.9015 acc_train: 0.8155 loss_val: 0.9269 acc_val: 0.8041 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.3881528973579407\nEpoch: 0068 loss_train: 0.8767 acc_train: 0.8188 loss_val: 0.9059 acc_val: 0.8080 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.38900792598724365\nEpoch: 0069 loss_train: 0.8625 acc_train: 0.8210 loss_val: 0.8854 acc_val: 0.8118 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.387868732213974\nEpoch: 0070 loss_train: 0.8372 acc_train: 0.8319 loss_val: 0.8654 acc_val: 0.8145 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.38951101899147034\nEpoch: 0071 loss_train: 0.8249 acc_train: 0.8352 loss_val: 0.8462 acc_val: 0.8178 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.3890523910522461\nEpoch: 0072 loss_train: 0.8016 acc_train: 0.8352 loss_val: 0.8274 acc_val: 0.8216 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.3889344036579132\nEpoch: 0073 loss_train: 0.7838 acc_train: 0.8439 loss_val: 0.8097 acc_val: 0.8276 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.39103183150291443\nEpoch: 0074 loss_train: 0.7676 acc_train: 0.8428 loss_val: 0.7928 acc_val: 0.8320 time: 0.0130s\nRanking optimizing... \nNow Average NDCG@k =  0.39145874977111816\nEpoch: 0075 loss_train: 0.7602 acc_train: 0.8395 loss_val: 0.7767 acc_val: 0.8358 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.3922424912452698\nEpoch: 0076 loss_train: 0.7481 acc_train: 0.8526 loss_val: 0.7610 acc_val: 0.8402 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.3919849693775177\nEpoch: 0077 loss_train: 0.7197 acc_train: 0.8526 loss_val: 0.7460 acc_val: 0.8440 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.39137548208236694\nEpoch: 0078 loss_train: 0.7017 acc_train: 0.8483 loss_val: 0.7321 acc_val: 0.8462 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.393608421087265\nEpoch: 0079 loss_train: 0.6827 acc_train: 0.8559 loss_val: 0.7191 acc_val: 0.8483 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.3928617238998413\nEpoch: 0080 loss_train: 0.6738 acc_train: 0.8614 loss_val: 0.7067 acc_val: 0.8489 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.3945379853248596\nEpoch: 0081 loss_train: 0.6673 acc_train: 0.8668 loss_val: 0.6952 acc_val: 0.8489 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.3946533203125\nEpoch: 0082 loss_train: 0.6617 acc_train: 0.8570 loss_val: 0.6843 acc_val: 0.8500 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.39328041672706604\nEpoch: 0083 loss_train: 0.6310 acc_train: 0.8723 loss_val: 0.6736 acc_val: 0.8505 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.39533838629722595\nEpoch: 0084 loss_train: 0.6348 acc_train: 0.8712 loss_val: 0.6633 acc_val: 0.8489 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.39406710863113403\nEpoch: 0085 loss_train: 0.6300 acc_train: 0.8734 loss_val: 0.6531 acc_val: 0.8505 time: 0.0106s\nRanking optimizing... \nNow Average NDCG@k =  0.39614400267601013\nEpoch: 0086 loss_train: 0.6017 acc_train: 0.8788 loss_val: 0.6428 acc_val: 0.8511 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.39395686984062195\nEpoch: 0087 loss_train: 0.6000 acc_train: 0.8668 loss_val: 0.6324 acc_val: 0.8532 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.3949119746685028\nEpoch: 0088 loss_train: 0.5962 acc_train: 0.8777 loss_val: 0.6221 acc_val: 0.8560 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.39484941959381104\nEpoch: 0089 loss_train: 0.5958 acc_train: 0.8679 loss_val: 0.6123 acc_val: 0.8582 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.3962302505970001\nEpoch: 0090 loss_train: 0.5734 acc_train: 0.8799 loss_val: 0.6032 acc_val: 0.8598 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.3982173204421997\nEpoch: 0091 loss_train: 0.5659 acc_train: 0.8865 loss_val: 0.5938 acc_val: 0.8625 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.39613208174705505\nEpoch: 0092 loss_train: 0.5589 acc_train: 0.8723 loss_val: 0.5846 acc_val: 0.8652 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.3985151946544647\nEpoch: 0093 loss_train: 0.5405 acc_train: 0.8952 loss_val: 0.5754 acc_val: 0.8685 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.398957759141922\nEpoch: 0094 loss_train: 0.5299 acc_train: 0.8985 loss_val: 0.5666 acc_val: 0.8723 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.3983430862426758\nEpoch: 0095 loss_train: 0.5305 acc_train: 0.8897 loss_val: 0.5580 acc_val: 0.8734 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.3983945846557617\nEpoch: 0096 loss_train: 0.5167 acc_train: 0.8908 loss_val: 0.5501 acc_val: 0.8751 time: 0.0105s\nRanking optimizing... \nNow Average NDCG@k =  0.3990706205368042\nEpoch: 0097 loss_train: 0.5046 acc_train: 0.9039 loss_val: 0.5425 acc_val: 0.8794 time: 0.0114s\nRanking optimizing... \nNow Average NDCG@k =  0.4007740318775177\nEpoch: 0098 loss_train: 0.5121 acc_train: 0.8930 loss_val: 0.5355 acc_val: 0.8805 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.4009719789028168\nEpoch: 0099 loss_train: 0.4986 acc_train: 0.8930 loss_val: 0.5290 acc_val: 0.8805 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.40056586265563965\nEpoch: 0100 loss_train: 0.4819 acc_train: 0.8996 loss_val: 0.5229 acc_val: 0.8827 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.40041089057922363\nEpoch: 0101 loss_train: 0.4859 acc_train: 0.9017 loss_val: 0.5167 acc_val: 0.8865 time: 0.0107s\nRanking optimizing... \nNow Average NDCG@k =  0.4010850787162781\nEpoch: 0102 loss_train: 0.4708 acc_train: 0.9116 loss_val: 0.5106 acc_val: 0.8893 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.40107467770576477\nEpoch: 0103 loss_train: 0.4671 acc_train: 0.8996 loss_val: 0.5047 acc_val: 0.8914 time: 0.0114s\nRanking optimizing... \nNow Average NDCG@k =  0.40229058265686035\nEpoch: 0104 loss_train: 0.4542 acc_train: 0.9094 loss_val: 0.4987 acc_val: 0.8931 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.4030981957912445\nEpoch: 0105 loss_train: 0.4691 acc_train: 0.9061 loss_val: 0.4930 acc_val: 0.8947 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.3994804918766022\nEpoch: 0106 loss_train: 0.4464 acc_train: 0.9050 loss_val: 0.4874 acc_val: 0.8969 time: 0.0107s\nRanking optimizing... \nNow Average NDCG@k =  0.4013630747795105\nEpoch: 0107 loss_train: 0.4423 acc_train: 0.9138 loss_val: 0.4820 acc_val: 0.8991 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.40353113412857056\nEpoch: 0108 loss_train: 0.4323 acc_train: 0.9061 loss_val: 0.4769 acc_val: 0.8991 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.4059153199195862\nEpoch: 0109 loss_train: 0.4165 acc_train: 0.9312 loss_val: 0.4722 acc_val: 0.8991 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.40320539474487305\nEpoch: 0110 loss_train: 0.4339 acc_train: 0.9181 loss_val: 0.4678 acc_val: 0.9018 time: 0.0121s\nRanking optimizing... \nNow Average NDCG@k =  0.4021376669406891\nEpoch: 0111 loss_train: 0.4283 acc_train: 0.9094 loss_val: 0.4632 acc_val: 0.9045 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.4004423916339874\nEpoch: 0112 loss_train: 0.4020 acc_train: 0.9181 loss_val: 0.4586 acc_val: 0.9034 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.4039098918437958\nEpoch: 0113 loss_train: 0.4050 acc_train: 0.9225 loss_val: 0.4541 acc_val: 0.9029 time: 0.0107s\nRanking optimizing... \nNow Average NDCG@k =  0.40476784110069275\nEpoch: 0114 loss_train: 0.4013 acc_train: 0.9181 loss_val: 0.4494 acc_val: 0.9040 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.40478962659835815\nEpoch: 0115 loss_train: 0.3942 acc_train: 0.9192 loss_val: 0.4449 acc_val: 0.9040 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.4040423035621643\nEpoch: 0116 loss_train: 0.3971 acc_train: 0.9236 loss_val: 0.4405 acc_val: 0.9045 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4054023027420044\nEpoch: 0117 loss_train: 0.3949 acc_train: 0.9225 loss_val: 0.4363 acc_val: 0.9045 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4034402072429657\nEpoch: 0118 loss_train: 0.3683 acc_train: 0.9290 loss_val: 0.4321 acc_val: 0.9051 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.4051078259944916\nEpoch: 0119 loss_train: 0.3937 acc_train: 0.9148 loss_val: 0.4281 acc_val: 0.9062 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.40760794281959534\nEpoch: 0120 loss_train: 0.3839 acc_train: 0.9192 loss_val: 0.4243 acc_val: 0.9067 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.4064312279224396\nEpoch: 0121 loss_train: 0.3698 acc_train: 0.9247 loss_val: 0.4209 acc_val: 0.9073 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.4063590466976166\nEpoch: 0122 loss_train: 0.3694 acc_train: 0.9192 loss_val: 0.4176 acc_val: 0.9078 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.4063095450401306\nEpoch: 0123 loss_train: 0.3759 acc_train: 0.9214 loss_val: 0.4143 acc_val: 0.9089 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4061424732208252\nEpoch: 0124 loss_train: 0.3560 acc_train: 0.9279 loss_val: 0.4109 acc_val: 0.9094 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.40673908591270447\nEpoch: 0125 loss_train: 0.3514 acc_train: 0.9247 loss_val: 0.4080 acc_val: 0.9116 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.4073915481567383\nEpoch: 0126 loss_train: 0.3372 acc_train: 0.9214 loss_val: 0.4052 acc_val: 0.9133 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4070911109447479\nEpoch: 0127 loss_train: 0.3528 acc_train: 0.9312 loss_val: 0.4027 acc_val: 0.9149 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4077034592628479\nEpoch: 0128 loss_train: 0.3448 acc_train: 0.9378 loss_val: 0.4004 acc_val: 0.9154 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.40736475586891174\nEpoch: 0129 loss_train: 0.3387 acc_train: 0.9290 loss_val: 0.3983 acc_val: 0.9160 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.4085264503955841\nEpoch: 0130 loss_train: 0.3335 acc_train: 0.9323 loss_val: 0.3963 acc_val: 0.9154 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.40848401188850403\nEpoch: 0131 loss_train: 0.3509 acc_train: 0.9236 loss_val: 0.3941 acc_val: 0.9154 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.40864473581314087\nEpoch: 0132 loss_train: 0.3398 acc_train: 0.9192 loss_val: 0.3916 acc_val: 0.9154 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4089401960372925\nEpoch: 0133 loss_train: 0.3337 acc_train: 0.9269 loss_val: 0.3888 acc_val: 0.9143 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.40899309515953064\nEpoch: 0134 loss_train: 0.3172 acc_train: 0.9334 loss_val: 0.3861 acc_val: 0.9149 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4087430238723755\nEpoch: 0135 loss_train: 0.3236 acc_train: 0.9323 loss_val: 0.3833 acc_val: 0.9149 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4086741507053375\nEpoch: 0136 loss_train: 0.3133 acc_train: 0.9356 loss_val: 0.3808 acc_val: 0.9143 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.41019731760025024\nEpoch: 0137 loss_train: 0.3158 acc_train: 0.9356 loss_val: 0.3780 acc_val: 0.9138 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.4098467230796814\nEpoch: 0138 loss_train: 0.3222 acc_train: 0.9323 loss_val: 0.3749 acc_val: 0.9138 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.4123052954673767\nEpoch: 0139 loss_train: 0.3213 acc_train: 0.9323 loss_val: 0.3720 acc_val: 0.9143 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.409454882144928\nEpoch: 0140 loss_train: 0.2972 acc_train: 0.9454 loss_val: 0.3691 acc_val: 0.9160 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.4095405340194702\nEpoch: 0141 loss_train: 0.3012 acc_train: 0.9367 loss_val: 0.3668 acc_val: 0.9171 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.4113052189350128\nEpoch: 0142 loss_train: 0.2956 acc_train: 0.9345 loss_val: 0.3644 acc_val: 0.9171 time: 0.0135s\nRanking optimizing... \nNow Average NDCG@k =  0.4100756347179413\nEpoch: 0143 loss_train: 0.3003 acc_train: 0.9367 loss_val: 0.3623 acc_val: 0.9176 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.4116908609867096\nEpoch: 0144 loss_train: 0.2982 acc_train: 0.9367 loss_val: 0.3607 acc_val: 0.9182 time: 0.0123s\nRanking optimizing... \nNow Average NDCG@k =  0.40928366780281067\nEpoch: 0145 loss_train: 0.2844 acc_train: 0.9378 loss_val: 0.3591 acc_val: 0.9182 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.41057121753692627\nEpoch: 0146 loss_train: 0.2835 acc_train: 0.9378 loss_val: 0.3575 acc_val: 0.9176 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.4129035472869873\nEpoch: 0147 loss_train: 0.3094 acc_train: 0.9356 loss_val: 0.3562 acc_val: 0.9171 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.4114029109477997\nEpoch: 0148 loss_train: 0.2921 acc_train: 0.9334 loss_val: 0.3551 acc_val: 0.9176 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.41288161277770996\nEpoch: 0149 loss_train: 0.2758 acc_train: 0.9498 loss_val: 0.3540 acc_val: 0.9171 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4124721586704254\nEpoch: 0150 loss_train: 0.2742 acc_train: 0.9432 loss_val: 0.3528 acc_val: 0.9171 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.41296476125717163\nEpoch: 0151 loss_train: 0.2783 acc_train: 0.9454 loss_val: 0.3517 acc_val: 0.9171 time: 0.0105s\nRanking optimizing... \nNow Average NDCG@k =  0.412670373916626\nEpoch: 0152 loss_train: 0.2581 acc_train: 0.9476 loss_val: 0.3508 acc_val: 0.9171 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4146578311920166\nEpoch: 0153 loss_train: 0.2829 acc_train: 0.9389 loss_val: 0.3503 acc_val: 0.9171 time: 0.0126s\nRanking optimizing... \nNow Average NDCG@k =  0.4141930043697357\nEpoch: 0154 loss_train: 0.2594 acc_train: 0.9400 loss_val: 0.3495 acc_val: 0.9182 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.41191181540489197\nEpoch: 0155 loss_train: 0.2840 acc_train: 0.9356 loss_val: 0.3481 acc_val: 0.9176 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.41547447443008423\nEpoch: 0156 loss_train: 0.2724 acc_train: 0.9400 loss_val: 0.3466 acc_val: 0.9182 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4147770404815674\nEpoch: 0157 loss_train: 0.2584 acc_train: 0.9410 loss_val: 0.3450 acc_val: 0.9176 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.41318532824516296\nEpoch: 0158 loss_train: 0.2650 acc_train: 0.9476 loss_val: 0.3432 acc_val: 0.9187 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.41366803646087646\nEpoch: 0159 loss_train: 0.2632 acc_train: 0.9509 loss_val: 0.3413 acc_val: 0.9187 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.4113011658191681\nEpoch: 0160 loss_train: 0.2598 acc_train: 0.9432 loss_val: 0.3396 acc_val: 0.9187 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.4168322682380676\nEpoch: 0161 loss_train: 0.2737 acc_train: 0.9389 loss_val: 0.3378 acc_val: 0.9193 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.41556307673454285\nEpoch: 0162 loss_train: 0.2771 acc_train: 0.9356 loss_val: 0.3359 acc_val: 0.9193 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4174320697784424\nEpoch: 0163 loss_train: 0.2514 acc_train: 0.9454 loss_val: 0.3340 acc_val: 0.9209 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.41513609886169434\nEpoch: 0164 loss_train: 0.2534 acc_train: 0.9443 loss_val: 0.3325 acc_val: 0.9203 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.41551318764686584\nEpoch: 0165 loss_train: 0.2537 acc_train: 0.9389 loss_val: 0.3313 acc_val: 0.9203 time: 0.0127s\nRanking optimizing... \nNow Average NDCG@k =  0.415500670671463\nEpoch: 0166 loss_train: 0.2532 acc_train: 0.9520 loss_val: 0.3303 acc_val: 0.9203 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.4181321859359741\nEpoch: 0167 loss_train: 0.2469 acc_train: 0.9443 loss_val: 0.3295 acc_val: 0.9203 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.4166068136692047\nEpoch: 0168 loss_train: 0.2439 acc_train: 0.9520 loss_val: 0.3290 acc_val: 0.9198 time: 0.0115s\nRanking optimizing... \nNow Average NDCG@k =  0.41534218192100525\nEpoch: 0169 loss_train: 0.2472 acc_train: 0.9498 loss_val: 0.3286 acc_val: 0.9187 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.4164232611656189\nEpoch: 0170 loss_train: 0.2523 acc_train: 0.9443 loss_val: 0.3284 acc_val: 0.9182 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.41672778129577637\nEpoch: 0171 loss_train: 0.2421 acc_train: 0.9432 loss_val: 0.3285 acc_val: 0.9176 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4173264503479004\nEpoch: 0172 loss_train: 0.2380 acc_train: 0.9443 loss_val: 0.3283 acc_val: 0.9165 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.4188351333141327\nEpoch: 0173 loss_train: 0.2346 acc_train: 0.9487 loss_val: 0.3281 acc_val: 0.9171 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4172378480434418\nEpoch: 0174 loss_train: 0.2440 acc_train: 0.9367 loss_val: 0.3280 acc_val: 0.9176 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.4172538220882416\nEpoch: 0175 loss_train: 0.2413 acc_train: 0.9520 loss_val: 0.3272 acc_val: 0.9187 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4178072214126587\nEpoch: 0176 loss_train: 0.2315 acc_train: 0.9487 loss_val: 0.3265 acc_val: 0.9187 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.41626209020614624\nEpoch: 0177 loss_train: 0.2358 acc_train: 0.9476 loss_val: 0.3257 acc_val: 0.9182 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4196906089782715\nEpoch: 0178 loss_train: 0.2239 acc_train: 0.9596 loss_val: 0.3247 acc_val: 0.9198 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4190569221973419\nEpoch: 0179 loss_train: 0.2386 acc_train: 0.9389 loss_val: 0.3232 acc_val: 0.9203 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4191284775733948\nEpoch: 0180 loss_train: 0.2400 acc_train: 0.9476 loss_val: 0.3220 acc_val: 0.9214 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4185788631439209\nEpoch: 0181 loss_train: 0.2348 acc_train: 0.9476 loss_val: 0.3209 acc_val: 0.9214 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.4184817969799042\nEpoch: 0182 loss_train: 0.2292 acc_train: 0.9520 loss_val: 0.3194 acc_val: 0.9209 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.4172391891479492\nEpoch: 0183 loss_train: 0.2292 acc_train: 0.9443 loss_val: 0.3178 acc_val: 0.9214 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.4195542335510254\nEpoch: 0184 loss_train: 0.2227 acc_train: 0.9520 loss_val: 0.3161 acc_val: 0.9220 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.4182707965373993\nEpoch: 0185 loss_train: 0.2360 acc_train: 0.9410 loss_val: 0.3147 acc_val: 0.9220 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4206845760345459\nEpoch: 0186 loss_train: 0.2071 acc_train: 0.9618 loss_val: 0.3137 acc_val: 0.9220 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.4173775911331177\nEpoch: 0187 loss_train: 0.2196 acc_train: 0.9574 loss_val: 0.3132 acc_val: 0.9203 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.41826102137565613\nEpoch: 0188 loss_train: 0.2326 acc_train: 0.9443 loss_val: 0.3126 acc_val: 0.9198 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4188084602355957\nEpoch: 0189 loss_train: 0.2136 acc_train: 0.9541 loss_val: 0.3124 acc_val: 0.9198 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.41868695616722107\nEpoch: 0190 loss_train: 0.2207 acc_train: 0.9498 loss_val: 0.3124 acc_val: 0.9187 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.41959652304649353\nEpoch: 0191 loss_train: 0.2234 acc_train: 0.9465 loss_val: 0.3125 acc_val: 0.9198 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4205649495124817\nEpoch: 0192 loss_train: 0.2063 acc_train: 0.9552 loss_val: 0.3124 acc_val: 0.9198 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4205390214920044\nEpoch: 0193 loss_train: 0.2061 acc_train: 0.9574 loss_val: 0.3122 acc_val: 0.9198 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.4216921627521515\nEpoch: 0194 loss_train: 0.2121 acc_train: 0.9498 loss_val: 0.3121 acc_val: 0.9187 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.42251351475715637\nEpoch: 0195 loss_train: 0.2246 acc_train: 0.9487 loss_val: 0.3120 acc_val: 0.9187 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.41972774267196655\nEpoch: 0196 loss_train: 0.2078 acc_train: 0.9585 loss_val: 0.3123 acc_val: 0.9198 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.42182543873786926\nEpoch: 0197 loss_train: 0.2095 acc_train: 0.9541 loss_val: 0.3128 acc_val: 0.9198 time: 0.0121s\nRanking optimizing... \nNow Average NDCG@k =  0.41940033435821533\nEpoch: 0198 loss_train: 0.2074 acc_train: 0.9552 loss_val: 0.3131 acc_val: 0.9203 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.42186757922172546\nEpoch: 0199 loss_train: 0.2145 acc_train: 0.9520 loss_val: 0.3127 acc_val: 0.9198 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4221344590187073\nEpoch: 0200 loss_train: 0.1958 acc_train: 0.9640 loss_val: 0.3125 acc_val: 0.9203 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.42065832018852234\nEpoch: 0201 loss_train: 0.2149 acc_train: 0.9520 loss_val: 0.3116 acc_val: 0.9209 time: 0.0107s\nRanking optimizing... \nNow Average NDCG@k =  0.42282000184059143\nEpoch: 0202 loss_train: 0.2126 acc_train: 0.9487 loss_val: 0.3109 acc_val: 0.9214 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4237217903137207\nEpoch: 0203 loss_train: 0.2130 acc_train: 0.9476 loss_val: 0.3099 acc_val: 0.9209 time: 0.0111s\nRanking optimizing... \nNow Average NDCG@k =  0.4216567575931549\nEpoch: 0204 loss_train: 0.2052 acc_train: 0.9552 loss_val: 0.3090 acc_val: 0.9203 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4214865565299988\nEpoch: 0205 loss_train: 0.2046 acc_train: 0.9552 loss_val: 0.3080 acc_val: 0.9198 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.423355370759964\nEpoch: 0206 loss_train: 0.2038 acc_train: 0.9563 loss_val: 0.3072 acc_val: 0.9198 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4238642752170563\nEpoch: 0207 loss_train: 0.2001 acc_train: 0.9487 loss_val: 0.3064 acc_val: 0.9198 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.4258035123348236\nEpoch: 0208 loss_train: 0.2115 acc_train: 0.9509 loss_val: 0.3056 acc_val: 0.9193 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.4230373203754425\nEpoch: 0209 loss_train: 0.1980 acc_train: 0.9585 loss_val: 0.3046 acc_val: 0.9187 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.4234413206577301\nEpoch: 0210 loss_train: 0.2050 acc_train: 0.9476 loss_val: 0.3036 acc_val: 0.9187 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.424539178609848\nEpoch: 0211 loss_train: 0.2014 acc_train: 0.9541 loss_val: 0.3027 acc_val: 0.9187 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.42468464374542236\nEpoch: 0212 loss_train: 0.2045 acc_train: 0.9454 loss_val: 0.3018 acc_val: 0.9198 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.42499834299087524\nEpoch: 0213 loss_train: 0.2067 acc_train: 0.9476 loss_val: 0.3011 acc_val: 0.9187 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4239041805267334\nEpoch: 0214 loss_train: 0.1862 acc_train: 0.9585 loss_val: 0.3005 acc_val: 0.9187 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.424995094537735\nEpoch: 0215 loss_train: 0.1996 acc_train: 0.9487 loss_val: 0.3000 acc_val: 0.9187 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.42589688301086426\nEpoch: 0216 loss_train: 0.1940 acc_train: 0.9563 loss_val: 0.2999 acc_val: 0.9187 time: 0.0088s\nRanking optimizing... \nNow Average NDCG@k =  0.4270482659339905\nEpoch: 0217 loss_train: 0.1815 acc_train: 0.9585 loss_val: 0.2998 acc_val: 0.9209 time: 0.0113s\nRanking optimizing... \nNow Average NDCG@k =  0.4268254339694977\nEpoch: 0218 loss_train: 0.2109 acc_train: 0.9520 loss_val: 0.2993 acc_val: 0.9209 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.42771610617637634\nEpoch: 0219 loss_train: 0.1890 acc_train: 0.9629 loss_val: 0.2989 acc_val: 0.9209 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4255602955818176\nEpoch: 0220 loss_train: 0.1772 acc_train: 0.9629 loss_val: 0.2985 acc_val: 0.9209 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4276610016822815\nEpoch: 0221 loss_train: 0.1855 acc_train: 0.9640 loss_val: 0.2982 acc_val: 0.9203 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.42750677466392517\nEpoch: 0222 loss_train: 0.1926 acc_train: 0.9574 loss_val: 0.2978 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4271047115325928\nEpoch: 0223 loss_train: 0.1888 acc_train: 0.9607 loss_val: 0.2977 acc_val: 0.9198 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.43037149310112\nEpoch: 0224 loss_train: 0.1840 acc_train: 0.9541 loss_val: 0.2975 acc_val: 0.9193 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4284226894378662\nEpoch: 0225 loss_train: 0.1866 acc_train: 0.9585 loss_val: 0.2973 acc_val: 0.9187 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.42792224884033203\nEpoch: 0226 loss_train: 0.1972 acc_train: 0.9498 loss_val: 0.2970 acc_val: 0.9198 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4288480877876282\nEpoch: 0227 loss_train: 0.1868 acc_train: 0.9640 loss_val: 0.2967 acc_val: 0.9198 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.42857012152671814\nEpoch: 0228 loss_train: 0.1849 acc_train: 0.9596 loss_val: 0.2964 acc_val: 0.9193 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4299931228160858\nEpoch: 0229 loss_train: 0.1751 acc_train: 0.9563 loss_val: 0.2960 acc_val: 0.9187 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.430169939994812\nEpoch: 0230 loss_train: 0.1672 acc_train: 0.9618 loss_val: 0.2958 acc_val: 0.9182 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.42984992265701294\nEpoch: 0231 loss_train: 0.1626 acc_train: 0.9672 loss_val: 0.2954 acc_val: 0.9187 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.4306633174419403\nEpoch: 0232 loss_train: 0.1744 acc_train: 0.9662 loss_val: 0.2950 acc_val: 0.9193 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4300023913383484\nEpoch: 0233 loss_train: 0.1717 acc_train: 0.9651 loss_val: 0.2947 acc_val: 0.9193 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4311956465244293\nEpoch: 0234 loss_train: 0.1800 acc_train: 0.9607 loss_val: 0.2949 acc_val: 0.9187 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.43037036061286926\nEpoch: 0235 loss_train: 0.1742 acc_train: 0.9552 loss_val: 0.2955 acc_val: 0.9193 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.4309145510196686\nEpoch: 0236 loss_train: 0.1668 acc_train: 0.9618 loss_val: 0.2958 acc_val: 0.9198 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.4323292672634125\nEpoch: 0237 loss_train: 0.1681 acc_train: 0.9596 loss_val: 0.2955 acc_val: 0.9198 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.4304947555065155\nEpoch: 0238 loss_train: 0.1641 acc_train: 0.9640 loss_val: 0.2945 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4320121109485626\nEpoch: 0239 loss_train: 0.1721 acc_train: 0.9574 loss_val: 0.2936 acc_val: 0.9198 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4312084913253784\nEpoch: 0240 loss_train: 0.1614 acc_train: 0.9651 loss_val: 0.2924 acc_val: 0.9209 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.43455466628074646\nEpoch: 0241 loss_train: 0.1848 acc_train: 0.9563 loss_val: 0.2908 acc_val: 0.9209 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.433366984128952\nEpoch: 0242 loss_train: 0.1545 acc_train: 0.9716 loss_val: 0.2892 acc_val: 0.9198 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.43524038791656494\nEpoch: 0243 loss_train: 0.1678 acc_train: 0.9498 loss_val: 0.2873 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.43394938111305237\nEpoch: 0244 loss_train: 0.1706 acc_train: 0.9618 loss_val: 0.2858 acc_val: 0.9198 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.43450772762298584\nEpoch: 0245 loss_train: 0.1609 acc_train: 0.9662 loss_val: 0.2847 acc_val: 0.9198 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4332752227783203\nEpoch: 0246 loss_train: 0.1608 acc_train: 0.9683 loss_val: 0.2842 acc_val: 0.9198 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.43725550174713135\nEpoch: 0247 loss_train: 0.1692 acc_train: 0.9640 loss_val: 0.2841 acc_val: 0.9198 time: 0.0108s\nRanking optimizing... \nNow Average NDCG@k =  0.4330560266971588\nEpoch: 0248 loss_train: 0.1618 acc_train: 0.9629 loss_val: 0.2843 acc_val: 0.9198 time: 0.0119s\nRanking optimizing... \nNow Average NDCG@k =  0.43556541204452515\nEpoch: 0249 loss_train: 0.1618 acc_train: 0.9683 loss_val: 0.2850 acc_val: 0.9193 time: 0.0121s\nRanking optimizing... \nNow Average NDCG@k =  0.4359557032585144\nEpoch: 0250 loss_train: 0.1664 acc_train: 0.9651 loss_val: 0.2860 acc_val: 0.9209 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.43699535727500916\nEpoch: 0251 loss_train: 0.1642 acc_train: 0.9629 loss_val: 0.2871 acc_val: 0.9214 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.43640363216400146\nEpoch: 0252 loss_train: 0.1565 acc_train: 0.9651 loss_val: 0.2882 acc_val: 0.9209 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.4345564842224121\nEpoch: 0253 loss_train: 0.1531 acc_train: 0.9640 loss_val: 0.2889 acc_val: 0.9203 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.4363434314727783\nEpoch: 0254 loss_train: 0.1734 acc_train: 0.9629 loss_val: 0.2892 acc_val: 0.9203 time: 0.0107s\nRanking optimizing... \nNow Average NDCG@k =  0.4344014525413513\nEpoch: 0255 loss_train: 0.1581 acc_train: 0.9672 loss_val: 0.2891 acc_val: 0.9203 time: 0.0108s\nRanking optimizing... \nNow Average NDCG@k =  0.43820732831954956\nEpoch: 0256 loss_train: 0.1475 acc_train: 0.9727 loss_val: 0.2884 acc_val: 0.9198 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.4370197653770447\nEpoch: 0257 loss_train: 0.1591 acc_train: 0.9629 loss_val: 0.2878 acc_val: 0.9198 time: 0.0114s\nRanking optimizing... \nNow Average NDCG@k =  0.4357040226459503\nEpoch: 0258 loss_train: 0.1642 acc_train: 0.9541 loss_val: 0.2874 acc_val: 0.9198 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.4375666677951813\nEpoch: 0259 loss_train: 0.1460 acc_train: 0.9705 loss_val: 0.2870 acc_val: 0.9198 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.4372926652431488\nEpoch: 0260 loss_train: 0.1552 acc_train: 0.9705 loss_val: 0.2870 acc_val: 0.9198 time: 0.0106s\nRanking optimizing... \nNow Average NDCG@k =  0.4381142258644104\nEpoch: 0261 loss_train: 0.1559 acc_train: 0.9640 loss_val: 0.2873 acc_val: 0.9203 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.4380296468734741\nEpoch: 0262 loss_train: 0.1690 acc_train: 0.9607 loss_val: 0.2876 acc_val: 0.9203 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.4395730495452881\nEpoch: 0263 loss_train: 0.1680 acc_train: 0.9596 loss_val: 0.2880 acc_val: 0.9203 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4380485713481903\nEpoch: 0264 loss_train: 0.1632 acc_train: 0.9651 loss_val: 0.2887 acc_val: 0.9198 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4390571415424347\nEpoch: 0265 loss_train: 0.1478 acc_train: 0.9651 loss_val: 0.2894 acc_val: 0.9198 time: 0.0118s\nRanking optimizing... \nNow Average NDCG@k =  0.4378730356693268\nEpoch: 0266 loss_train: 0.1590 acc_train: 0.9596 loss_val: 0.2895 acc_val: 0.9203 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.4381183385848999\nEpoch: 0267 loss_train: 0.1531 acc_train: 0.9705 loss_val: 0.2892 acc_val: 0.9209 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.4407052993774414\nEpoch: 0268 loss_train: 0.1467 acc_train: 0.9694 loss_val: 0.2889 acc_val: 0.9209 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4402965307235718\nEpoch: 0269 loss_train: 0.1555 acc_train: 0.9563 loss_val: 0.2880 acc_val: 0.9209 time: 0.0135s\nRanking optimizing... \nNow Average NDCG@k =  0.4400663673877716\nEpoch: 0270 loss_train: 0.1503 acc_train: 0.9662 loss_val: 0.2867 acc_val: 0.9198 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.44152554869651794\nEpoch: 0271 loss_train: 0.1589 acc_train: 0.9640 loss_val: 0.2856 acc_val: 0.9214 time: 0.0126s\nRanking optimizing... \nNow Average NDCG@k =  0.43952620029449463\nEpoch: 0272 loss_train: 0.1506 acc_train: 0.9629 loss_val: 0.2847 acc_val: 0.9209 time: 0.0116s\nRanking optimizing... \nNow Average NDCG@k =  0.441967636346817\nEpoch: 0273 loss_train: 0.1574 acc_train: 0.9640 loss_val: 0.2839 acc_val: 0.9209 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.4400845170021057\nEpoch: 0274 loss_train: 0.1537 acc_train: 0.9716 loss_val: 0.2837 acc_val: 0.9203 time: 0.0129s\nRanking optimizing... \nNow Average NDCG@k =  0.44211500883102417\nEpoch: 0275 loss_train: 0.1430 acc_train: 0.9727 loss_val: 0.2840 acc_val: 0.9203 time: 0.0105s\nRanking optimizing... \nNow Average NDCG@k =  0.441185861825943\nEpoch: 0276 loss_train: 0.1436 acc_train: 0.9683 loss_val: 0.2842 acc_val: 0.9209 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.440307080745697\nEpoch: 0277 loss_train: 0.1480 acc_train: 0.9672 loss_val: 0.2846 acc_val: 0.9203 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.44079309701919556\nEpoch: 0278 loss_train: 0.1521 acc_train: 0.9716 loss_val: 0.2847 acc_val: 0.9209 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.44110697507858276\nEpoch: 0279 loss_train: 0.1645 acc_train: 0.9640 loss_val: 0.2847 acc_val: 0.9198 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.44407495856285095\nEpoch: 0280 loss_train: 0.1552 acc_train: 0.9552 loss_val: 0.2850 acc_val: 0.9193 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.44150421023368835\nEpoch: 0281 loss_train: 0.1449 acc_train: 0.9716 loss_val: 0.2845 acc_val: 0.9209 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.4422513544559479\nEpoch: 0282 loss_train: 0.1461 acc_train: 0.9672 loss_val: 0.2840 acc_val: 0.9203 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.442996084690094\nEpoch: 0283 loss_train: 0.1404 acc_train: 0.9749 loss_val: 0.2834 acc_val: 0.9203 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4427297115325928\nEpoch: 0284 loss_train: 0.1582 acc_train: 0.9651 loss_val: 0.2828 acc_val: 0.9198 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.4432726502418518\nEpoch: 0285 loss_train: 0.1396 acc_train: 0.9727 loss_val: 0.2824 acc_val: 0.9198 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.4414556324481964\nEpoch: 0286 loss_train: 0.1408 acc_train: 0.9672 loss_val: 0.2825 acc_val: 0.9198 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.44318315386772156\nEpoch: 0287 loss_train: 0.1361 acc_train: 0.9716 loss_val: 0.2831 acc_val: 0.9198 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4445587694644928\nEpoch: 0288 loss_train: 0.1393 acc_train: 0.9793 loss_val: 0.2839 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4424211084842682\nEpoch: 0289 loss_train: 0.1505 acc_train: 0.9629 loss_val: 0.2850 acc_val: 0.9209 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4454459846019745\nEpoch: 0290 loss_train: 0.1558 acc_train: 0.9585 loss_val: 0.2861 acc_val: 0.9203 time: 0.0174s\nRanking optimizing... \nNow Average NDCG@k =  0.4427514374256134\nEpoch: 0291 loss_train: 0.1540 acc_train: 0.9629 loss_val: 0.2875 acc_val: 0.9203 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.4450119733810425\nEpoch: 0292 loss_train: 0.1488 acc_train: 0.9683 loss_val: 0.2885 acc_val: 0.9193 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.44440770149230957\nEpoch: 0293 loss_train: 0.1418 acc_train: 0.9716 loss_val: 0.2884 acc_val: 0.9203 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.4449661076068878\nEpoch: 0294 loss_train: 0.1413 acc_train: 0.9727 loss_val: 0.2880 acc_val: 0.9198 time: 0.0135s\nRanking optimizing... \nNow Average NDCG@k =  0.44506949186325073\nEpoch: 0295 loss_train: 0.1302 acc_train: 0.9716 loss_val: 0.2881 acc_val: 0.9198 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.44524237513542175\nEpoch: 0296 loss_train: 0.1479 acc_train: 0.9640 loss_val: 0.2879 acc_val: 0.9203 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.44485074281692505\nEpoch: 0297 loss_train: 0.1469 acc_train: 0.9694 loss_val: 0.2877 acc_val: 0.9203 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.44476738572120667\nEpoch: 0298 loss_train: 0.1442 acc_train: 0.9672 loss_val: 0.2872 acc_val: 0.9209 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.44584912061691284\nEpoch: 0299 loss_train: 0.1368 acc_train: 0.9760 loss_val: 0.2871 acc_val: 0.9203 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.45020216703414917\nEpoch: 0300 loss_train: 0.1480 acc_train: 0.9705 loss_val: 0.2870 acc_val: 0.9214 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4481898844242096\nEpoch: 0301 loss_train: 0.1500 acc_train: 0.9640 loss_val: 0.2868 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.44605910778045654\nEpoch: 0302 loss_train: 0.1376 acc_train: 0.9738 loss_val: 0.2863 acc_val: 0.9198 time: 0.0114s\nRanking optimizing... \nNow Average NDCG@k =  0.44686660170555115\nEpoch: 0303 loss_train: 0.1495 acc_train: 0.9716 loss_val: 0.2857 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.44540607929229736\nEpoch: 0304 loss_train: 0.1515 acc_train: 0.9596 loss_val: 0.2848 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.447313517332077\nEpoch: 0305 loss_train: 0.1481 acc_train: 0.9651 loss_val: 0.2840 acc_val: 0.9214 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.4475279748439789\nEpoch: 0306 loss_train: 0.1496 acc_train: 0.9683 loss_val: 0.2836 acc_val: 0.9209 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.44801202416419983\nEpoch: 0307 loss_train: 0.1416 acc_train: 0.9694 loss_val: 0.2835 acc_val: 0.9209 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.44748133420944214\nEpoch: 0308 loss_train: 0.1353 acc_train: 0.9716 loss_val: 0.2837 acc_val: 0.9214 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.4497802257537842\nEpoch: 0309 loss_train: 0.1523 acc_train: 0.9662 loss_val: 0.2839 acc_val: 0.9214 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.44820982217788696\nEpoch: 0310 loss_train: 0.1307 acc_train: 0.9672 loss_val: 0.2843 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4483843147754669\nEpoch: 0311 loss_train: 0.1620 acc_train: 0.9563 loss_val: 0.2848 acc_val: 0.9203 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4476081430912018\nEpoch: 0312 loss_train: 0.1420 acc_train: 0.9749 loss_val: 0.2853 acc_val: 0.9203 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.44705259799957275\nEpoch: 0313 loss_train: 0.1408 acc_train: 0.9683 loss_val: 0.2859 acc_val: 0.9209 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.4515266418457031\nEpoch: 0314 loss_train: 0.1397 acc_train: 0.9760 loss_val: 0.2867 acc_val: 0.9203 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.44997745752334595\nEpoch: 0315 loss_train: 0.1431 acc_train: 0.9738 loss_val: 0.2872 acc_val: 0.9198 time: 0.0131s\nRanking optimizing... \nNow Average NDCG@k =  0.448091059923172\nEpoch: 0316 loss_train: 0.1319 acc_train: 0.9749 loss_val: 0.2872 acc_val: 0.9198 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.4489385783672333\nEpoch: 0317 loss_train: 0.1505 acc_train: 0.9651 loss_val: 0.2865 acc_val: 0.9198 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.44961485266685486\nEpoch: 0318 loss_train: 0.1304 acc_train: 0.9814 loss_val: 0.2863 acc_val: 0.9203 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.44904404878616333\nEpoch: 0319 loss_train: 0.1458 acc_train: 0.9640 loss_val: 0.2862 acc_val: 0.9193 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.44973286986351013\nEpoch: 0320 loss_train: 0.1351 acc_train: 0.9694 loss_val: 0.2864 acc_val: 0.9198 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.45070353150367737\nEpoch: 0321 loss_train: 0.1314 acc_train: 0.9738 loss_val: 0.2867 acc_val: 0.9193 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.4517021179199219\nEpoch: 0322 loss_train: 0.1429 acc_train: 0.9662 loss_val: 0.2868 acc_val: 0.9198 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.4505525231361389\nEpoch: 0323 loss_train: 0.1439 acc_train: 0.9738 loss_val: 0.2868 acc_val: 0.9198 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.44765856862068176\nEpoch: 0324 loss_train: 0.1447 acc_train: 0.9683 loss_val: 0.2863 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4516066014766693\nEpoch: 0325 loss_train: 0.1394 acc_train: 0.9716 loss_val: 0.2859 acc_val: 0.9214 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.44940438866615295\nEpoch: 0326 loss_train: 0.1353 acc_train: 0.9749 loss_val: 0.2860 acc_val: 0.9214 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4503990411758423\nEpoch: 0327 loss_train: 0.1374 acc_train: 0.9771 loss_val: 0.2867 acc_val: 0.9220 time: 0.0107s\nRanking optimizing... \nNow Average NDCG@k =  0.4515652358531952\nEpoch: 0328 loss_train: 0.1546 acc_train: 0.9607 loss_val: 0.2869 acc_val: 0.9214 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.450594961643219\nEpoch: 0329 loss_train: 0.1428 acc_train: 0.9694 loss_val: 0.2867 acc_val: 0.9220 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.451279878616333\nEpoch: 0330 loss_train: 0.1488 acc_train: 0.9683 loss_val: 0.2864 acc_val: 0.9220 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.45078349113464355\nEpoch: 0331 loss_train: 0.1427 acc_train: 0.9727 loss_val: 0.2864 acc_val: 0.9203 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.45172661542892456\nEpoch: 0332 loss_train: 0.1440 acc_train: 0.9727 loss_val: 0.2865 acc_val: 0.9203 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4532453715801239\nEpoch: 0333 loss_train: 0.1361 acc_train: 0.9705 loss_val: 0.2865 acc_val: 0.9198 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.4505329728126526\nEpoch: 0334 loss_train: 0.1443 acc_train: 0.9694 loss_val: 0.2867 acc_val: 0.9209 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.45204704999923706\nEpoch: 0335 loss_train: 0.1361 acc_train: 0.9771 loss_val: 0.2869 acc_val: 0.9209 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4513436555862427\nEpoch: 0336 loss_train: 0.1467 acc_train: 0.9640 loss_val: 0.2871 acc_val: 0.9209 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.451668381690979\nEpoch: 0337 loss_train: 0.1314 acc_train: 0.9771 loss_val: 0.2876 acc_val: 0.9220 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.4521709978580475\nEpoch: 0338 loss_train: 0.1306 acc_train: 0.9803 loss_val: 0.2878 acc_val: 0.9209 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4512437582015991\nEpoch: 0339 loss_train: 0.1315 acc_train: 0.9760 loss_val: 0.2882 acc_val: 0.9203 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.45038655400276184\nEpoch: 0340 loss_train: 0.1333 acc_train: 0.9749 loss_val: 0.2886 acc_val: 0.9203 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.45127561688423157\nEpoch: 0341 loss_train: 0.1434 acc_train: 0.9662 loss_val: 0.2892 acc_val: 0.9203 time: 0.0105s\nRanking optimizing... \nNow Average NDCG@k =  0.45131716132164\nEpoch: 0342 loss_train: 0.1282 acc_train: 0.9716 loss_val: 0.2898 acc_val: 0.9203 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.45138019323349\nEpoch: 0343 loss_train: 0.1259 acc_train: 0.9803 loss_val: 0.2900 acc_val: 0.9203 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.4524175226688385\nEpoch: 0344 loss_train: 0.1354 acc_train: 0.9716 loss_val: 0.2903 acc_val: 0.9209 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.451289564371109\nEpoch: 0345 loss_train: 0.1439 acc_train: 0.9672 loss_val: 0.2902 acc_val: 0.9209 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.45371440052986145\nEpoch: 0346 loss_train: 0.1268 acc_train: 0.9782 loss_val: 0.2898 acc_val: 0.9209 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.4528471827507019\nEpoch: 0347 loss_train: 0.1461 acc_train: 0.9727 loss_val: 0.2894 acc_val: 0.9209 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.45266756415367126\nEpoch: 0348 loss_train: 0.1356 acc_train: 0.9705 loss_val: 0.2886 acc_val: 0.9209 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4519798755645752\nEpoch: 0349 loss_train: 0.1300 acc_train: 0.9683 loss_val: 0.2876 acc_val: 0.9214 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.4557199478149414\nEpoch: 0350 loss_train: 0.1290 acc_train: 0.9738 loss_val: 0.2866 acc_val: 0.9209 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.45453792810440063\nEpoch: 0351 loss_train: 0.1452 acc_train: 0.9716 loss_val: 0.2861 acc_val: 0.9214 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.45736318826675415\nEpoch: 0352 loss_train: 0.1389 acc_train: 0.9749 loss_val: 0.2859 acc_val: 0.9220 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.45429128408432007\nEpoch: 0353 loss_train: 0.1278 acc_train: 0.9803 loss_val: 0.2858 acc_val: 0.9220 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4553527534008026\nEpoch: 0354 loss_train: 0.1343 acc_train: 0.9749 loss_val: 0.2860 acc_val: 0.9220 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4560174345970154\nEpoch: 0355 loss_train: 0.1381 acc_train: 0.9760 loss_val: 0.2863 acc_val: 0.9214 time: 0.0120s\nRanking optimizing... \nNow Average NDCG@k =  0.4555923640727997\nEpoch: 0356 loss_train: 0.1374 acc_train: 0.9727 loss_val: 0.2868 acc_val: 0.9209 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.456840842962265\nEpoch: 0357 loss_train: 0.1358 acc_train: 0.9749 loss_val: 0.2874 acc_val: 0.9203 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4551546573638916\nEpoch: 0358 loss_train: 0.1423 acc_train: 0.9694 loss_val: 0.2882 acc_val: 0.9203 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4558705985546112\nEpoch: 0359 loss_train: 0.1321 acc_train: 0.9727 loss_val: 0.2890 acc_val: 0.9198 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4565091133117676\nEpoch: 0360 loss_train: 0.1458 acc_train: 0.9694 loss_val: 0.2904 acc_val: 0.9193 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.4560566544532776\nEpoch: 0361 loss_train: 0.1323 acc_train: 0.9836 loss_val: 0.2917 acc_val: 0.9182 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.4569338262081146\nEpoch: 0362 loss_train: 0.1294 acc_train: 0.9716 loss_val: 0.2925 acc_val: 0.9182 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.45911237597465515\nEpoch: 0363 loss_train: 0.1367 acc_train: 0.9738 loss_val: 0.2926 acc_val: 0.9187 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.4548209011554718\nEpoch: 0364 loss_train: 0.1422 acc_train: 0.9672 loss_val: 0.2924 acc_val: 0.9176 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.45655256509780884\nEpoch: 0365 loss_train: 0.1283 acc_train: 0.9793 loss_val: 0.2917 acc_val: 0.9182 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.4569835662841797\nEpoch: 0366 loss_train: 0.1419 acc_train: 0.9727 loss_val: 0.2904 acc_val: 0.9198 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.45650577545166016\nEpoch: 0367 loss_train: 0.1312 acc_train: 0.9771 loss_val: 0.2891 acc_val: 0.9193 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.45749902725219727\nEpoch: 0368 loss_train: 0.1282 acc_train: 0.9771 loss_val: 0.2882 acc_val: 0.9209 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.4553854167461395\nEpoch: 0369 loss_train: 0.1446 acc_train: 0.9640 loss_val: 0.2871 acc_val: 0.9214 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.45689859986305237\nEpoch: 0370 loss_train: 0.1256 acc_train: 0.9760 loss_val: 0.2865 acc_val: 0.9209 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.45609423518180847\nEpoch: 0371 loss_train: 0.1275 acc_train: 0.9771 loss_val: 0.2859 acc_val: 0.9214 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4579506516456604\nEpoch: 0372 loss_train: 0.1262 acc_train: 0.9814 loss_val: 0.2858 acc_val: 0.9220 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.45756614208221436\nEpoch: 0373 loss_train: 0.1331 acc_train: 0.9782 loss_val: 0.2859 acc_val: 0.9203 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.45801541209220886\nEpoch: 0374 loss_train: 0.1334 acc_train: 0.9738 loss_val: 0.2862 acc_val: 0.9203 time: 0.0107s\nRanking optimizing... \nNow Average NDCG@k =  0.4586019217967987\nEpoch: 0375 loss_train: 0.1384 acc_train: 0.9694 loss_val: 0.2866 acc_val: 0.9198 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.46019959449768066\nEpoch: 0376 loss_train: 0.1403 acc_train: 0.9662 loss_val: 0.2871 acc_val: 0.9198 time: 0.0116s\nRanking optimizing... \nNow Average NDCG@k =  0.45819219946861267\nEpoch: 0377 loss_train: 0.1387 acc_train: 0.9727 loss_val: 0.2878 acc_val: 0.9198 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.46085500717163086\nEpoch: 0378 loss_train: 0.1247 acc_train: 0.9825 loss_val: 0.2886 acc_val: 0.9187 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4579208493232727\nEpoch: 0379 loss_train: 0.1330 acc_train: 0.9716 loss_val: 0.2892 acc_val: 0.9176 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.45987454056739807\nEpoch: 0380 loss_train: 0.1328 acc_train: 0.9749 loss_val: 0.2895 acc_val: 0.9182 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.4613551199436188\nEpoch: 0381 loss_train: 0.1415 acc_train: 0.9749 loss_val: 0.2895 acc_val: 0.9187 time: 0.0124s\nRanking optimizing... \nNow Average NDCG@k =  0.45908382534980774\nEpoch: 0382 loss_train: 0.1314 acc_train: 0.9727 loss_val: 0.2896 acc_val: 0.9193 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.4596734344959259\nEpoch: 0383 loss_train: 0.1317 acc_train: 0.9825 loss_val: 0.2896 acc_val: 0.9209 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.460407555103302\nEpoch: 0384 loss_train: 0.1310 acc_train: 0.9705 loss_val: 0.2897 acc_val: 0.9214 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.45730262994766235\nEpoch: 0385 loss_train: 0.1417 acc_train: 0.9760 loss_val: 0.2896 acc_val: 0.9214 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.45862850546836853\nEpoch: 0386 loss_train: 0.1410 acc_train: 0.9760 loss_val: 0.2896 acc_val: 0.9214 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.4592641294002533\nEpoch: 0387 loss_train: 0.1370 acc_train: 0.9738 loss_val: 0.2893 acc_val: 0.9214 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4604593813419342\nEpoch: 0388 loss_train: 0.1365 acc_train: 0.9705 loss_val: 0.2892 acc_val: 0.9209 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.4608590304851532\nEpoch: 0389 loss_train: 0.1357 acc_train: 0.9760 loss_val: 0.2886 acc_val: 0.9203 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.459507554769516\nEpoch: 0390 loss_train: 0.1344 acc_train: 0.9716 loss_val: 0.2886 acc_val: 0.9209 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4585033059120178\nEpoch: 0391 loss_train: 0.1289 acc_train: 0.9760 loss_val: 0.2888 acc_val: 0.9209 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.46030372381210327\nEpoch: 0392 loss_train: 0.1194 acc_train: 0.9793 loss_val: 0.2890 acc_val: 0.9203 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.4600840210914612\nEpoch: 0393 loss_train: 0.1329 acc_train: 0.9738 loss_val: 0.2890 acc_val: 0.9203 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.45990028977394104\nEpoch: 0394 loss_train: 0.1335 acc_train: 0.9727 loss_val: 0.2889 acc_val: 0.9203 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.4617554247379303\nEpoch: 0395 loss_train: 0.1354 acc_train: 0.9738 loss_val: 0.2889 acc_val: 0.9203 time: 0.0093s\nRanking optimizing... \nNow Average NDCG@k =  0.4627951681613922\nEpoch: 0396 loss_train: 0.1308 acc_train: 0.9749 loss_val: 0.2886 acc_val: 0.9203 time: 0.0107s\nRanking optimizing... \nNow Average NDCG@k =  0.46190178394317627\nEpoch: 0397 loss_train: 0.1291 acc_train: 0.9760 loss_val: 0.2885 acc_val: 0.9203 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.46125027537345886\nEpoch: 0398 loss_train: 0.1313 acc_train: 0.9760 loss_val: 0.2885 acc_val: 0.9209 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.4614851176738739\nEpoch: 0399 loss_train: 0.1330 acc_train: 0.9749 loss_val: 0.2883 acc_val: 0.9203 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.4617285430431366\nEpoch: 0400 loss_train: 0.1311 acc_train: 0.9705 loss_val: 0.2881 acc_val: 0.9209 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4609505534172058\nEpoch: 0401 loss_train: 0.1311 acc_train: 0.9760 loss_val: 0.2884 acc_val: 0.9214 time: 0.0114s\nRanking optimizing... \nNow Average NDCG@k =  0.4620177149772644\nEpoch: 0402 loss_train: 0.1421 acc_train: 0.9760 loss_val: 0.2889 acc_val: 0.9220 time: 0.0093s\nRanking optimizing... \nNow Average NDCG@k =  0.46096014976501465\nEpoch: 0403 loss_train: 0.1262 acc_train: 0.9782 loss_val: 0.2895 acc_val: 0.9209 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.46452316641807556\nEpoch: 0404 loss_train: 0.1315 acc_train: 0.9771 loss_val: 0.2903 acc_val: 0.9220 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.46221575140953064\nEpoch: 0405 loss_train: 0.1409 acc_train: 0.9727 loss_val: 0.2912 acc_val: 0.9209 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.46377164125442505\nEpoch: 0406 loss_train: 0.1380 acc_train: 0.9771 loss_val: 0.2920 acc_val: 0.9203 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.46192437410354614\nEpoch: 0407 loss_train: 0.1214 acc_train: 0.9869 loss_val: 0.2931 acc_val: 0.9214 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.4610688090324402\nEpoch: 0408 loss_train: 0.1247 acc_train: 0.9793 loss_val: 0.2942 acc_val: 0.9198 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.4637135863304138\nEpoch: 0409 loss_train: 0.1220 acc_train: 0.9760 loss_val: 0.2950 acc_val: 0.9182 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.4631742238998413\nEpoch: 0410 loss_train: 0.1331 acc_train: 0.9749 loss_val: 0.2956 acc_val: 0.9187 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.4621279239654541\nEpoch: 0411 loss_train: 0.1272 acc_train: 0.9782 loss_val: 0.2948 acc_val: 0.9182 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4612923860549927\nEpoch: 0412 loss_train: 0.1313 acc_train: 0.9771 loss_val: 0.2937 acc_val: 0.9198 time: 0.0077s\nRanking optimizing... \nNow Average NDCG@k =  0.4610118567943573\nEpoch: 0413 loss_train: 0.1393 acc_train: 0.9694 loss_val: 0.2925 acc_val: 0.9198 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.45927780866622925\nEpoch: 0414 loss_train: 0.1295 acc_train: 0.9705 loss_val: 0.2911 acc_val: 0.9198 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.4621422290802002\nEpoch: 0415 loss_train: 0.1379 acc_train: 0.9771 loss_val: 0.2899 acc_val: 0.9203 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.46213486790657043\nEpoch: 0416 loss_train: 0.1280 acc_train: 0.9814 loss_val: 0.2886 acc_val: 0.9209 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4632696807384491\nEpoch: 0417 loss_train: 0.1253 acc_train: 0.9782 loss_val: 0.2878 acc_val: 0.9193 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.4635935425758362\nEpoch: 0418 loss_train: 0.1214 acc_train: 0.9793 loss_val: 0.2876 acc_val: 0.9193 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.46324455738067627\nEpoch: 0419 loss_train: 0.1302 acc_train: 0.9749 loss_val: 0.2876 acc_val: 0.9187 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.46643227338790894\nEpoch: 0420 loss_train: 0.1480 acc_train: 0.9716 loss_val: 0.2881 acc_val: 0.9198 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.46482768654823303\nEpoch: 0421 loss_train: 0.1347 acc_train: 0.9814 loss_val: 0.2890 acc_val: 0.9193 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.46469277143478394\nEpoch: 0422 loss_train: 0.1335 acc_train: 0.9771 loss_val: 0.2910 acc_val: 0.9193 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.46311286091804504\nEpoch: 0423 loss_train: 0.1236 acc_train: 0.9803 loss_val: 0.2932 acc_val: 0.9203 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.46446651220321655\nEpoch: 0424 loss_train: 0.1356 acc_train: 0.9771 loss_val: 0.2949 acc_val: 0.9187 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.46524566411972046\nEpoch: 0425 loss_train: 0.1347 acc_train: 0.9727 loss_val: 0.2958 acc_val: 0.9182 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.46576017141342163\nEpoch: 0426 loss_train: 0.1342 acc_train: 0.9716 loss_val: 0.2959 acc_val: 0.9187 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.4655061960220337\nEpoch: 0427 loss_train: 0.1311 acc_train: 0.9749 loss_val: 0.2955 acc_val: 0.9198 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.4647645652294159\nEpoch: 0428 loss_train: 0.1301 acc_train: 0.9793 loss_val: 0.2945 acc_val: 0.9198 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4651390314102173\nEpoch: 0429 loss_train: 0.1311 acc_train: 0.9803 loss_val: 0.2932 acc_val: 0.9193 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.46613752841949463\nEpoch: 0430 loss_train: 0.1377 acc_train: 0.9760 loss_val: 0.2925 acc_val: 0.9203 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.46395736932754517\nEpoch: 0431 loss_train: 0.1371 acc_train: 0.9803 loss_val: 0.2920 acc_val: 0.9203 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.4660176634788513\nEpoch: 0432 loss_train: 0.1351 acc_train: 0.9760 loss_val: 0.2916 acc_val: 0.9203 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.4661194086074829\nEpoch: 0433 loss_train: 0.1310 acc_train: 0.9803 loss_val: 0.2916 acc_val: 0.9198 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.4654178023338318\nEpoch: 0434 loss_train: 0.1241 acc_train: 0.9825 loss_val: 0.2915 acc_val: 0.9198 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.46538302302360535\nEpoch: 0435 loss_train: 0.1281 acc_train: 0.9836 loss_val: 0.2914 acc_val: 0.9193 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.4671081602573395\nEpoch: 0436 loss_train: 0.1277 acc_train: 0.9793 loss_val: 0.2913 acc_val: 0.9182 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.4660775661468506\nEpoch: 0437 loss_train: 0.1277 acc_train: 0.9749 loss_val: 0.2912 acc_val: 0.9187 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.466805636882782\nEpoch: 0438 loss_train: 0.1264 acc_train: 0.9793 loss_val: 0.2911 acc_val: 0.9198 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.4669446051120758\nEpoch: 0439 loss_train: 0.1271 acc_train: 0.9782 loss_val: 0.2910 acc_val: 0.9203 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.46560388803482056\nEpoch: 0440 loss_train: 0.1343 acc_train: 0.9793 loss_val: 0.2909 acc_val: 0.9198 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.4676005244255066\nEpoch: 0441 loss_train: 0.1300 acc_train: 0.9782 loss_val: 0.2905 acc_val: 0.9193 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.4679466187953949\nEpoch: 0442 loss_train: 0.1331 acc_train: 0.9727 loss_val: 0.2904 acc_val: 0.9187 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.46744614839553833\nEpoch: 0443 loss_train: 0.1324 acc_train: 0.9760 loss_val: 0.2899 acc_val: 0.9193 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.46730127930641174\nEpoch: 0444 loss_train: 0.1219 acc_train: 0.9793 loss_val: 0.2891 acc_val: 0.9193 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.46785619854927063\nEpoch: 0445 loss_train: 0.1279 acc_train: 0.9738 loss_val: 0.2890 acc_val: 0.9203 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.46707016229629517\nEpoch: 0446 loss_train: 0.1319 acc_train: 0.9738 loss_val: 0.2891 acc_val: 0.9203 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.47032326459884644\nEpoch: 0447 loss_train: 0.1343 acc_train: 0.9760 loss_val: 0.2895 acc_val: 0.9198 time: 0.0093s\nRanking optimizing... \nNow Average NDCG@k =  0.46884095668792725\nEpoch: 0448 loss_train: 0.1329 acc_train: 0.9749 loss_val: 0.2899 acc_val: 0.9198 time: 0.0076s\nRanking optimizing... \nNow Average NDCG@k =  0.4676499664783478\nEpoch: 0449 loss_train: 0.1359 acc_train: 0.9705 loss_val: 0.2907 acc_val: 0.9182 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.46620649099349976\nEpoch: 0450 loss_train: 0.1207 acc_train: 0.9825 loss_val: 0.2916 acc_val: 0.9198 time: 0.0091s\nRanking optimizing... \nNow Average NDCG@k =  0.4663814902305603\nEpoch: 0451 loss_train: 0.1263 acc_train: 0.9760 loss_val: 0.2924 acc_val: 0.9187 time: 0.0075s\nRanking optimizing... \nNow Average NDCG@k =  0.4663331210613251\nEpoch: 0452 loss_train: 0.1422 acc_train: 0.9782 loss_val: 0.2930 acc_val: 0.9187 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.46709197759628296\nEpoch: 0453 loss_train: 0.1294 acc_train: 0.9836 loss_val: 0.2937 acc_val: 0.9187 time: 0.0076s\nRanking optimizing... \nNow Average NDCG@k =  0.4674251675605774\nEpoch: 0454 loss_train: 0.1340 acc_train: 0.9760 loss_val: 0.2942 acc_val: 0.9187 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.4719354510307312\nEpoch: 0455 loss_train: 0.1266 acc_train: 0.9825 loss_val: 0.2944 acc_val: 0.9193 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4702126979827881\nEpoch: 0456 loss_train: 0.1307 acc_train: 0.9771 loss_val: 0.2947 acc_val: 0.9187 time: 0.0122s\nRanking optimizing... \nNow Average NDCG@k =  0.46905243396759033\nEpoch: 0457 loss_train: 0.1339 acc_train: 0.9727 loss_val: 0.2949 acc_val: 0.9182 time: 0.0110s\nRanking optimizing... \nNow Average NDCG@k =  0.4685487449169159\nEpoch: 0458 loss_train: 0.1328 acc_train: 0.9749 loss_val: 0.2951 acc_val: 0.9187 time: 0.0132s\nRanking optimizing... \nNow Average NDCG@k =  0.4686988890171051\nEpoch: 0459 loss_train: 0.1277 acc_train: 0.9760 loss_val: 0.2953 acc_val: 0.9187 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4693264663219452\nEpoch: 0460 loss_train: 0.1356 acc_train: 0.9782 loss_val: 0.2954 acc_val: 0.9193 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4709993898868561\nEpoch: 0461 loss_train: 0.1406 acc_train: 0.9716 loss_val: 0.2952 acc_val: 0.9198 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.4687124490737915\nEpoch: 0462 loss_train: 0.1306 acc_train: 0.9727 loss_val: 0.2951 acc_val: 0.9198 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.4689783453941345\nEpoch: 0463 loss_train: 0.1468 acc_train: 0.9705 loss_val: 0.2949 acc_val: 0.9193 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.4695682227611542\nEpoch: 0464 loss_train: 0.1332 acc_train: 0.9771 loss_val: 0.2949 acc_val: 0.9193 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.46962863206863403\nEpoch: 0465 loss_train: 0.1363 acc_train: 0.9771 loss_val: 0.2950 acc_val: 0.9187 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.47113922238349915\nEpoch: 0466 loss_train: 0.1247 acc_train: 0.9858 loss_val: 0.2950 acc_val: 0.9193 time: 0.0103s\nRanking optimizing... \nNow Average NDCG@k =  0.470461368560791\nEpoch: 0467 loss_train: 0.1297 acc_train: 0.9771 loss_val: 0.2946 acc_val: 0.9209 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.4707536995410919\nEpoch: 0468 loss_train: 0.1299 acc_train: 0.9771 loss_val: 0.2944 acc_val: 0.9209 time: 0.0106s\nRanking optimizing... \nNow Average NDCG@k =  0.4708462357521057\nEpoch: 0469 loss_train: 0.1285 acc_train: 0.9760 loss_val: 0.2941 acc_val: 0.9209 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.4685174822807312\nEpoch: 0470 loss_train: 0.1325 acc_train: 0.9836 loss_val: 0.2942 acc_val: 0.9203 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.469573050737381\nEpoch: 0471 loss_train: 0.1193 acc_train: 0.9869 loss_val: 0.2945 acc_val: 0.9187 time: 0.0116s\nRanking optimizing... \nNow Average NDCG@k =  0.4705362915992737\nEpoch: 0472 loss_train: 0.1272 acc_train: 0.9760 loss_val: 0.2948 acc_val: 0.9171 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.47261983156204224\nEpoch: 0473 loss_train: 0.1220 acc_train: 0.9847 loss_val: 0.2951 acc_val: 0.9176 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.4703923165798187\nEpoch: 0474 loss_train: 0.1377 acc_train: 0.9705 loss_val: 0.2956 acc_val: 0.9176 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.47021999955177307\nEpoch: 0475 loss_train: 0.1378 acc_train: 0.9727 loss_val: 0.2958 acc_val: 0.9171 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.46891719102859497\nEpoch: 0476 loss_train: 0.1256 acc_train: 0.9803 loss_val: 0.2960 acc_val: 0.9193 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.46975618600845337\nEpoch: 0477 loss_train: 0.1337 acc_train: 0.9771 loss_val: 0.2958 acc_val: 0.9193 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.46925973892211914\nEpoch: 0478 loss_train: 0.1380 acc_train: 0.9771 loss_val: 0.2959 acc_val: 0.9187 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.47101613879203796\nEpoch: 0479 loss_train: 0.1136 acc_train: 0.9891 loss_val: 0.2960 acc_val: 0.9193 time: 0.0093s\nRanking optimizing... \nNow Average NDCG@k =  0.47095537185668945\nEpoch: 0480 loss_train: 0.1344 acc_train: 0.9803 loss_val: 0.2964 acc_val: 0.9193 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.46837830543518066\nEpoch: 0481 loss_train: 0.1291 acc_train: 0.9749 loss_val: 0.2967 acc_val: 0.9187 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.47118741273880005\nEpoch: 0482 loss_train: 0.1191 acc_train: 0.9880 loss_val: 0.2975 acc_val: 0.9176 time: 0.0096s\nRanking optimizing... \nNow Average NDCG@k =  0.46995076537132263\nEpoch: 0483 loss_train: 0.1314 acc_train: 0.9793 loss_val: 0.2983 acc_val: 0.9176 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.4716394245624542\nEpoch: 0484 loss_train: 0.1282 acc_train: 0.9749 loss_val: 0.2990 acc_val: 0.9176 time: 0.0099s\nRanking optimizing... \nNow Average NDCG@k =  0.47170138359069824\nEpoch: 0485 loss_train: 0.1389 acc_train: 0.9727 loss_val: 0.2994 acc_val: 0.9176 time: 0.0120s\nRanking optimizing... \nNow Average NDCG@k =  0.4708210825920105\nEpoch: 0486 loss_train: 0.1299 acc_train: 0.9793 loss_val: 0.2996 acc_val: 0.9182 time: 0.0104s\nRanking optimizing... \nNow Average NDCG@k =  0.4690832197666168\nEpoch: 0487 loss_train: 0.1311 acc_train: 0.9836 loss_val: 0.2996 acc_val: 0.9182 time: 0.0100s\nRanking optimizing... \nNow Average NDCG@k =  0.47025081515312195\nEpoch: 0488 loss_train: 0.1196 acc_train: 0.9825 loss_val: 0.2994 acc_val: 0.9187 time: 0.0118s\nRanking optimizing... \nNow Average NDCG@k =  0.4722825884819031\nEpoch: 0489 loss_train: 0.1238 acc_train: 0.9814 loss_val: 0.2989 acc_val: 0.9193 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.47202321887016296\nEpoch: 0490 loss_train: 0.1215 acc_train: 0.9793 loss_val: 0.2986 acc_val: 0.9198 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4717268943786621\nEpoch: 0491 loss_train: 0.1223 acc_train: 0.9858 loss_val: 0.2985 acc_val: 0.9203 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.47201183438301086\nEpoch: 0492 loss_train: 0.1382 acc_train: 0.9771 loss_val: 0.2984 acc_val: 0.9193 time: 0.0101s\nRanking optimizing... \nNow Average NDCG@k =  0.4697633683681488\nEpoch: 0493 loss_train: 0.1202 acc_train: 0.9814 loss_val: 0.2974 acc_val: 0.9203 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.47338956594467163\nEpoch: 0494 loss_train: 0.1286 acc_train: 0.9771 loss_val: 0.2968 acc_val: 0.9187 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.4717005789279938\nEpoch: 0495 loss_train: 0.1295 acc_train: 0.9716 loss_val: 0.2965 acc_val: 0.9193 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.4717825949192047\nEpoch: 0496 loss_train: 0.1257 acc_train: 0.9803 loss_val: 0.2965 acc_val: 0.9182 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.4724629521369934\nEpoch: 0497 loss_train: 0.1234 acc_train: 0.9803 loss_val: 0.2963 acc_val: 0.9187 time: 0.0134s\nRanking optimizing... \nNow Average NDCG@k =  0.47293105721473694\nEpoch: 0498 loss_train: 0.1342 acc_train: 0.9738 loss_val: 0.2958 acc_val: 0.9193 time: 0.0102s\nRanking optimizing... \nNow Average NDCG@k =  0.4731147289276123\nEpoch: 0499 loss_train: 0.1180 acc_train: 0.9836 loss_val: 0.2957 acc_val: 0.9198 time: 0.0112s\nRanking optimizing... \nNow Average NDCG@k =  0.4721985161304474\nEpoch: 0500 loss_train: 0.1341 acc_train: 0.9803 loss_val: 0.2958 acc_val: 0.9193 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.472404807806015\nTest set results: loss= 0.2776 accuracy= 0.9209\n"], ["node classification", "feature", "NDCG", "coauthor-phy", "SGC", "Command 'cd node\\ classification; time python REDRESS_feature_NDCG.py --dataset coauthor-phy --model SGC' returned non-zero exit status 1."], ["node classification", "feature", "NDCG", "coauthor-phy", "GCN", "Command 'cd node\\ classification; time python REDRESS_feature_NDCG.py --dataset coauthor-phy --model GCN' returned non-zero exit status 1."], ["node classification", "feature", "ERR", "ACM", "SGC", "ACM\nUsing ACM dataset\nEpoch: 0001 loss_train: 2.1953 acc_train: 0.1117 loss_val: 2.1741 acc_val: 0.1833 time: 0.5481s\nEpoch: 0002 loss_train: 2.1691 acc_train: 0.2027 loss_val: 2.1535 acc_val: 0.3186 time: 0.0023s\nEpoch: 0003 loss_train: 2.1431 acc_train: 0.3871 loss_val: 2.1330 acc_val: 0.4072 time: 0.0019s\nEpoch: 0004 loss_train: 2.1175 acc_train: 0.5061 loss_val: 2.1129 acc_val: 0.4715 time: 0.0019s\nEpoch: 0005 loss_train: 2.0922 acc_train: 0.5680 loss_val: 2.0929 acc_val: 0.5176 time: 0.0019s\nEpoch: 0006 loss_train: 2.0671 acc_train: 0.6092 loss_val: 2.0732 acc_val: 0.5419 time: 0.0019s\nEpoch: 0007 loss_train: 2.0424 acc_train: 0.6286 loss_val: 2.0538 acc_val: 0.5643 time: 0.0019s\nEpoch: 0008 loss_train: 2.0180 acc_train: 0.6456 loss_val: 2.0346 acc_val: 0.5722 time: 0.0018s\nEpoch: 0009 loss_train: 1.9939 acc_train: 0.6578 loss_val: 2.0157 acc_val: 0.5777 time: 0.0018s\nEpoch: 0010 loss_train: 1.9701 acc_train: 0.6699 loss_val: 1.9971 acc_val: 0.5874 time: 0.0018s\nEpoch: 0011 loss_train: 1.9467 acc_train: 0.6820 loss_val: 1.9787 acc_val: 0.5898 time: 0.0018s\nEpoch: 0012 loss_train: 1.9236 acc_train: 0.6942 loss_val: 1.9606 acc_val: 0.5934 time: 0.0018s\nEpoch: 0013 loss_train: 1.9008 acc_train: 0.7051 loss_val: 1.9428 acc_val: 0.5977 time: 0.0018s\nEpoch: 0014 loss_train: 1.8784 acc_train: 0.7100 loss_val: 1.9253 acc_val: 0.5989 time: 0.0019s\nEpoch: 0015 loss_train: 1.8563 acc_train: 0.7124 loss_val: 1.9081 acc_val: 0.6001 time: 0.0019s\nEpoch: 0016 loss_train: 1.8346 acc_train: 0.7184 loss_val: 1.8912 acc_val: 0.6038 time: 0.0019s\nEpoch: 0017 loss_train: 1.8132 acc_train: 0.7197 loss_val: 1.8745 acc_val: 0.6086 time: 0.0019s\nEpoch: 0018 loss_train: 1.7921 acc_train: 0.7221 loss_val: 1.8582 acc_val: 0.6098 time: 0.0019s\nEpoch: 0019 loss_train: 1.7714 acc_train: 0.7245 loss_val: 1.8422 acc_val: 0.6104 time: 0.0019s\nEpoch: 0020 loss_train: 1.7510 acc_train: 0.7282 loss_val: 1.8264 acc_val: 0.6123 time: 0.0020s\nEpoch: 0021 loss_train: 1.7310 acc_train: 0.7306 loss_val: 1.8110 acc_val: 0.6129 time: 0.0019s\nEpoch: 0022 loss_train: 1.7113 acc_train: 0.7318 loss_val: 1.7959 acc_val: 0.6129 time: 0.0020s\nEpoch: 0023 loss_train: 1.6919 acc_train: 0.7306 loss_val: 1.7810 acc_val: 0.6117 time: 0.0019s\nEpoch: 0024 loss_train: 1.6729 acc_train: 0.7330 loss_val: 1.7664 acc_val: 0.6123 time: 0.0020s\nEpoch: 0025 loss_train: 1.6542 acc_train: 0.7354 loss_val: 1.7522 acc_val: 0.6117 time: 0.0018s\nEpoch: 0026 loss_train: 1.6359 acc_train: 0.7354 loss_val: 1.7382 acc_val: 0.6135 time: 0.0019s\nEpoch: 0027 loss_train: 1.6179 acc_train: 0.7330 loss_val: 1.7244 acc_val: 0.6123 time: 0.0019s\nEpoch: 0028 loss_train: 1.6002 acc_train: 0.7367 loss_val: 1.7110 acc_val: 0.6141 time: 0.0019s\nEpoch: 0029 loss_train: 1.5828 acc_train: 0.7415 loss_val: 1.6978 acc_val: 0.6135 time: 0.0019s\nEpoch: 0030 loss_train: 1.5658 acc_train: 0.7427 loss_val: 1.6849 acc_val: 0.6171 time: 0.0019s\nEpoch: 0031 loss_train: 1.5491 acc_train: 0.7439 loss_val: 1.6722 acc_val: 0.6183 time: 0.0018s\nEpoch: 0032 loss_train: 1.5326 acc_train: 0.7464 loss_val: 1.6598 acc_val: 0.6177 time: 0.0018s\nEpoch: 0033 loss_train: 1.5165 acc_train: 0.7476 loss_val: 1.6477 acc_val: 0.6183 time: 0.0018s\nEpoch: 0034 loss_train: 1.5007 acc_train: 0.7500 loss_val: 1.6358 acc_val: 0.6189 time: 0.0018s\nEpoch: 0035 loss_train: 1.4852 acc_train: 0.7488 loss_val: 1.6241 acc_val: 0.6189 time: 0.0019s\nEpoch: 0036 loss_train: 1.4700 acc_train: 0.7500 loss_val: 1.6127 acc_val: 0.6189 time: 0.0019s\nEpoch: 0037 loss_train: 1.4550 acc_train: 0.7524 loss_val: 1.6014 acc_val: 0.6189 time: 0.0019s\nEpoch: 0038 loss_train: 1.4403 acc_train: 0.7524 loss_val: 1.5905 acc_val: 0.6201 time: 0.0019s\nEpoch: 0039 loss_train: 1.4259 acc_train: 0.7524 loss_val: 1.5797 acc_val: 0.6208 time: 0.0019s\nEpoch: 0040 loss_train: 1.4118 acc_train: 0.7561 loss_val: 1.5691 acc_val: 0.6214 time: 0.0019s\nEpoch: 0041 loss_train: 1.3979 acc_train: 0.7561 loss_val: 1.5588 acc_val: 0.6238 time: 0.0018s\nEpoch: 0042 loss_train: 1.3843 acc_train: 0.7573 loss_val: 1.5487 acc_val: 0.6250 time: 0.0018s\nEpoch: 0043 loss_train: 1.3709 acc_train: 0.7597 loss_val: 1.5388 acc_val: 0.6274 time: 0.0019s\nEpoch: 0044 loss_train: 1.3578 acc_train: 0.7597 loss_val: 1.5291 acc_val: 0.6286 time: 0.0018s\nEpoch: 0045 loss_train: 1.3449 acc_train: 0.7597 loss_val: 1.5196 acc_val: 0.6317 time: 0.0019s\nEpoch: 0046 loss_train: 1.3323 acc_train: 0.7597 loss_val: 1.5103 acc_val: 0.6341 time: 0.0018s\nEpoch: 0047 loss_train: 1.3199 acc_train: 0.7597 loss_val: 1.5011 acc_val: 0.6335 time: 0.0018s\nEpoch: 0048 loss_train: 1.3077 acc_train: 0.7609 loss_val: 1.4922 acc_val: 0.6341 time: 0.0018s\nEpoch: 0049 loss_train: 1.2957 acc_train: 0.7597 loss_val: 1.4835 acc_val: 0.6341 time: 0.0018s\nEpoch: 0050 loss_train: 1.2840 acc_train: 0.7621 loss_val: 1.4749 acc_val: 0.6341 time: 0.0018s\nEpoch: 0051 loss_train: 1.2724 acc_train: 0.7633 loss_val: 1.4665 acc_val: 0.6341 time: 0.0019s\nEpoch: 0052 loss_train: 1.2611 acc_train: 0.7658 loss_val: 1.4583 acc_val: 0.6347 time: 0.0019s\nEpoch: 0053 loss_train: 1.2499 acc_train: 0.7670 loss_val: 1.4502 acc_val: 0.6371 time: 0.0019s\nEpoch: 0054 loss_train: 1.2390 acc_train: 0.7694 loss_val: 1.4424 acc_val: 0.6365 time: 0.0019s\nEpoch: 0055 loss_train: 1.2283 acc_train: 0.7694 loss_val: 1.4346 acc_val: 0.6377 time: 0.0018s\nEpoch: 0056 loss_train: 1.2177 acc_train: 0.7731 loss_val: 1.4271 acc_val: 0.6365 time: 0.0019s\nEpoch: 0057 loss_train: 1.2073 acc_train: 0.7755 loss_val: 1.4196 acc_val: 0.6371 time: 0.0018s\nEpoch: 0058 loss_train: 1.1971 acc_train: 0.7803 loss_val: 1.4123 acc_val: 0.6390 time: 0.0019s\nEpoch: 0059 loss_train: 1.1871 acc_train: 0.7803 loss_val: 1.4052 acc_val: 0.6414 time: 0.0018s\nEpoch: 0060 loss_train: 1.1772 acc_train: 0.7828 loss_val: 1.3982 acc_val: 0.6414 time: 0.0019s\nEpoch: 0061 loss_train: 1.1675 acc_train: 0.7840 loss_val: 1.3913 acc_val: 0.6414 time: 0.0018s\nEpoch: 0062 loss_train: 1.1580 acc_train: 0.7852 loss_val: 1.3846 acc_val: 0.6426 time: 0.0018s\nEpoch: 0063 loss_train: 1.1486 acc_train: 0.7864 loss_val: 1.3780 acc_val: 0.6438 time: 0.0018s\nEpoch: 0064 loss_train: 1.1394 acc_train: 0.7876 loss_val: 1.3715 acc_val: 0.6444 time: 0.0019s\nEpoch: 0065 loss_train: 1.1303 acc_train: 0.7900 loss_val: 1.3652 acc_val: 0.6444 time: 0.0018s\nEpoch: 0066 loss_train: 1.1214 acc_train: 0.7888 loss_val: 1.3589 acc_val: 0.6468 time: 0.0019s\nEpoch: 0067 loss_train: 1.1126 acc_train: 0.7900 loss_val: 1.3528 acc_val: 0.6481 time: 0.0018s\nEpoch: 0068 loss_train: 1.1040 acc_train: 0.7900 loss_val: 1.3468 acc_val: 0.6481 time: 0.0018s\nEpoch: 0069 loss_train: 1.0955 acc_train: 0.7913 loss_val: 1.3408 acc_val: 0.6481 time: 0.0018s\nEpoch: 0070 loss_train: 1.0871 acc_train: 0.7913 loss_val: 1.3350 acc_val: 0.6481 time: 0.0018s\nEpoch: 0071 loss_train: 1.0789 acc_train: 0.7913 loss_val: 1.3293 acc_val: 0.6499 time: 0.0018s\nEpoch: 0072 loss_train: 1.0708 acc_train: 0.7961 loss_val: 1.3237 acc_val: 0.6505 time: 0.0018s\nEpoch: 0073 loss_train: 1.0628 acc_train: 0.8022 loss_val: 1.3182 acc_val: 0.6523 time: 0.0019s\nEpoch: 0074 loss_train: 1.0549 acc_train: 0.8058 loss_val: 1.3128 acc_val: 0.6529 time: 0.0018s\nEpoch: 0075 loss_train: 1.0472 acc_train: 0.8070 loss_val: 1.3075 acc_val: 0.6547 time: 0.0019s\nEpoch: 0076 loss_train: 1.0396 acc_train: 0.8083 loss_val: 1.3023 acc_val: 0.6566 time: 0.0018s\nEpoch: 0077 loss_train: 1.0321 acc_train: 0.8083 loss_val: 1.2972 acc_val: 0.6590 time: 0.0018s\nEpoch: 0078 loss_train: 1.0247 acc_train: 0.8095 loss_val: 1.2922 acc_val: 0.6608 time: 0.0018s\nEpoch: 0079 loss_train: 1.0174 acc_train: 0.8095 loss_val: 1.2873 acc_val: 0.6620 time: 0.0018s\nEpoch: 0080 loss_train: 1.0102 acc_train: 0.8119 loss_val: 1.2824 acc_val: 0.6626 time: 0.0018s\nEpoch: 0081 loss_train: 1.0032 acc_train: 0.8131 loss_val: 1.2777 acc_val: 0.6614 time: 0.0018s\nEpoch: 0082 loss_train: 0.9962 acc_train: 0.8143 loss_val: 1.2730 acc_val: 0.6620 time: 0.0018s\nEpoch: 0083 loss_train: 0.9894 acc_train: 0.8143 loss_val: 1.2684 acc_val: 0.6638 time: 0.0018s\nEpoch: 0084 loss_train: 0.9826 acc_train: 0.8155 loss_val: 1.2639 acc_val: 0.6638 time: 0.0019s\nEpoch: 0085 loss_train: 0.9759 acc_train: 0.8180 loss_val: 1.2595 acc_val: 0.6657 time: 0.0018s\nEpoch: 0086 loss_train: 0.9693 acc_train: 0.8216 loss_val: 1.2551 acc_val: 0.6669 time: 0.0019s\nEpoch: 0087 loss_train: 0.9629 acc_train: 0.8228 loss_val: 1.2509 acc_val: 0.6675 time: 0.0018s\nEpoch: 0088 loss_train: 0.9565 acc_train: 0.8240 loss_val: 1.2467 acc_val: 0.6681 time: 0.0019s\nEpoch: 0089 loss_train: 0.9502 acc_train: 0.8252 loss_val: 1.2425 acc_val: 0.6687 time: 0.0018s\nEpoch: 0090 loss_train: 0.9440 acc_train: 0.8265 loss_val: 1.2385 acc_val: 0.6687 time: 0.0020s\nEpoch: 0091 loss_train: 0.9378 acc_train: 0.8289 loss_val: 1.2345 acc_val: 0.6687 time: 0.0019s\nEpoch: 0092 loss_train: 0.9318 acc_train: 0.8289 loss_val: 1.2306 acc_val: 0.6693 time: 0.0019s\nEpoch: 0093 loss_train: 0.9258 acc_train: 0.8325 loss_val: 1.2267 acc_val: 0.6687 time: 0.0019s\nEpoch: 0094 loss_train: 0.9200 acc_train: 0.8313 loss_val: 1.2229 acc_val: 0.6681 time: 0.0019s\nEpoch: 0095 loss_train: 0.9141 acc_train: 0.8337 loss_val: 1.2192 acc_val: 0.6687 time: 0.0019s\nEpoch: 0096 loss_train: 0.9084 acc_train: 0.8398 loss_val: 1.2155 acc_val: 0.6699 time: 0.0019s\nEpoch: 0097 loss_train: 0.9028 acc_train: 0.8422 loss_val: 1.2119 acc_val: 0.6711 time: 0.0019s\nEpoch: 0098 loss_train: 0.8972 acc_train: 0.8422 loss_val: 1.2084 acc_val: 0.6723 time: 0.0019s\nEpoch: 0099 loss_train: 0.8917 acc_train: 0.8422 loss_val: 1.2049 acc_val: 0.6723 time: 0.0019s\nEpoch: 0100 loss_train: 0.8863 acc_train: 0.8447 loss_val: 1.2015 acc_val: 0.6735 time: 0.0018s\nEpoch: 0101 loss_train: 0.8809 acc_train: 0.8447 loss_val: 1.1981 acc_val: 0.6754 time: 0.0018s\nEpoch: 0102 loss_train: 0.8756 acc_train: 0.8447 loss_val: 1.1948 acc_val: 0.6772 time: 0.0018s\nEpoch: 0103 loss_train: 0.8704 acc_train: 0.8447 loss_val: 1.1916 acc_val: 0.6778 time: 0.0022s\nEpoch: 0104 loss_train: 0.8652 acc_train: 0.8471 loss_val: 1.1883 acc_val: 0.6772 time: 0.0019s\nEpoch: 0105 loss_train: 0.8601 acc_train: 0.8471 loss_val: 1.1852 acc_val: 0.6784 time: 0.0019s\nEpoch: 0106 loss_train: 0.8551 acc_train: 0.8471 loss_val: 1.1821 acc_val: 0.6796 time: 0.0018s\nEpoch: 0107 loss_train: 0.8501 acc_train: 0.8471 loss_val: 1.1790 acc_val: 0.6796 time: 0.0019s\nEpoch: 0108 loss_train: 0.8452 acc_train: 0.8495 loss_val: 1.1760 acc_val: 0.6790 time: 0.0018s\nEpoch: 0109 loss_train: 0.8404 acc_train: 0.8495 loss_val: 1.1731 acc_val: 0.6796 time: 0.0019s\nEpoch: 0110 loss_train: 0.8356 acc_train: 0.8495 loss_val: 1.1702 acc_val: 0.6784 time: 0.0018s\nEpoch: 0111 loss_train: 0.8309 acc_train: 0.8495 loss_val: 1.1673 acc_val: 0.6790 time: 0.0019s\nEpoch: 0112 loss_train: 0.8262 acc_train: 0.8507 loss_val: 1.1645 acc_val: 0.6790 time: 0.0019s\nEpoch: 0113 loss_train: 0.8216 acc_train: 0.8519 loss_val: 1.1617 acc_val: 0.6796 time: 0.0019s\nEpoch: 0114 loss_train: 0.8170 acc_train: 0.8519 loss_val: 1.1590 acc_val: 0.6796 time: 0.0019s\nEpoch: 0115 loss_train: 0.8125 acc_train: 0.8519 loss_val: 1.1563 acc_val: 0.6796 time: 0.0019s\nEpoch: 0116 loss_train: 0.8081 acc_train: 0.8519 loss_val: 1.1537 acc_val: 0.6802 time: 0.0019s\nEpoch: 0117 loss_train: 0.8037 acc_train: 0.8519 loss_val: 1.1511 acc_val: 0.6814 time: 0.0019s\nEpoch: 0118 loss_train: 0.7993 acc_train: 0.8519 loss_val: 1.1485 acc_val: 0.6814 time: 0.0019s\nEpoch: 0119 loss_train: 0.7950 acc_train: 0.8519 loss_val: 1.1460 acc_val: 0.6820 time: 0.0019s\nEpoch: 0120 loss_train: 0.7908 acc_train: 0.8519 loss_val: 1.1435 acc_val: 0.6839 time: 0.0019s\nEpoch: 0121 loss_train: 0.7866 acc_train: 0.8532 loss_val: 1.1411 acc_val: 0.6839 time: 0.0018s\nEpoch: 0122 loss_train: 0.7824 acc_train: 0.8544 loss_val: 1.1387 acc_val: 0.6839 time: 0.0018s\nEpoch: 0123 loss_train: 0.7783 acc_train: 0.8544 loss_val: 1.1364 acc_val: 0.6857 time: 0.0018s\nEpoch: 0124 loss_train: 0.7743 acc_train: 0.8556 loss_val: 1.1340 acc_val: 0.6869 time: 0.0018s\nEpoch: 0125 loss_train: 0.7703 acc_train: 0.8556 loss_val: 1.1317 acc_val: 0.6881 time: 0.0018s\nEpoch: 0126 loss_train: 0.7663 acc_train: 0.8556 loss_val: 1.1295 acc_val: 0.6875 time: 0.0019s\nEpoch: 0127 loss_train: 0.7624 acc_train: 0.8568 loss_val: 1.1273 acc_val: 0.6869 time: 0.0019s\nEpoch: 0128 loss_train: 0.7585 acc_train: 0.8568 loss_val: 1.1251 acc_val: 0.6857 time: 0.0019s\nEpoch: 0129 loss_train: 0.7547 acc_train: 0.8568 loss_val: 1.1229 acc_val: 0.6857 time: 0.0019s\nEpoch: 0130 loss_train: 0.7509 acc_train: 0.8568 loss_val: 1.1208 acc_val: 0.6857 time: 0.0019s\nEpoch: 0131 loss_train: 0.7471 acc_train: 0.8568 loss_val: 1.1187 acc_val: 0.6851 time: 0.0019s\nEpoch: 0132 loss_train: 0.7434 acc_train: 0.8580 loss_val: 1.1167 acc_val: 0.6851 time: 0.0019s\nEpoch: 0133 loss_train: 0.7397 acc_train: 0.8580 loss_val: 1.1147 acc_val: 0.6863 time: 0.0018s\nEpoch: 0134 loss_train: 0.7361 acc_train: 0.8580 loss_val: 1.1127 acc_val: 0.6863 time: 0.0019s\nEpoch: 0135 loss_train: 0.7325 acc_train: 0.8580 loss_val: 1.1107 acc_val: 0.6863 time: 0.0018s\nEpoch: 0136 loss_train: 0.7290 acc_train: 0.8592 loss_val: 1.1088 acc_val: 0.6875 time: 0.0019s\nEpoch: 0137 loss_train: 0.7254 acc_train: 0.8604 loss_val: 1.1069 acc_val: 0.6875 time: 0.0018s\nEpoch: 0138 loss_train: 0.7220 acc_train: 0.8604 loss_val: 1.1050 acc_val: 0.6869 time: 0.0018s\nEpoch: 0139 loss_train: 0.7185 acc_train: 0.8617 loss_val: 1.1032 acc_val: 0.6881 time: 0.0018s\nEpoch: 0140 loss_train: 0.7151 acc_train: 0.8617 loss_val: 1.1014 acc_val: 0.6881 time: 0.0018s\nEpoch: 0141 loss_train: 0.7117 acc_train: 0.8617 loss_val: 1.0996 acc_val: 0.6881 time: 0.0018s\nEpoch: 0142 loss_train: 0.7084 acc_train: 0.8617 loss_val: 1.0978 acc_val: 0.6887 time: 0.0018s\nEpoch: 0143 loss_train: 0.7051 acc_train: 0.8617 loss_val: 1.0961 acc_val: 0.6887 time: 0.0018s\nEpoch: 0144 loss_train: 0.7018 acc_train: 0.8617 loss_val: 1.0944 acc_val: 0.6887 time: 0.0018s\nEpoch: 0145 loss_train: 0.6986 acc_train: 0.8617 loss_val: 1.0927 acc_val: 0.6887 time: 0.0018s\nEpoch: 0146 loss_train: 0.6954 acc_train: 0.8617 loss_val: 1.0911 acc_val: 0.6887 time: 0.0018s\nEpoch: 0147 loss_train: 0.6922 acc_train: 0.8617 loss_val: 1.0894 acc_val: 0.6893 time: 0.0018s\nEpoch: 0148 loss_train: 0.6891 acc_train: 0.8629 loss_val: 1.0878 acc_val: 0.6899 time: 0.0018s\nEpoch: 0149 loss_train: 0.6859 acc_train: 0.8629 loss_val: 1.0863 acc_val: 0.6893 time: 0.0018s\nEpoch: 0150 loss_train: 0.6829 acc_train: 0.8629 loss_val: 1.0847 acc_val: 0.6881 time: 0.0018s\nEpoch: 0151 loss_train: 0.6798 acc_train: 0.8629 loss_val: 1.0832 acc_val: 0.6881 time: 0.0018s\nEpoch: 0152 loss_train: 0.6768 acc_train: 0.8653 loss_val: 1.0817 acc_val: 0.6869 time: 0.0018s\nEpoch: 0153 loss_train: 0.6738 acc_train: 0.8653 loss_val: 1.0802 acc_val: 0.6869 time: 0.0018s\nEpoch: 0154 loss_train: 0.6709 acc_train: 0.8653 loss_val: 1.0787 acc_val: 0.6881 time: 0.0018s\nEpoch: 0155 loss_train: 0.6679 acc_train: 0.8653 loss_val: 1.0773 acc_val: 0.6893 time: 0.0018s\nEpoch: 0156 loss_train: 0.6650 acc_train: 0.8653 loss_val: 1.0759 acc_val: 0.6893 time: 0.0018s\nEpoch: 0157 loss_train: 0.6621 acc_train: 0.8665 loss_val: 1.0745 acc_val: 0.6893 time: 0.0018s\nEpoch: 0158 loss_train: 0.6593 acc_train: 0.8665 loss_val: 1.0731 acc_val: 0.6887 time: 0.0018s\nEpoch: 0159 loss_train: 0.6565 acc_train: 0.8677 loss_val: 1.0717 acc_val: 0.6887 time: 0.0018s\nEpoch: 0160 loss_train: 0.6537 acc_train: 0.8677 loss_val: 1.0704 acc_val: 0.6887 time: 0.0019s\nEpoch: 0161 loss_train: 0.6509 acc_train: 0.8677 loss_val: 1.0691 acc_val: 0.6875 time: 0.0018s\nEpoch: 0162 loss_train: 0.6482 acc_train: 0.8677 loss_val: 1.0678 acc_val: 0.6887 time: 0.0019s\nEpoch: 0163 loss_train: 0.6455 acc_train: 0.8677 loss_val: 1.0665 acc_val: 0.6887 time: 0.0018s\nEpoch: 0164 loss_train: 0.6428 acc_train: 0.8689 loss_val: 1.0653 acc_val: 0.6875 time: 0.0018s\nEpoch: 0165 loss_train: 0.6401 acc_train: 0.8714 loss_val: 1.0640 acc_val: 0.6863 time: 0.0019s\nEpoch: 0166 loss_train: 0.6375 acc_train: 0.8726 loss_val: 1.0628 acc_val: 0.6869 time: 0.0019s\nEpoch: 0167 loss_train: 0.6348 acc_train: 0.8738 loss_val: 1.0616 acc_val: 0.6869 time: 0.0019s\nEpoch: 0168 loss_train: 0.6322 acc_train: 0.8750 loss_val: 1.0604 acc_val: 0.6875 time: 0.0019s\nEpoch: 0169 loss_train: 0.6297 acc_train: 0.8750 loss_val: 1.0593 acc_val: 0.6881 time: 0.0019s\nEpoch: 0170 loss_train: 0.6271 acc_train: 0.8762 loss_val: 1.0581 acc_val: 0.6881 time: 0.0018s\nEpoch: 0171 loss_train: 0.6246 acc_train: 0.8762 loss_val: 1.0570 acc_val: 0.6881 time: 0.0019s\nEpoch: 0172 loss_train: 0.6221 acc_train: 0.8762 loss_val: 1.0559 acc_val: 0.6875 time: 0.0018s\nEpoch: 0173 loss_train: 0.6196 acc_train: 0.8762 loss_val: 1.0548 acc_val: 0.6881 time: 0.0019s\nEpoch: 0174 loss_train: 0.6172 acc_train: 0.8762 loss_val: 1.0537 acc_val: 0.6881 time: 0.0018s\nEpoch: 0175 loss_train: 0.6147 acc_train: 0.8762 loss_val: 1.0527 acc_val: 0.6881 time: 0.0019s\nEpoch: 0176 loss_train: 0.6123 acc_train: 0.8762 loss_val: 1.0516 acc_val: 0.6881 time: 0.0018s\nEpoch: 0177 loss_train: 0.6099 acc_train: 0.8762 loss_val: 1.0506 acc_val: 0.6875 time: 0.0018s\nEpoch: 0178 loss_train: 0.6076 acc_train: 0.8762 loss_val: 1.0496 acc_val: 0.6881 time: 0.0018s\nEpoch: 0179 loss_train: 0.6052 acc_train: 0.8762 loss_val: 1.0486 acc_val: 0.6875 time: 0.0018s\nEpoch: 0180 loss_train: 0.6029 acc_train: 0.8762 loss_val: 1.0476 acc_val: 0.6881 time: 0.0018s\nEpoch: 0181 loss_train: 0.6006 acc_train: 0.8762 loss_val: 1.0467 acc_val: 0.6881 time: 0.0018s\nEpoch: 0182 loss_train: 0.5983 acc_train: 0.8762 loss_val: 1.0457 acc_val: 0.6875 time: 0.0018s\nEpoch: 0183 loss_train: 0.5960 acc_train: 0.8762 loss_val: 1.0448 acc_val: 0.6875 time: 0.0018s\nEpoch: 0184 loss_train: 0.5937 acc_train: 0.8762 loss_val: 1.0439 acc_val: 0.6875 time: 0.0018s\nEpoch: 0185 loss_train: 0.5915 acc_train: 0.8774 loss_val: 1.0430 acc_val: 0.6875 time: 0.0018s\nEpoch: 0186 loss_train: 0.5893 acc_train: 0.8774 loss_val: 1.0421 acc_val: 0.6875 time: 0.0019s\nEpoch: 0187 loss_train: 0.5871 acc_train: 0.8799 loss_val: 1.0412 acc_val: 0.6875 time: 0.0018s\nEpoch: 0188 loss_train: 0.5849 acc_train: 0.8799 loss_val: 1.0403 acc_val: 0.6875 time: 0.0019s\nEpoch: 0189 loss_train: 0.5828 acc_train: 0.8811 loss_val: 1.0395 acc_val: 0.6869 time: 0.0018s\nEpoch: 0190 loss_train: 0.5806 acc_train: 0.8823 loss_val: 1.0386 acc_val: 0.6869 time: 0.0019s\nEpoch: 0191 loss_train: 0.5785 acc_train: 0.8823 loss_val: 1.0378 acc_val: 0.6863 time: 0.0019s\nEpoch: 0192 loss_train: 0.5764 acc_train: 0.8823 loss_val: 1.0370 acc_val: 0.6851 time: 0.0019s\nEpoch: 0193 loss_train: 0.5743 acc_train: 0.8823 loss_val: 1.0362 acc_val: 0.6857 time: 0.0018s\nEpoch: 0194 loss_train: 0.5722 acc_train: 0.8823 loss_val: 1.0354 acc_val: 0.6863 time: 0.0018s\nEpoch: 0195 loss_train: 0.5702 acc_train: 0.8823 loss_val: 1.0347 acc_val: 0.6863 time: 0.0018s\nEpoch: 0196 loss_train: 0.5681 acc_train: 0.8835 loss_val: 1.0339 acc_val: 0.6863 time: 0.0018s\nEpoch: 0197 loss_train: 0.5661 acc_train: 0.8835 loss_val: 1.0332 acc_val: 0.6857 time: 0.0018s\nEpoch: 0198 loss_train: 0.5641 acc_train: 0.8835 loss_val: 1.0324 acc_val: 0.6857 time: 0.0018s\nEpoch: 0199 loss_train: 0.5621 acc_train: 0.8847 loss_val: 1.0317 acc_val: 0.6857 time: 0.0018s\nEpoch: 0200 loss_train: 0.5601 acc_train: 0.8859 loss_val: 1.0310 acc_val: 0.6857 time: 0.0018s\nEpoch: 0201 loss_train: 0.5582 acc_train: 0.8871 loss_val: 1.0303 acc_val: 0.6857 time: 0.0018s\nEpoch: 0202 loss_train: 0.5562 acc_train: 0.8871 loss_val: 1.0296 acc_val: 0.6857 time: 0.0018s\nEpoch: 0203 loss_train: 0.5543 acc_train: 0.8883 loss_val: 1.0289 acc_val: 0.6857 time: 0.0019s\nEpoch: 0204 loss_train: 0.5524 acc_train: 0.8896 loss_val: 1.0283 acc_val: 0.6857 time: 0.0019s\nEpoch: 0205 loss_train: 0.5505 acc_train: 0.8896 loss_val: 1.0276 acc_val: 0.6857 time: 0.0019s\nEpoch: 0206 loss_train: 0.5486 acc_train: 0.8896 loss_val: 1.0270 acc_val: 0.6857 time: 0.0018s\nEpoch: 0207 loss_train: 0.5467 acc_train: 0.8896 loss_val: 1.0264 acc_val: 0.6857 time: 0.0019s\nEpoch: 0208 loss_train: 0.5449 acc_train: 0.8896 loss_val: 1.0257 acc_val: 0.6857 time: 0.0018s\nEpoch: 0209 loss_train: 0.5430 acc_train: 0.8920 loss_val: 1.0251 acc_val: 0.6851 time: 0.0019s\nEpoch: 0210 loss_train: 0.5412 acc_train: 0.8932 loss_val: 1.0245 acc_val: 0.6851 time: 0.0018s\nEpoch: 0211 loss_train: 0.5394 acc_train: 0.8932 loss_val: 1.0239 acc_val: 0.6851 time: 0.0019s\nEpoch: 0212 loss_train: 0.5376 acc_train: 0.8932 loss_val: 1.0234 acc_val: 0.6845 time: 0.0018s\nEpoch: 0213 loss_train: 0.5358 acc_train: 0.8932 loss_val: 1.0228 acc_val: 0.6851 time: 0.0018s\nEpoch: 0214 loss_train: 0.5340 acc_train: 0.8932 loss_val: 1.0222 acc_val: 0.6857 time: 0.0018s\nEpoch: 0215 loss_train: 0.5323 acc_train: 0.8932 loss_val: 1.0217 acc_val: 0.6857 time: 0.0018s\nEpoch: 0216 loss_train: 0.5305 acc_train: 0.8932 loss_val: 1.0211 acc_val: 0.6857 time: 0.0018s\nEpoch: 0217 loss_train: 0.5288 acc_train: 0.8932 loss_val: 1.0206 acc_val: 0.6857 time: 0.0018s\nEpoch: 0218 loss_train: 0.5271 acc_train: 0.8956 loss_val: 1.0201 acc_val: 0.6851 time: 0.0018s\nEpoch: 0219 loss_train: 0.5253 acc_train: 0.8956 loss_val: 1.0196 acc_val: 0.6851 time: 0.0018s\nEpoch: 0220 loss_train: 0.5236 acc_train: 0.8956 loss_val: 1.0191 acc_val: 0.6851 time: 0.0018s\nEpoch: 0221 loss_train: 0.5220 acc_train: 0.8956 loss_val: 1.0186 acc_val: 0.6857 time: 0.0018s\nEpoch: 0222 loss_train: 0.5203 acc_train: 0.8956 loss_val: 1.0181 acc_val: 0.6857 time: 0.0018s\nEpoch: 0223 loss_train: 0.5186 acc_train: 0.8956 loss_val: 1.0176 acc_val: 0.6863 time: 0.0018s\nEpoch: 0224 loss_train: 0.5170 acc_train: 0.8956 loss_val: 1.0172 acc_val: 0.6863 time: 0.0018s\nEpoch: 0225 loss_train: 0.5153 acc_train: 0.8968 loss_val: 1.0167 acc_val: 0.6863 time: 0.0018s\nEpoch: 0226 loss_train: 0.5137 acc_train: 0.8968 loss_val: 1.0162 acc_val: 0.6863 time: 0.0018s\nEpoch: 0227 loss_train: 0.5121 acc_train: 0.8968 loss_val: 1.0158 acc_val: 0.6857 time: 0.0018s\nEpoch: 0228 loss_train: 0.5105 acc_train: 0.8968 loss_val: 1.0154 acc_val: 0.6857 time: 0.0018s\nEpoch: 0229 loss_train: 0.5089 acc_train: 0.9005 loss_val: 1.0149 acc_val: 0.6857 time: 0.0019s\nEpoch: 0230 loss_train: 0.5073 acc_train: 0.9017 loss_val: 1.0145 acc_val: 0.6857 time: 0.0018s\nEpoch: 0231 loss_train: 0.5058 acc_train: 0.9017 loss_val: 1.0141 acc_val: 0.6857 time: 0.0018s\nEpoch: 0232 loss_train: 0.5042 acc_train: 0.9017 loss_val: 1.0137 acc_val: 0.6857 time: 0.0018s\nEpoch: 0233 loss_train: 0.5027 acc_train: 0.9017 loss_val: 1.0133 acc_val: 0.6857 time: 0.0018s\nEpoch: 0234 loss_train: 0.5011 acc_train: 0.9017 loss_val: 1.0129 acc_val: 0.6869 time: 0.0018s\nEpoch: 0235 loss_train: 0.4996 acc_train: 0.9017 loss_val: 1.0126 acc_val: 0.6863 time: 0.0018s\nEpoch: 0236 loss_train: 0.4981 acc_train: 0.9017 loss_val: 1.0122 acc_val: 0.6863 time: 0.0018s\nEpoch: 0237 loss_train: 0.4966 acc_train: 0.9017 loss_val: 1.0118 acc_val: 0.6869 time: 0.0018s\nEpoch: 0238 loss_train: 0.4951 acc_train: 0.9017 loss_val: 1.0115 acc_val: 0.6863 time: 0.0018s\nEpoch: 0239 loss_train: 0.4936 acc_train: 0.9017 loss_val: 1.0111 acc_val: 0.6863 time: 0.0018s\nEpoch: 0240 loss_train: 0.4921 acc_train: 0.9017 loss_val: 1.0108 acc_val: 0.6869 time: 0.0019s\nEpoch: 0241 loss_train: 0.4907 acc_train: 0.9017 loss_val: 1.0104 acc_val: 0.6875 time: 0.0018s\nEpoch: 0242 loss_train: 0.4892 acc_train: 0.9017 loss_val: 1.0101 acc_val: 0.6875 time: 0.0018s\nEpoch: 0243 loss_train: 0.4878 acc_train: 0.9017 loss_val: 1.0098 acc_val: 0.6875 time: 0.0018s\nEpoch: 0244 loss_train: 0.4863 acc_train: 0.9017 loss_val: 1.0095 acc_val: 0.6869 time: 0.0018s\nEpoch: 0245 loss_train: 0.4849 acc_train: 0.9017 loss_val: 1.0092 acc_val: 0.6869 time: 0.0018s\nEpoch: 0246 loss_train: 0.4835 acc_train: 0.9029 loss_val: 1.0089 acc_val: 0.6869 time: 0.0019s\nEpoch: 0247 loss_train: 0.4821 acc_train: 0.9053 loss_val: 1.0086 acc_val: 0.6869 time: 0.0019s\nEpoch: 0248 loss_train: 0.4807 acc_train: 0.9053 loss_val: 1.0083 acc_val: 0.6869 time: 0.0019s\nEpoch: 0249 loss_train: 0.4793 acc_train: 0.9053 loss_val: 1.0080 acc_val: 0.6863 time: 0.0019s\nEpoch: 0250 loss_train: 0.4779 acc_train: 0.9066 loss_val: 1.0077 acc_val: 0.6863 time: 0.0019s\nEpoch: 0251 loss_train: 0.4765 acc_train: 0.9066 loss_val: 1.0075 acc_val: 0.6863 time: 0.0019s\nEpoch: 0252 loss_train: 0.4752 acc_train: 0.9066 loss_val: 1.0072 acc_val: 0.6869 time: 0.0018s\nEpoch: 0253 loss_train: 0.4738 acc_train: 0.9090 loss_val: 1.0070 acc_val: 0.6875 time: 0.0019s\nEpoch: 0254 loss_train: 0.4725 acc_train: 0.9090 loss_val: 1.0067 acc_val: 0.6869 time: 0.0018s\nEpoch: 0255 loss_train: 0.4711 acc_train: 0.9090 loss_val: 1.0065 acc_val: 0.6875 time: 0.0019s\nEpoch: 0256 loss_train: 0.4698 acc_train: 0.9090 loss_val: 1.0062 acc_val: 0.6869 time: 0.0018s\nEpoch: 0257 loss_train: 0.4685 acc_train: 0.9090 loss_val: 1.0060 acc_val: 0.6869 time: 0.0019s\nEpoch: 0258 loss_train: 0.4672 acc_train: 0.9090 loss_val: 1.0058 acc_val: 0.6869 time: 0.0018s\nEpoch: 0259 loss_train: 0.4659 acc_train: 0.9090 loss_val: 1.0056 acc_val: 0.6869 time: 0.0019s\nEpoch: 0260 loss_train: 0.4646 acc_train: 0.9090 loss_val: 1.0054 acc_val: 0.6875 time: 0.0018s\nEpoch: 0261 loss_train: 0.4633 acc_train: 0.9102 loss_val: 1.0051 acc_val: 0.6869 time: 0.0018s\nEpoch: 0262 loss_train: 0.4620 acc_train: 0.9102 loss_val: 1.0049 acc_val: 0.6869 time: 0.0018s\nEpoch: 0263 loss_train: 0.4608 acc_train: 0.9114 loss_val: 1.0047 acc_val: 0.6875 time: 0.0018s\nEpoch: 0264 loss_train: 0.4595 acc_train: 0.9126 loss_val: 1.0046 acc_val: 0.6893 time: 0.0018s\nEpoch: 0265 loss_train: 0.4582 acc_train: 0.9126 loss_val: 1.0044 acc_val: 0.6905 time: 0.0018s\nEpoch: 0266 loss_train: 0.4570 acc_train: 0.9138 loss_val: 1.0042 acc_val: 0.6905 time: 0.0018s\nEpoch: 0267 loss_train: 0.4557 acc_train: 0.9150 loss_val: 1.0040 acc_val: 0.6905 time: 0.0018s\nEpoch: 0268 loss_train: 0.4545 acc_train: 0.9150 loss_val: 1.0038 acc_val: 0.6899 time: 0.0018s\nEpoch: 0269 loss_train: 0.4533 acc_train: 0.9163 loss_val: 1.0037 acc_val: 0.6899 time: 0.0018s\nEpoch: 0270 loss_train: 0.4521 acc_train: 0.9175 loss_val: 1.0035 acc_val: 0.6899 time: 0.0018s\nEpoch: 0271 loss_train: 0.4509 acc_train: 0.9187 loss_val: 1.0034 acc_val: 0.6899 time: 0.0018s\nEpoch: 0272 loss_train: 0.4497 acc_train: 0.9187 loss_val: 1.0032 acc_val: 0.6899 time: 0.0018s\nEpoch: 0273 loss_train: 0.4485 acc_train: 0.9187 loss_val: 1.0031 acc_val: 0.6899 time: 0.0018s\nEpoch: 0274 loss_train: 0.4473 acc_train: 0.9187 loss_val: 1.0029 acc_val: 0.6899 time: 0.0019s\nEpoch: 0275 loss_train: 0.4461 acc_train: 0.9187 loss_val: 1.0028 acc_val: 0.6899 time: 0.0018s\nEpoch: 0276 loss_train: 0.4449 acc_train: 0.9187 loss_val: 1.0027 acc_val: 0.6899 time: 0.0019s\nEpoch: 0277 loss_train: 0.4438 acc_train: 0.9199 loss_val: 1.0025 acc_val: 0.6899 time: 0.0019s\nEpoch: 0278 loss_train: 0.4426 acc_train: 0.9199 loss_val: 1.0024 acc_val: 0.6899 time: 0.0019s\nEpoch: 0279 loss_train: 0.4414 acc_train: 0.9199 loss_val: 1.0023 acc_val: 0.6899 time: 0.0018s\nEpoch: 0280 loss_train: 0.4403 acc_train: 0.9199 loss_val: 1.0022 acc_val: 0.6905 time: 0.0018s\nEpoch: 0281 loss_train: 0.4392 acc_train: 0.9199 loss_val: 1.0021 acc_val: 0.6899 time: 0.0018s\nEpoch: 0282 loss_train: 0.4380 acc_train: 0.9199 loss_val: 1.0020 acc_val: 0.6899 time: 0.0018s\nEpoch: 0283 loss_train: 0.4369 acc_train: 0.9199 loss_val: 1.0019 acc_val: 0.6899 time: 0.0018s\nEpoch: 0284 loss_train: 0.4358 acc_train: 0.9199 loss_val: 1.0018 acc_val: 0.6899 time: 0.0018s\nEpoch: 0285 loss_train: 0.4347 acc_train: 0.9199 loss_val: 1.0017 acc_val: 0.6905 time: 0.0018s\nEpoch: 0286 loss_train: 0.4336 acc_train: 0.9211 loss_val: 1.0016 acc_val: 0.6905 time: 0.0018s\nEpoch: 0287 loss_train: 0.4325 acc_train: 0.9211 loss_val: 1.0015 acc_val: 0.6911 time: 0.0018s\nEpoch: 0288 loss_train: 0.4314 acc_train: 0.9211 loss_val: 1.0015 acc_val: 0.6911 time: 0.0018s\nEpoch: 0289 loss_train: 0.4303 acc_train: 0.9211 loss_val: 1.0014 acc_val: 0.6911 time: 0.0018s\nEpoch: 0290 loss_train: 0.4292 acc_train: 0.9223 loss_val: 1.0013 acc_val: 0.6911 time: 0.0018s\nEpoch: 0291 loss_train: 0.4281 acc_train: 0.9235 loss_val: 1.0013 acc_val: 0.6911 time: 0.0018s\nEpoch: 0292 loss_train: 0.4271 acc_train: 0.9235 loss_val: 1.0012 acc_val: 0.6911 time: 0.0018s\nEpoch: 0293 loss_train: 0.4260 acc_train: 0.9223 loss_val: 1.0011 acc_val: 0.6911 time: 0.0018s\nEpoch: 0294 loss_train: 0.4249 acc_train: 0.9223 loss_val: 1.0011 acc_val: 0.6911 time: 0.0018s\nEpoch: 0295 loss_train: 0.4239 acc_train: 0.9223 loss_val: 1.0010 acc_val: 0.6911 time: 0.0018s\nEpoch: 0296 loss_train: 0.4228 acc_train: 0.9235 loss_val: 1.0010 acc_val: 0.6924 time: 0.0018s\nEpoch: 0297 loss_train: 0.4218 acc_train: 0.9235 loss_val: 1.0010 acc_val: 0.6924 time: 0.0018s\nEpoch: 0298 loss_train: 0.4208 acc_train: 0.9235 loss_val: 1.0009 acc_val: 0.6924 time: 0.0019s\nEpoch: 0299 loss_train: 0.4197 acc_train: 0.9235 loss_val: 1.0009 acc_val: 0.6924 time: 0.0018s\nEpoch: 0300 loss_train: 0.4187 acc_train: 0.9235 loss_val: 1.0009 acc_val: 0.6917 time: 0.0018s\nEpoch: 0001 loss_train: 0.4177 acc_train: 0.9223 loss_val: 1.0009 acc_val: 0.6917 time: 0.0015s\nRanking optimizing... \nNow Average ERR@k =  0.804981529712677\nEpoch: 0002 loss_train: 0.4169 acc_train: 0.9235 loss_val: 1.0018 acc_val: 0.6899 time: 0.0067s\nRanking optimizing... \nNow Average ERR@k =  0.8059852719306946\nEpoch: 0003 loss_train: 0.4164 acc_train: 0.9235 loss_val: 1.0034 acc_val: 0.6887 time: 0.0040s\nRanking optimizing... \nNow Average ERR@k =  0.8069812655448914\nEpoch: 0004 loss_train: 0.4162 acc_train: 0.9235 loss_val: 1.0056 acc_val: 0.6924 time: 0.0036s\nRanking optimizing... \nNow Average ERR@k =  0.8073820471763611\nEpoch: 0005 loss_train: 0.4166 acc_train: 0.9235 loss_val: 1.0085 acc_val: 0.6911 time: 0.0031s\nRanking optimizing... \nNow Average ERR@k =  0.8086826205253601\nEpoch: 0006 loss_train: 0.4174 acc_train: 0.9211 loss_val: 1.0122 acc_val: 0.6899 time: 0.0028s\nRanking optimizing... \nNow Average ERR@k =  0.8107191324234009\nEpoch: 0007 loss_train: 0.4189 acc_train: 0.9223 loss_val: 1.0167 acc_val: 0.6905 time: 0.0048s\nRanking optimizing... \nNow Average ERR@k =  0.8117743134498596\nEpoch: 0008 loss_train: 0.4211 acc_train: 0.9260 loss_val: 1.0220 acc_val: 0.6887 time: 0.0024s\nRanking optimizing... \nNow Average ERR@k =  0.8136475086212158\nEpoch: 0009 loss_train: 0.4239 acc_train: 0.9223 loss_val: 1.0282 acc_val: 0.6875 time: 0.0038s\nRanking optimizing... \nNow Average ERR@k =  0.8161019682884216\nEpoch: 0010 loss_train: 0.4276 acc_train: 0.9199 loss_val: 1.0352 acc_val: 0.6869 time: 0.0033s\nRanking optimizing... \nNow Average ERR@k =  0.8185255527496338\nEpoch: 0011 loss_train: 0.4320 acc_train: 0.9199 loss_val: 1.0429 acc_val: 0.6845 time: 0.0026s\nRanking optimizing... \nNow Average ERR@k =  0.8193084597587585\nEpoch: 0012 loss_train: 0.4373 acc_train: 0.9199 loss_val: 1.0514 acc_val: 0.6839 time: 0.0027s\nRanking optimizing... \nNow Average ERR@k =  0.8206794261932373\nEpoch: 0013 loss_train: 0.4433 acc_train: 0.9187 loss_val: 1.0605 acc_val: 0.6814 time: 0.0065s\nRanking optimizing... \nNow Average ERR@k =  0.8230046629905701\nEpoch: 0014 loss_train: 0.4500 acc_train: 0.9150 loss_val: 1.0699 acc_val: 0.6778 time: 0.0032s\nRanking optimizing... \nNow Average ERR@k =  0.8246352672576904\nEpoch: 0015 loss_train: 0.4571 acc_train: 0.9126 loss_val: 1.0797 acc_val: 0.6778 time: 0.0032s\nRanking optimizing... \nNow Average ERR@k =  0.8251983523368835\nTest set results: loss= 1.1057 accuracy= 0.6629\n"], ["node classification", "feature", "ERR", "ACM", "GCN", "ACM\nUsing ACM dataset\nEpoch: 0001 loss_train: 2.1528 acc_train: 0.1893 loss_val: 2.1508 acc_val: 0.1839 time: 0.9018s\nRanking optimizing... \nNow Average ERR@k =  0.7601377964019775\nEpoch: 0002 loss_train: 2.1362 acc_train: 0.2403 loss_val: 2.1368 acc_val: 0.2215 time: 0.0095s\nRanking optimizing... \nNow Average ERR@k =  0.7624905705451965\nEpoch: 0003 loss_train: 2.1197 acc_train: 0.2961 loss_val: 2.1234 acc_val: 0.2779 time: 0.0073s\nRanking optimizing... \nNow Average ERR@k =  0.761354923248291\nEpoch: 0004 loss_train: 2.1053 acc_train: 0.3410 loss_val: 2.1107 acc_val: 0.3240 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7635940909385681\nEpoch: 0005 loss_train: 2.0927 acc_train: 0.3799 loss_val: 2.0998 acc_val: 0.3677 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7627884149551392\nEpoch: 0006 loss_train: 2.0778 acc_train: 0.4223 loss_val: 2.0899 acc_val: 0.4047 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.7597111463546753\nEpoch: 0007 loss_train: 2.0712 acc_train: 0.4223 loss_val: 2.0803 acc_val: 0.4181 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7617887854576111\nEpoch: 0008 loss_train: 2.0556 acc_train: 0.4430 loss_val: 2.0712 acc_val: 0.4399 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7615187764167786\nEpoch: 0009 loss_train: 2.0449 acc_train: 0.4502 loss_val: 2.0615 acc_val: 0.4515 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.762226939201355\nEpoch: 0010 loss_train: 2.0374 acc_train: 0.4757 loss_val: 2.0509 acc_val: 0.4581 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7631019353866577\nEpoch: 0011 loss_train: 2.0212 acc_train: 0.4951 loss_val: 2.0389 acc_val: 0.4794 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.759458601474762\nEpoch: 0012 loss_train: 2.0057 acc_train: 0.5170 loss_val: 2.0251 acc_val: 0.4964 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7608910799026489\nEpoch: 0013 loss_train: 1.9900 acc_train: 0.5328 loss_val: 2.0098 acc_val: 0.5176 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7631473541259766\nEpoch: 0014 loss_train: 1.9730 acc_train: 0.5291 loss_val: 1.9927 acc_val: 0.5413 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7617350816726685\nEpoch: 0015 loss_train: 1.9518 acc_train: 0.5728 loss_val: 1.9743 acc_val: 0.5546 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7637962102890015\nEpoch: 0016 loss_train: 1.9332 acc_train: 0.5825 loss_val: 1.9541 acc_val: 0.5704 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7628766298294067\nEpoch: 0017 loss_train: 1.9015 acc_train: 0.5850 loss_val: 1.9326 acc_val: 0.5777 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7638750076293945\nEpoch: 0018 loss_train: 1.8817 acc_train: 0.6068 loss_val: 1.9100 acc_val: 0.5843 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.766241729259491\nEpoch: 0019 loss_train: 1.8596 acc_train: 0.5959 loss_val: 1.8861 acc_val: 0.5922 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.765721321105957\nEpoch: 0020 loss_train: 1.8270 acc_train: 0.6201 loss_val: 1.8613 acc_val: 0.5977 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.7608565092086792\nEpoch: 0021 loss_train: 1.7983 acc_train: 0.6080 loss_val: 1.8355 acc_val: 0.5965 time: 0.0069s\nRanking optimizing... \nNow Average ERR@k =  0.7640411853790283\nEpoch: 0022 loss_train: 1.7765 acc_train: 0.6080 loss_val: 1.8092 acc_val: 0.5965 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.7634585499763489\nEpoch: 0023 loss_train: 1.7440 acc_train: 0.6189 loss_val: 1.7825 acc_val: 0.5977 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.765084445476532\nEpoch: 0024 loss_train: 1.7120 acc_train: 0.6214 loss_val: 1.7555 acc_val: 0.5965 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7640147805213928\nEpoch: 0025 loss_train: 1.6889 acc_train: 0.6032 loss_val: 1.7284 acc_val: 0.5983 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7637377381324768\nEpoch: 0026 loss_train: 1.6498 acc_train: 0.6383 loss_val: 1.7007 acc_val: 0.5971 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7645390033721924\nEpoch: 0027 loss_train: 1.6334 acc_train: 0.6214 loss_val: 1.6727 acc_val: 0.5995 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7648206353187561\nEpoch: 0028 loss_train: 1.5987 acc_train: 0.6189 loss_val: 1.6447 acc_val: 0.6007 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.764187216758728\nEpoch: 0029 loss_train: 1.5599 acc_train: 0.6226 loss_val: 1.6167 acc_val: 0.6062 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.761469304561615\nEpoch: 0030 loss_train: 1.5413 acc_train: 0.6335 loss_val: 1.5885 acc_val: 0.6117 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7621039748191833\nEpoch: 0031 loss_train: 1.5107 acc_train: 0.6408 loss_val: 1.5605 acc_val: 0.6147 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7633868455886841\nEpoch: 0032 loss_train: 1.4679 acc_train: 0.6468 loss_val: 1.5324 acc_val: 0.6208 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7621042728424072\nEpoch: 0033 loss_train: 1.4438 acc_train: 0.6456 loss_val: 1.5043 acc_val: 0.6232 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7646424174308777\nEpoch: 0034 loss_train: 1.4101 acc_train: 0.6420 loss_val: 1.4764 acc_val: 0.6274 time: 0.0148s\nRanking optimizing... \nNow Average ERR@k =  0.7634013295173645\nEpoch: 0035 loss_train: 1.3838 acc_train: 0.6420 loss_val: 1.4486 acc_val: 0.6347 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7608435750007629\nEpoch: 0036 loss_train: 1.3519 acc_train: 0.6529 loss_val: 1.4211 acc_val: 0.6408 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7624648809432983\nEpoch: 0037 loss_train: 1.3094 acc_train: 0.6735 loss_val: 1.3939 acc_val: 0.6438 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7654825448989868\nEpoch: 0038 loss_train: 1.2933 acc_train: 0.6687 loss_val: 1.3670 acc_val: 0.6468 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7647162675857544\nEpoch: 0039 loss_train: 1.2631 acc_train: 0.6857 loss_val: 1.3407 acc_val: 0.6511 time: 0.0075s\nRanking optimizing... \nNow Average ERR@k =  0.7632655501365662\nEpoch: 0040 loss_train: 1.2424 acc_train: 0.6772 loss_val: 1.3149 acc_val: 0.6578 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7614881992340088\nEpoch: 0041 loss_train: 1.2042 acc_train: 0.6748 loss_val: 1.2898 acc_val: 0.6638 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.76280677318573\nEpoch: 0042 loss_train: 1.1781 acc_train: 0.6881 loss_val: 1.2654 acc_val: 0.6693 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.763861358165741\nEpoch: 0043 loss_train: 1.1510 acc_train: 0.6990 loss_val: 1.2420 acc_val: 0.6778 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7663989663124084\nEpoch: 0044 loss_train: 1.1386 acc_train: 0.7002 loss_val: 1.2193 acc_val: 0.6826 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.7635095119476318\nEpoch: 0045 loss_train: 1.1068 acc_train: 0.7184 loss_val: 1.1973 acc_val: 0.6851 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.764754593372345\nEpoch: 0046 loss_train: 1.0864 acc_train: 0.7209 loss_val: 1.1762 acc_val: 0.6887 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7634037137031555\nEpoch: 0047 loss_train: 1.0624 acc_train: 0.7039 loss_val: 1.1558 acc_val: 0.6911 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.7623997926712036\nEpoch: 0048 loss_train: 1.0399 acc_train: 0.7197 loss_val: 1.1361 acc_val: 0.6936 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7634294629096985\nEpoch: 0049 loss_train: 1.0161 acc_train: 0.7282 loss_val: 1.1172 acc_val: 0.6942 time: 0.0096s\nRanking optimizing... \nNow Average ERR@k =  0.762135922908783\nEpoch: 0050 loss_train: 0.9900 acc_train: 0.7439 loss_val: 1.0990 acc_val: 0.6966 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7626113295555115\nEpoch: 0051 loss_train: 0.9740 acc_train: 0.7427 loss_val: 1.0815 acc_val: 0.6972 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7638242244720459\nEpoch: 0052 loss_train: 0.9603 acc_train: 0.7379 loss_val: 1.0648 acc_val: 0.7002 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7619019746780396\nEpoch: 0053 loss_train: 0.9347 acc_train: 0.7488 loss_val: 1.0491 acc_val: 0.7015 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.76416015625\nEpoch: 0054 loss_train: 0.9089 acc_train: 0.7524 loss_val: 1.0343 acc_val: 0.7039 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7632805109024048\nEpoch: 0055 loss_train: 0.9044 acc_train: 0.7415 loss_val: 1.0203 acc_val: 0.7045 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7629476189613342\nEpoch: 0056 loss_train: 0.8825 acc_train: 0.7536 loss_val: 1.0071 acc_val: 0.7051 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7624803781509399\nEpoch: 0057 loss_train: 0.8433 acc_train: 0.7561 loss_val: 0.9948 acc_val: 0.7100 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.759429395198822\nEpoch: 0058 loss_train: 0.8601 acc_train: 0.7682 loss_val: 0.9832 acc_val: 0.7087 time: 0.0068s\nRanking optimizing... \nNow Average ERR@k =  0.7606409192085266\nEpoch: 0059 loss_train: 0.8384 acc_train: 0.7621 loss_val: 0.9721 acc_val: 0.7112 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7629638314247131\nEpoch: 0060 loss_train: 0.8171 acc_train: 0.7706 loss_val: 0.9618 acc_val: 0.7124 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7589259147644043\nEpoch: 0061 loss_train: 0.7991 acc_train: 0.7731 loss_val: 0.9521 acc_val: 0.7142 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7607768774032593\nEpoch: 0062 loss_train: 0.7929 acc_train: 0.7670 loss_val: 0.9431 acc_val: 0.7154 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7628776431083679\nEpoch: 0063 loss_train: 0.7756 acc_train: 0.7706 loss_val: 0.9348 acc_val: 0.7154 time: 0.0132s\nRanking optimizing... \nNow Average ERR@k =  0.765359103679657\nEpoch: 0064 loss_train: 0.7757 acc_train: 0.7743 loss_val: 0.9269 acc_val: 0.7154 time: 0.0066s\nRanking optimizing... \nNow Average ERR@k =  0.7624237537384033\nEpoch: 0065 loss_train: 0.7436 acc_train: 0.7900 loss_val: 0.9195 acc_val: 0.7178 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.7619612812995911\nEpoch: 0066 loss_train: 0.7452 acc_train: 0.7852 loss_val: 0.9126 acc_val: 0.7178 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.762039065361023\nEpoch: 0067 loss_train: 0.7403 acc_train: 0.7779 loss_val: 0.9062 acc_val: 0.7197 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7628610730171204\nEpoch: 0068 loss_train: 0.7092 acc_train: 0.7985 loss_val: 0.9003 acc_val: 0.7209 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7599517107009888\nEpoch: 0069 loss_train: 0.7271 acc_train: 0.7852 loss_val: 0.8947 acc_val: 0.7215 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7612172365188599\nEpoch: 0070 loss_train: 0.6982 acc_train: 0.7985 loss_val: 0.8897 acc_val: 0.7209 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7597812414169312\nEpoch: 0071 loss_train: 0.6890 acc_train: 0.7998 loss_val: 0.8849 acc_val: 0.7215 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7611267566680908\nEpoch: 0072 loss_train: 0.6771 acc_train: 0.7998 loss_val: 0.8804 acc_val: 0.7227 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7618412971496582\nEpoch: 0073 loss_train: 0.6748 acc_train: 0.8119 loss_val: 0.8763 acc_val: 0.7221 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7628063559532166\nEpoch: 0074 loss_train: 0.6637 acc_train: 0.7925 loss_val: 0.8726 acc_val: 0.7233 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.762398898601532\nEpoch: 0075 loss_train: 0.6673 acc_train: 0.8083 loss_val: 0.8692 acc_val: 0.7227 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7612535953521729\nEpoch: 0076 loss_train: 0.6470 acc_train: 0.8131 loss_val: 0.8662 acc_val: 0.7197 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7652081847190857\nEpoch: 0077 loss_train: 0.6388 acc_train: 0.8107 loss_val: 0.8635 acc_val: 0.7197 time: 0.0137s\nRanking optimizing... \nNow Average ERR@k =  0.7613656520843506\nEpoch: 0078 loss_train: 0.6219 acc_train: 0.8192 loss_val: 0.8610 acc_val: 0.7191 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7617504596710205\nEpoch: 0079 loss_train: 0.6342 acc_train: 0.8070 loss_val: 0.8588 acc_val: 0.7191 time: 0.0071s\nRanking optimizing... \nNow Average ERR@k =  0.7600679397583008\nEpoch: 0080 loss_train: 0.6220 acc_train: 0.8155 loss_val: 0.8568 acc_val: 0.7197 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7617618441581726\nEpoch: 0081 loss_train: 0.5960 acc_train: 0.8313 loss_val: 0.8549 acc_val: 0.7203 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7642669081687927\nEpoch: 0082 loss_train: 0.5931 acc_train: 0.8289 loss_val: 0.8532 acc_val: 0.7203 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7620436549186707\nEpoch: 0083 loss_train: 0.5951 acc_train: 0.8180 loss_val: 0.8517 acc_val: 0.7197 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7621021270751953\nEpoch: 0084 loss_train: 0.5826 acc_train: 0.8192 loss_val: 0.8503 acc_val: 0.7209 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7608308792114258\nEpoch: 0085 loss_train: 0.5749 acc_train: 0.8313 loss_val: 0.8489 acc_val: 0.7203 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7612380385398865\nEpoch: 0086 loss_train: 0.5721 acc_train: 0.8192 loss_val: 0.8478 acc_val: 0.7184 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7642061114311218\nEpoch: 0087 loss_train: 0.5571 acc_train: 0.8277 loss_val: 0.8469 acc_val: 0.7184 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7617384195327759\nEpoch: 0088 loss_train: 0.5620 acc_train: 0.8252 loss_val: 0.8461 acc_val: 0.7172 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7627455592155457\nEpoch: 0089 loss_train: 0.5558 acc_train: 0.8240 loss_val: 0.8454 acc_val: 0.7178 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7619538307189941\nEpoch: 0090 loss_train: 0.5330 acc_train: 0.8337 loss_val: 0.8449 acc_val: 0.7191 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7598617076873779\nEpoch: 0091 loss_train: 0.5370 acc_train: 0.8374 loss_val: 0.8445 acc_val: 0.7197 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7636422514915466\nEpoch: 0092 loss_train: 0.5356 acc_train: 0.8277 loss_val: 0.8443 acc_val: 0.7191 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.765053391456604\nEpoch: 0093 loss_train: 0.5239 acc_train: 0.8434 loss_val: 0.8442 acc_val: 0.7166 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7621251940727234\nEpoch: 0094 loss_train: 0.5272 acc_train: 0.8362 loss_val: 0.8442 acc_val: 0.7166 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7618644833564758\nEpoch: 0095 loss_train: 0.5322 acc_train: 0.8410 loss_val: 0.8445 acc_val: 0.7154 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7620346546173096\nEpoch: 0096 loss_train: 0.5196 acc_train: 0.8495 loss_val: 0.8447 acc_val: 0.7142 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7614798545837402\nEpoch: 0097 loss_train: 0.5079 acc_train: 0.8483 loss_val: 0.8450 acc_val: 0.7136 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.760836124420166\nEpoch: 0098 loss_train: 0.5240 acc_train: 0.8325 loss_val: 0.8456 acc_val: 0.7124 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.7613314390182495\nEpoch: 0099 loss_train: 0.4977 acc_train: 0.8386 loss_val: 0.8460 acc_val: 0.7136 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7601704597473145\nEpoch: 0100 loss_train: 0.5016 acc_train: 0.8422 loss_val: 0.8466 acc_val: 0.7148 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7623733282089233\nEpoch: 0101 loss_train: 0.4926 acc_train: 0.8483 loss_val: 0.8472 acc_val: 0.7124 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.761481523513794\nEpoch: 0102 loss_train: 0.4772 acc_train: 0.8617 loss_val: 0.8479 acc_val: 0.7112 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7582811117172241\nEpoch: 0103 loss_train: 0.4754 acc_train: 0.8556 loss_val: 0.8488 acc_val: 0.7100 time: 0.0070s\nRanking optimizing... \nNow Average ERR@k =  0.7608516216278076\nEpoch: 0104 loss_train: 0.4781 acc_train: 0.8483 loss_val: 0.8496 acc_val: 0.7093 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.762475311756134\nEpoch: 0105 loss_train: 0.4808 acc_train: 0.8519 loss_val: 0.8505 acc_val: 0.7100 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7608954310417175\nEpoch: 0106 loss_train: 0.4703 acc_train: 0.8580 loss_val: 0.8513 acc_val: 0.7081 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.76161128282547\nEpoch: 0107 loss_train: 0.4671 acc_train: 0.8592 loss_val: 0.8524 acc_val: 0.7087 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7604207992553711\nEpoch: 0108 loss_train: 0.4506 acc_train: 0.8653 loss_val: 0.8536 acc_val: 0.7100 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.761758029460907\nEpoch: 0109 loss_train: 0.4597 acc_train: 0.8544 loss_val: 0.8548 acc_val: 0.7087 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7640146613121033\nEpoch: 0110 loss_train: 0.4565 acc_train: 0.8592 loss_val: 0.8562 acc_val: 0.7093 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7617007493972778\nEpoch: 0111 loss_train: 0.4572 acc_train: 0.8653 loss_val: 0.8577 acc_val: 0.7106 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.765804648399353\nEpoch: 0112 loss_train: 0.4440 acc_train: 0.8653 loss_val: 0.8594 acc_val: 0.7093 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7640061974525452\nEpoch: 0113 loss_train: 0.4302 acc_train: 0.8701 loss_val: 0.8612 acc_val: 0.7100 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7602424621582031\nEpoch: 0114 loss_train: 0.4383 acc_train: 0.8665 loss_val: 0.8629 acc_val: 0.7081 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.7626375555992126\nEpoch: 0115 loss_train: 0.4501 acc_train: 0.8701 loss_val: 0.8647 acc_val: 0.7087 time: 0.0063s\nRanking optimizing... \nNow Average ERR@k =  0.7617985010147095\nEpoch: 0116 loss_train: 0.4428 acc_train: 0.8677 loss_val: 0.8666 acc_val: 0.7069 time: 0.0063s\nRanking optimizing... \nNow Average ERR@k =  0.7643350958824158\nEpoch: 0117 loss_train: 0.4318 acc_train: 0.8580 loss_val: 0.8685 acc_val: 0.7069 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7598749995231628\nEpoch: 0118 loss_train: 0.4193 acc_train: 0.8762 loss_val: 0.8704 acc_val: 0.7069 time: 0.0065s\nRanking optimizing... \nNow Average ERR@k =  0.7626304030418396\nEpoch: 0119 loss_train: 0.4286 acc_train: 0.8750 loss_val: 0.8723 acc_val: 0.7075 time: 0.0067s\nRanking optimizing... \nNow Average ERR@k =  0.7596162557601929\nEpoch: 0120 loss_train: 0.4160 acc_train: 0.8726 loss_val: 0.8742 acc_val: 0.7075 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.7589085698127747\nEpoch: 0121 loss_train: 0.4195 acc_train: 0.8762 loss_val: 0.8762 acc_val: 0.7069 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7584404349327087\nEpoch: 0122 loss_train: 0.4199 acc_train: 0.8677 loss_val: 0.8782 acc_val: 0.7057 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7629274129867554\nEpoch: 0123 loss_train: 0.4024 acc_train: 0.8774 loss_val: 0.8803 acc_val: 0.7051 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.761528491973877\nEpoch: 0124 loss_train: 0.4203 acc_train: 0.8653 loss_val: 0.8825 acc_val: 0.7063 time: 0.0068s\nRanking optimizing... \nNow Average ERR@k =  0.7624374628067017\nEpoch: 0125 loss_train: 0.4061 acc_train: 0.8799 loss_val: 0.8847 acc_val: 0.7063 time: 0.0067s\nRanking optimizing... \nNow Average ERR@k =  0.763422429561615\nEpoch: 0126 loss_train: 0.3899 acc_train: 0.8871 loss_val: 0.8868 acc_val: 0.7045 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.7645394206047058\nEpoch: 0127 loss_train: 0.4144 acc_train: 0.8677 loss_val: 0.8890 acc_val: 0.7045 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7648456692695618\nEpoch: 0128 loss_train: 0.4146 acc_train: 0.8641 loss_val: 0.8913 acc_val: 0.7045 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7596011161804199\nEpoch: 0129 loss_train: 0.4074 acc_train: 0.8835 loss_val: 0.8936 acc_val: 0.7015 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7620274424552917\nEpoch: 0130 loss_train: 0.4001 acc_train: 0.8774 loss_val: 0.8958 acc_val: 0.7015 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7631025910377502\nEpoch: 0131 loss_train: 0.4009 acc_train: 0.8762 loss_val: 0.8979 acc_val: 0.7008 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7613505125045776\nEpoch: 0132 loss_train: 0.3858 acc_train: 0.8774 loss_val: 0.8997 acc_val: 0.7008 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7629417777061462\nEpoch: 0133 loss_train: 0.3921 acc_train: 0.8883 loss_val: 0.9015 acc_val: 0.6996 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.763595461845398\nEpoch: 0134 loss_train: 0.3977 acc_train: 0.8750 loss_val: 0.9030 acc_val: 0.7008 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.761338472366333\nEpoch: 0135 loss_train: 0.3876 acc_train: 0.8859 loss_val: 0.9046 acc_val: 0.6996 time: 0.0101s\nRanking optimizing... \nNow Average ERR@k =  0.7653800249099731\nEpoch: 0136 loss_train: 0.3834 acc_train: 0.8811 loss_val: 0.9063 acc_val: 0.6984 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.7608768343925476\nEpoch: 0137 loss_train: 0.3762 acc_train: 0.8859 loss_val: 0.9080 acc_val: 0.6978 time: 0.0068s\nRanking optimizing... \nNow Average ERR@k =  0.7629702687263489\nEpoch: 0138 loss_train: 0.3624 acc_train: 0.8908 loss_val: 0.9097 acc_val: 0.6978 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7652526497840881\nEpoch: 0139 loss_train: 0.3553 acc_train: 0.9017 loss_val: 0.9116 acc_val: 0.6972 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7616567015647888\nEpoch: 0140 loss_train: 0.3597 acc_train: 0.8981 loss_val: 0.9137 acc_val: 0.6972 time: 0.0099s\nRanking optimizing... \nNow Average ERR@k =  0.7621685862541199\nEpoch: 0141 loss_train: 0.3800 acc_train: 0.8944 loss_val: 0.9159 acc_val: 0.6978 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7645779252052307\nEpoch: 0142 loss_train: 0.3654 acc_train: 0.8908 loss_val: 0.9183 acc_val: 0.6978 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.7604029774665833\nEpoch: 0143 loss_train: 0.3553 acc_train: 0.8944 loss_val: 0.9208 acc_val: 0.6972 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7609425187110901\nEpoch: 0144 loss_train: 0.3807 acc_train: 0.8823 loss_val: 0.9234 acc_val: 0.6966 time: 0.0104s\nRanking optimizing... \nNow Average ERR@k =  0.7599913477897644\nEpoch: 0145 loss_train: 0.3521 acc_train: 0.8908 loss_val: 0.9258 acc_val: 0.6960 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7628137469291687\nEpoch: 0146 loss_train: 0.3557 acc_train: 0.8883 loss_val: 0.9285 acc_val: 0.6942 time: 0.0068s\nRanking optimizing... \nNow Average ERR@k =  0.7637008428573608\nEpoch: 0147 loss_train: 0.3591 acc_train: 0.8908 loss_val: 0.9313 acc_val: 0.6924 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.7620155215263367\nEpoch: 0148 loss_train: 0.3535 acc_train: 0.8968 loss_val: 0.9338 acc_val: 0.6930 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7601646780967712\nEpoch: 0149 loss_train: 0.3490 acc_train: 0.9053 loss_val: 0.9363 acc_val: 0.6930 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.7634078860282898\nEpoch: 0150 loss_train: 0.3589 acc_train: 0.8920 loss_val: 0.9386 acc_val: 0.6917 time: 0.0097s\nRanking optimizing... \nNow Average ERR@k =  0.7625755071640015\nEpoch: 0151 loss_train: 0.3667 acc_train: 0.8738 loss_val: 0.9408 acc_val: 0.6924 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7633839249610901\nEpoch: 0152 loss_train: 0.3624 acc_train: 0.8896 loss_val: 0.9431 acc_val: 0.6917 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7630280256271362\nEpoch: 0153 loss_train: 0.3547 acc_train: 0.8823 loss_val: 0.9452 acc_val: 0.6936 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.763650119304657\nEpoch: 0154 loss_train: 0.3417 acc_train: 0.8968 loss_val: 0.9474 acc_val: 0.6924 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7619226574897766\nEpoch: 0155 loss_train: 0.3259 acc_train: 0.9053 loss_val: 0.9495 acc_val: 0.6917 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7637505531311035\nEpoch: 0156 loss_train: 0.3512 acc_train: 0.8932 loss_val: 0.9515 acc_val: 0.6924 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.7632700204849243\nEpoch: 0157 loss_train: 0.3319 acc_train: 0.9017 loss_val: 0.9532 acc_val: 0.6924 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.7628790140151978\nEpoch: 0158 loss_train: 0.3217 acc_train: 0.8993 loss_val: 0.9550 acc_val: 0.6905 time: 0.0078s\nRanking optimizing... \nNow Average ERR@k =  0.7608509063720703\nEpoch: 0159 loss_train: 0.3473 acc_train: 0.8871 loss_val: 0.9568 acc_val: 0.6881 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7626978754997253\nEpoch: 0160 loss_train: 0.3457 acc_train: 0.8920 loss_val: 0.9589 acc_val: 0.6893 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.7637441754341125\nEpoch: 0161 loss_train: 0.3304 acc_train: 0.8920 loss_val: 0.9611 acc_val: 0.6893 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7622004747390747\nEpoch: 0162 loss_train: 0.3367 acc_train: 0.9041 loss_val: 0.9631 acc_val: 0.6899 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.765132486820221\nEpoch: 0163 loss_train: 0.3352 acc_train: 0.8871 loss_val: 0.9653 acc_val: 0.6911 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.7621452212333679\nEpoch: 0164 loss_train: 0.3240 acc_train: 0.9029 loss_val: 0.9672 acc_val: 0.6905 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.7616243958473206\nEpoch: 0165 loss_train: 0.3094 acc_train: 0.9102 loss_val: 0.9691 acc_val: 0.6905 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.7628490328788757\nEpoch: 0166 loss_train: 0.3225 acc_train: 0.9053 loss_val: 0.9711 acc_val: 0.6911 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.7635862827301025\nEpoch: 0167 loss_train: 0.3194 acc_train: 0.9017 loss_val: 0.9731 acc_val: 0.6911 time: 0.0096s\nRanking optimizing... \nNow Average ERR@k =  0.7612786889076233\nEpoch: 0168 loss_train: 0.3146 acc_train: 0.9175 loss_val: 0.9753 acc_val: 0.6911 time: 0.0065s\nRanking optimizing... \nNow Average ERR@k =  0.7610599398612976\nEpoch: 0169 loss_train: 0.3366 acc_train: 0.8956 loss_val: 0.9777 acc_val: 0.6911 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7625329494476318\nEpoch: 0170 loss_train: 0.3093 acc_train: 0.9126 loss_val: 0.9799 acc_val: 0.6924 time: 0.0065s\nRanking optimizing... \nNow Average ERR@k =  0.7624905705451965\nEpoch: 0171 loss_train: 0.3149 acc_train: 0.9114 loss_val: 0.9821 acc_val: 0.6905 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.7639288902282715\nEpoch: 0172 loss_train: 0.3085 acc_train: 0.9126 loss_val: 0.9843 acc_val: 0.6905 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.7627003192901611\nEpoch: 0173 loss_train: 0.3070 acc_train: 0.9053 loss_val: 0.9864 acc_val: 0.6911 time: 0.0068s\nRanking optimizing... \nNow Average ERR@k =  0.7627202868461609\nEpoch: 0174 loss_train: 0.2917 acc_train: 0.9163 loss_val: 0.9883 acc_val: 0.6917 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7609202861785889\nEpoch: 0175 loss_train: 0.2987 acc_train: 0.9126 loss_val: 0.9903 acc_val: 0.6905 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7636728286743164\nEpoch: 0176 loss_train: 0.2951 acc_train: 0.9041 loss_val: 0.9926 acc_val: 0.6911 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7640503644943237\nEpoch: 0177 loss_train: 0.3091 acc_train: 0.9078 loss_val: 0.9950 acc_val: 0.6899 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7635688781738281\nEpoch: 0178 loss_train: 0.3016 acc_train: 0.9017 loss_val: 0.9974 acc_val: 0.6905 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.7636491060256958\nEpoch: 0179 loss_train: 0.3012 acc_train: 0.9126 loss_val: 0.9997 acc_val: 0.6905 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.7624130249023438\nEpoch: 0180 loss_train: 0.2859 acc_train: 0.9150 loss_val: 1.0020 acc_val: 0.6881 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7646365761756897\nEpoch: 0181 loss_train: 0.3026 acc_train: 0.9066 loss_val: 1.0044 acc_val: 0.6863 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7622866034507751\nEpoch: 0182 loss_train: 0.3021 acc_train: 0.9199 loss_val: 1.0070 acc_val: 0.6857 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7647153735160828\nEpoch: 0183 loss_train: 0.2991 acc_train: 0.9126 loss_val: 1.0096 acc_val: 0.6851 time: 0.0094s\nRanking optimizing... \nNow Average ERR@k =  0.76380854845047\nEpoch: 0184 loss_train: 0.3055 acc_train: 0.9102 loss_val: 1.0123 acc_val: 0.6845 time: 0.0096s\nRanking optimizing... \nNow Average ERR@k =  0.7609385848045349\nEpoch: 0185 loss_train: 0.2922 acc_train: 0.9199 loss_val: 1.0148 acc_val: 0.6845 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7626004815101624\nEpoch: 0186 loss_train: 0.3015 acc_train: 0.9114 loss_val: 1.0172 acc_val: 0.6845 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.764582633972168\nEpoch: 0187 loss_train: 0.2874 acc_train: 0.9090 loss_val: 1.0196 acc_val: 0.6851 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7618606686592102\nEpoch: 0188 loss_train: 0.2984 acc_train: 0.9163 loss_val: 1.0219 acc_val: 0.6845 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7640064358711243\nEpoch: 0189 loss_train: 0.2746 acc_train: 0.9296 loss_val: 1.0241 acc_val: 0.6869 time: 0.0094s\nRanking optimizing... \nNow Average ERR@k =  0.7613416910171509\nEpoch: 0190 loss_train: 0.2863 acc_train: 0.9163 loss_val: 1.0266 acc_val: 0.6869 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.761984646320343\nEpoch: 0191 loss_train: 0.2849 acc_train: 0.9199 loss_val: 1.0289 acc_val: 0.6875 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7658459544181824\nEpoch: 0192 loss_train: 0.2799 acc_train: 0.9187 loss_val: 1.0314 acc_val: 0.6857 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7651473879814148\nEpoch: 0193 loss_train: 0.2934 acc_train: 0.9199 loss_val: 1.0340 acc_val: 0.6863 time: 0.0093s\nRanking optimizing... \nNow Average ERR@k =  0.7640818953514099\nEpoch: 0194 loss_train: 0.2806 acc_train: 0.9102 loss_val: 1.0365 acc_val: 0.6857 time: 0.0096s\nRanking optimizing... \nNow Average ERR@k =  0.7643139958381653\nEpoch: 0195 loss_train: 0.2787 acc_train: 0.9175 loss_val: 1.0387 acc_val: 0.6845 time: 0.0098s\nRanking optimizing... \nNow Average ERR@k =  0.7625037431716919\nEpoch: 0196 loss_train: 0.2940 acc_train: 0.9138 loss_val: 1.0412 acc_val: 0.6845 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7629110217094421\nEpoch: 0197 loss_train: 0.2875 acc_train: 0.9126 loss_val: 1.0436 acc_val: 0.6845 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7632843852043152\nEpoch: 0198 loss_train: 0.2669 acc_train: 0.9199 loss_val: 1.0460 acc_val: 0.6839 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7642467021942139\nEpoch: 0199 loss_train: 0.2827 acc_train: 0.9066 loss_val: 1.0486 acc_val: 0.6851 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7635488510131836\nEpoch: 0200 loss_train: 0.2657 acc_train: 0.9284 loss_val: 1.0509 acc_val: 0.6839 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7624082565307617\nTest set results: loss= 1.0505 accuracy= 0.6996\n"], ["node classification", "feature", "ERR", "coauthor-cs", "SGC", "coauthor-cs\nTotal size :  18333\nUsing coauthor-cs dataset\nEpoch: 0001 loss_train: 2.7106 acc_train: 0.0229 loss_val: 2.6932 acc_val: 0.5183 time: 0.6155s\nEpoch: 0002 loss_train: 2.6921 acc_train: 0.5808 loss_val: 2.6760 acc_val: 0.5374 time: 0.0034s\nEpoch: 0003 loss_train: 2.6738 acc_train: 0.5928 loss_val: 2.6589 acc_val: 0.5548 time: 0.0034s\nEpoch: 0004 loss_train: 2.6557 acc_train: 0.6037 loss_val: 2.6421 acc_val: 0.5646 time: 0.0034s\nEpoch: 0005 loss_train: 2.6378 acc_train: 0.6081 loss_val: 2.6254 acc_val: 0.5636 time: 0.0034s\nEpoch: 0006 loss_train: 2.6201 acc_train: 0.6179 loss_val: 2.6090 acc_val: 0.5641 time: 0.0033s\nEpoch: 0007 loss_train: 2.6025 acc_train: 0.6212 loss_val: 2.5928 acc_val: 0.5652 time: 0.0033s\nEpoch: 0008 loss_train: 2.5852 acc_train: 0.6212 loss_val: 2.5767 acc_val: 0.5674 time: 0.0033s\nEpoch: 0009 loss_train: 2.5681 acc_train: 0.6146 loss_val: 2.5609 acc_val: 0.5679 time: 0.0033s\nEpoch: 0010 loss_train: 2.5512 acc_train: 0.6157 loss_val: 2.5453 acc_val: 0.5663 time: 0.0033s\nEpoch: 0011 loss_train: 2.5344 acc_train: 0.6146 loss_val: 2.5299 acc_val: 0.5652 time: 0.0033s\nEpoch: 0012 loss_train: 2.5179 acc_train: 0.6114 loss_val: 2.5147 acc_val: 0.5646 time: 0.0033s\nEpoch: 0013 loss_train: 2.5016 acc_train: 0.6124 loss_val: 2.4997 acc_val: 0.5657 time: 0.0033s\nEpoch: 0014 loss_train: 2.4855 acc_train: 0.6124 loss_val: 2.4849 acc_val: 0.5663 time: 0.0033s\nEpoch: 0015 loss_train: 2.4695 acc_train: 0.6114 loss_val: 2.4704 acc_val: 0.5668 time: 0.0033s\nEpoch: 0016 loss_train: 2.4538 acc_train: 0.6114 loss_val: 2.4560 acc_val: 0.5657 time: 0.0033s\nEpoch: 0017 loss_train: 2.4383 acc_train: 0.6114 loss_val: 2.4418 acc_val: 0.5663 time: 0.0033s\nEpoch: 0018 loss_train: 2.4230 acc_train: 0.6124 loss_val: 2.4278 acc_val: 0.5674 time: 0.0033s\nEpoch: 0019 loss_train: 2.4079 acc_train: 0.6114 loss_val: 2.4141 acc_val: 0.5690 time: 0.0034s\nEpoch: 0020 loss_train: 2.3930 acc_train: 0.6124 loss_val: 2.4005 acc_val: 0.5717 time: 0.0049s\nEpoch: 0021 loss_train: 2.3783 acc_train: 0.6114 loss_val: 2.3871 acc_val: 0.5717 time: 0.0034s\nEpoch: 0022 loss_train: 2.3638 acc_train: 0.6114 loss_val: 2.3739 acc_val: 0.5723 time: 0.0033s\nEpoch: 0023 loss_train: 2.3495 acc_train: 0.6114 loss_val: 2.3609 acc_val: 0.5728 time: 0.0033s\nEpoch: 0024 loss_train: 2.3354 acc_train: 0.6124 loss_val: 2.3480 acc_val: 0.5706 time: 0.0033s\nEpoch: 0025 loss_train: 2.3214 acc_train: 0.6124 loss_val: 2.3353 acc_val: 0.5728 time: 0.0034s\nEpoch: 0026 loss_train: 2.3077 acc_train: 0.6124 loss_val: 2.3228 acc_val: 0.5717 time: 0.0032s\nEpoch: 0027 loss_train: 2.2941 acc_train: 0.6070 loss_val: 2.3105 acc_val: 0.5706 time: 0.0032s\nEpoch: 0028 loss_train: 2.2808 acc_train: 0.6070 loss_val: 2.2983 acc_val: 0.5712 time: 0.0032s\nEpoch: 0029 loss_train: 2.2675 acc_train: 0.6059 loss_val: 2.2862 acc_val: 0.5706 time: 0.0032s\nEpoch: 0030 loss_train: 2.2545 acc_train: 0.6037 loss_val: 2.2744 acc_val: 0.5696 time: 0.0032s\nEpoch: 0031 loss_train: 2.2416 acc_train: 0.6037 loss_val: 2.2627 acc_val: 0.5685 time: 0.0032s\nEpoch: 0032 loss_train: 2.2289 acc_train: 0.6037 loss_val: 2.2511 acc_val: 0.5685 time: 0.0032s\nEpoch: 0033 loss_train: 2.2164 acc_train: 0.6037 loss_val: 2.2397 acc_val: 0.5690 time: 0.0032s\nEpoch: 0034 loss_train: 2.2040 acc_train: 0.6015 loss_val: 2.2284 acc_val: 0.5685 time: 0.0032s\nEpoch: 0035 loss_train: 2.1918 acc_train: 0.6004 loss_val: 2.2173 acc_val: 0.5679 time: 0.0032s\nEpoch: 0036 loss_train: 2.1797 acc_train: 0.6026 loss_val: 2.2063 acc_val: 0.5657 time: 0.0032s\nEpoch: 0037 loss_train: 2.1678 acc_train: 0.6015 loss_val: 2.1954 acc_val: 0.5652 time: 0.0032s\nEpoch: 0038 loss_train: 2.1560 acc_train: 0.6026 loss_val: 2.1847 acc_val: 0.5652 time: 0.0032s\nEpoch: 0039 loss_train: 2.1444 acc_train: 0.6026 loss_val: 2.1741 acc_val: 0.5641 time: 0.0032s\nEpoch: 0040 loss_train: 2.1329 acc_train: 0.6015 loss_val: 2.1637 acc_val: 0.5641 time: 0.0032s\nEpoch: 0041 loss_train: 2.1215 acc_train: 0.6015 loss_val: 2.1533 acc_val: 0.5657 time: 0.0032s\nEpoch: 0042 loss_train: 2.1103 acc_train: 0.6004 loss_val: 2.1431 acc_val: 0.5652 time: 0.0032s\nEpoch: 0043 loss_train: 2.0992 acc_train: 0.5983 loss_val: 2.1331 acc_val: 0.5652 time: 0.0032s\nEpoch: 0044 loss_train: 2.0882 acc_train: 0.5972 loss_val: 2.1231 acc_val: 0.5646 time: 0.0032s\nEpoch: 0045 loss_train: 2.0774 acc_train: 0.5972 loss_val: 2.1132 acc_val: 0.5641 time: 0.0032s\nEpoch: 0046 loss_train: 2.0666 acc_train: 0.5983 loss_val: 2.1035 acc_val: 0.5625 time: 0.0032s\nEpoch: 0047 loss_train: 2.0560 acc_train: 0.5972 loss_val: 2.0939 acc_val: 0.5608 time: 0.0032s\nEpoch: 0048 loss_train: 2.0455 acc_train: 0.5983 loss_val: 2.0843 acc_val: 0.5597 time: 0.0032s\nEpoch: 0049 loss_train: 2.0351 acc_train: 0.5983 loss_val: 2.0749 acc_val: 0.5586 time: 0.0032s\nEpoch: 0050 loss_train: 2.0249 acc_train: 0.5983 loss_val: 2.0656 acc_val: 0.5581 time: 0.0032s\nEpoch: 0051 loss_train: 2.0147 acc_train: 0.5993 loss_val: 2.0564 acc_val: 0.5576 time: 0.0032s\nEpoch: 0052 loss_train: 2.0047 acc_train: 0.5993 loss_val: 2.0472 acc_val: 0.5581 time: 0.0032s\nEpoch: 0053 loss_train: 1.9947 acc_train: 0.6004 loss_val: 2.0382 acc_val: 0.5581 time: 0.0032s\nEpoch: 0054 loss_train: 1.9849 acc_train: 0.6004 loss_val: 2.0293 acc_val: 0.5592 time: 0.0032s\nEpoch: 0055 loss_train: 1.9751 acc_train: 0.6015 loss_val: 2.0204 acc_val: 0.5597 time: 0.0032s\nEpoch: 0056 loss_train: 1.9655 acc_train: 0.5993 loss_val: 2.0116 acc_val: 0.5603 time: 0.0032s\nEpoch: 0057 loss_train: 1.9560 acc_train: 0.6015 loss_val: 2.0029 acc_val: 0.5603 time: 0.0032s\nEpoch: 0058 loss_train: 1.9465 acc_train: 0.6037 loss_val: 1.9943 acc_val: 0.5625 time: 0.0032s\nEpoch: 0059 loss_train: 1.9372 acc_train: 0.6037 loss_val: 1.9858 acc_val: 0.5619 time: 0.0032s\nEpoch: 0060 loss_train: 1.9279 acc_train: 0.6048 loss_val: 1.9774 acc_val: 0.5619 time: 0.0032s\nEpoch: 0061 loss_train: 1.9187 acc_train: 0.6081 loss_val: 1.9690 acc_val: 0.5646 time: 0.0032s\nEpoch: 0062 loss_train: 1.9096 acc_train: 0.6103 loss_val: 1.9607 acc_val: 0.5652 time: 0.0032s\nEpoch: 0063 loss_train: 1.9006 acc_train: 0.6146 loss_val: 1.9525 acc_val: 0.5663 time: 0.0032s\nEpoch: 0064 loss_train: 1.8917 acc_train: 0.6179 loss_val: 1.9444 acc_val: 0.5674 time: 0.0032s\nEpoch: 0065 loss_train: 1.8829 acc_train: 0.6201 loss_val: 1.9364 acc_val: 0.5679 time: 0.0032s\nEpoch: 0066 loss_train: 1.8742 acc_train: 0.6223 loss_val: 1.9284 acc_val: 0.5685 time: 0.0032s\nEpoch: 0067 loss_train: 1.8655 acc_train: 0.6234 loss_val: 1.9205 acc_val: 0.5712 time: 0.0032s\nEpoch: 0068 loss_train: 1.8569 acc_train: 0.6234 loss_val: 1.9127 acc_val: 0.5728 time: 0.0032s\nEpoch: 0069 loss_train: 1.8484 acc_train: 0.6255 loss_val: 1.9049 acc_val: 0.5750 time: 0.0032s\nEpoch: 0070 loss_train: 1.8400 acc_train: 0.6277 loss_val: 1.8972 acc_val: 0.5772 time: 0.0032s\nEpoch: 0071 loss_train: 1.8317 acc_train: 0.6310 loss_val: 1.8896 acc_val: 0.5788 time: 0.0032s\nEpoch: 0072 loss_train: 1.8234 acc_train: 0.6343 loss_val: 1.8820 acc_val: 0.5799 time: 0.0032s\nEpoch: 0073 loss_train: 1.8152 acc_train: 0.6376 loss_val: 1.8746 acc_val: 0.5805 time: 0.0032s\nEpoch: 0074 loss_train: 1.8071 acc_train: 0.6408 loss_val: 1.8671 acc_val: 0.5821 time: 0.0032s\nEpoch: 0075 loss_train: 1.7990 acc_train: 0.6441 loss_val: 1.8598 acc_val: 0.5837 time: 0.0032s\nEpoch: 0076 loss_train: 1.7911 acc_train: 0.6463 loss_val: 1.8525 acc_val: 0.5854 time: 0.0032s\nEpoch: 0077 loss_train: 1.7832 acc_train: 0.6474 loss_val: 1.8452 acc_val: 0.5870 time: 0.0032s\nEpoch: 0078 loss_train: 1.7753 acc_train: 0.6561 loss_val: 1.8380 acc_val: 0.5903 time: 0.0032s\nEpoch: 0079 loss_train: 1.7676 acc_train: 0.6583 loss_val: 1.8309 acc_val: 0.5925 time: 0.0032s\nEpoch: 0080 loss_train: 1.7599 acc_train: 0.6605 loss_val: 1.8239 acc_val: 0.5947 time: 0.0032s\nEpoch: 0081 loss_train: 1.7522 acc_train: 0.6616 loss_val: 1.8169 acc_val: 0.5957 time: 0.0032s\nEpoch: 0082 loss_train: 1.7447 acc_train: 0.6648 loss_val: 1.8099 acc_val: 0.5979 time: 0.0032s\nEpoch: 0083 loss_train: 1.7372 acc_train: 0.6670 loss_val: 1.8030 acc_val: 0.5996 time: 0.0032s\nEpoch: 0084 loss_train: 1.7297 acc_train: 0.6714 loss_val: 1.7962 acc_val: 0.6023 time: 0.0032s\nEpoch: 0085 loss_train: 1.7223 acc_train: 0.6736 loss_val: 1.7894 acc_val: 0.6050 time: 0.0032s\nEpoch: 0086 loss_train: 1.7150 acc_train: 0.6779 loss_val: 1.7827 acc_val: 0.6077 time: 0.0032s\nEpoch: 0087 loss_train: 1.7078 acc_train: 0.6790 loss_val: 1.7760 acc_val: 0.6105 time: 0.0032s\nEpoch: 0088 loss_train: 1.7006 acc_train: 0.6834 loss_val: 1.7694 acc_val: 0.6127 time: 0.0032s\nEpoch: 0089 loss_train: 1.6934 acc_train: 0.6856 loss_val: 1.7628 acc_val: 0.6154 time: 0.0032s\nEpoch: 0090 loss_train: 1.6864 acc_train: 0.6867 loss_val: 1.7563 acc_val: 0.6176 time: 0.0032s\nEpoch: 0091 loss_train: 1.6793 acc_train: 0.6867 loss_val: 1.7499 acc_val: 0.6208 time: 0.0032s\nEpoch: 0092 loss_train: 1.6724 acc_train: 0.6878 loss_val: 1.7435 acc_val: 0.6230 time: 0.0032s\nEpoch: 0093 loss_train: 1.6655 acc_train: 0.6889 loss_val: 1.7371 acc_val: 0.6247 time: 0.0032s\nEpoch: 0094 loss_train: 1.6586 acc_train: 0.6943 loss_val: 1.7308 acc_val: 0.6263 time: 0.0032s\nEpoch: 0095 loss_train: 1.6518 acc_train: 0.6954 loss_val: 1.7245 acc_val: 0.6296 time: 0.0032s\nEpoch: 0096 loss_train: 1.6451 acc_train: 0.6998 loss_val: 1.7183 acc_val: 0.6312 time: 0.0032s\nEpoch: 0097 loss_train: 1.6384 acc_train: 0.7009 loss_val: 1.7121 acc_val: 0.6345 time: 0.0032s\nEpoch: 0098 loss_train: 1.6317 acc_train: 0.7020 loss_val: 1.7060 acc_val: 0.6378 time: 0.0032s\nEpoch: 0099 loss_train: 1.6252 acc_train: 0.7052 loss_val: 1.6999 acc_val: 0.6405 time: 0.0032s\nEpoch: 0100 loss_train: 1.6186 acc_train: 0.7085 loss_val: 1.6939 acc_val: 0.6427 time: 0.0032s\nEpoch: 0101 loss_train: 1.6121 acc_train: 0.7151 loss_val: 1.6879 acc_val: 0.6454 time: 0.0032s\nEpoch: 0102 loss_train: 1.6057 acc_train: 0.7183 loss_val: 1.6820 acc_val: 0.6481 time: 0.0032s\nEpoch: 0103 loss_train: 1.5993 acc_train: 0.7194 loss_val: 1.6761 acc_val: 0.6514 time: 0.0032s\nEpoch: 0104 loss_train: 1.5930 acc_train: 0.7216 loss_val: 1.6702 acc_val: 0.6530 time: 0.0032s\nEpoch: 0105 loss_train: 1.5867 acc_train: 0.7271 loss_val: 1.6644 acc_val: 0.6574 time: 0.0032s\nEpoch: 0106 loss_train: 1.5804 acc_train: 0.7293 loss_val: 1.6587 acc_val: 0.6590 time: 0.0032s\nEpoch: 0107 loss_train: 1.5742 acc_train: 0.7314 loss_val: 1.6529 acc_val: 0.6628 time: 0.0032s\nEpoch: 0108 loss_train: 1.5681 acc_train: 0.7325 loss_val: 1.6472 acc_val: 0.6639 time: 0.0032s\nEpoch: 0109 loss_train: 1.5620 acc_train: 0.7369 loss_val: 1.6416 acc_val: 0.6678 time: 0.0032s\nEpoch: 0110 loss_train: 1.5559 acc_train: 0.7445 loss_val: 1.6360 acc_val: 0.6688 time: 0.0032s\nEpoch: 0111 loss_train: 1.5499 acc_train: 0.7456 loss_val: 1.6304 acc_val: 0.6716 time: 0.0032s\nEpoch: 0112 loss_train: 1.5440 acc_train: 0.7478 loss_val: 1.6249 acc_val: 0.6743 time: 0.0032s\nEpoch: 0113 loss_train: 1.5380 acc_train: 0.7489 loss_val: 1.6194 acc_val: 0.6759 time: 0.0032s\nEpoch: 0114 loss_train: 1.5322 acc_train: 0.7511 loss_val: 1.6140 acc_val: 0.6787 time: 0.0032s\nEpoch: 0115 loss_train: 1.5263 acc_train: 0.7533 loss_val: 1.6086 acc_val: 0.6803 time: 0.0032s\nEpoch: 0116 loss_train: 1.5205 acc_train: 0.7566 loss_val: 1.6032 acc_val: 0.6836 time: 0.0032s\nEpoch: 0117 loss_train: 1.5148 acc_train: 0.7620 loss_val: 1.5979 acc_val: 0.6863 time: 0.0032s\nEpoch: 0118 loss_train: 1.5091 acc_train: 0.7642 loss_val: 1.5926 acc_val: 0.6885 time: 0.0032s\nEpoch: 0119 loss_train: 1.5034 acc_train: 0.7642 loss_val: 1.5874 acc_val: 0.6912 time: 0.0032s\nEpoch: 0120 loss_train: 1.4978 acc_train: 0.7675 loss_val: 1.5821 acc_val: 0.6950 time: 0.0032s\nEpoch: 0121 loss_train: 1.4922 acc_train: 0.7686 loss_val: 1.5770 acc_val: 0.6978 time: 0.0032s\nEpoch: 0122 loss_train: 1.4867 acc_train: 0.7718 loss_val: 1.5718 acc_val: 0.7010 time: 0.0032s\nEpoch: 0123 loss_train: 1.4812 acc_train: 0.7751 loss_val: 1.5667 acc_val: 0.7016 time: 0.0032s\nEpoch: 0124 loss_train: 1.4757 acc_train: 0.7751 loss_val: 1.5616 acc_val: 0.7049 time: 0.0032s\nEpoch: 0125 loss_train: 1.4703 acc_train: 0.7751 loss_val: 1.5566 acc_val: 0.7059 time: 0.0032s\nEpoch: 0126 loss_train: 1.4649 acc_train: 0.7773 loss_val: 1.5516 acc_val: 0.7092 time: 0.0032s\nEpoch: 0127 loss_train: 1.4595 acc_train: 0.7795 loss_val: 1.5466 acc_val: 0.7092 time: 0.0032s\nEpoch: 0128 loss_train: 1.4542 acc_train: 0.7806 loss_val: 1.5417 acc_val: 0.7103 time: 0.0032s\nEpoch: 0129 loss_train: 1.4490 acc_train: 0.7817 loss_val: 1.5368 acc_val: 0.7114 time: 0.0032s\nEpoch: 0130 loss_train: 1.4437 acc_train: 0.7817 loss_val: 1.5319 acc_val: 0.7152 time: 0.0032s\nEpoch: 0131 loss_train: 1.4385 acc_train: 0.7817 loss_val: 1.5271 acc_val: 0.7190 time: 0.0032s\nEpoch: 0132 loss_train: 1.4334 acc_train: 0.7838 loss_val: 1.5223 acc_val: 0.7218 time: 0.0032s\nEpoch: 0133 loss_train: 1.4282 acc_train: 0.7849 loss_val: 1.5175 acc_val: 0.7245 time: 0.0032s\nEpoch: 0134 loss_train: 1.4231 acc_train: 0.7882 loss_val: 1.5127 acc_val: 0.7261 time: 0.0032s\nEpoch: 0135 loss_train: 1.4181 acc_train: 0.7937 loss_val: 1.5080 acc_val: 0.7289 time: 0.0032s\nEpoch: 0136 loss_train: 1.4131 acc_train: 0.7980 loss_val: 1.5033 acc_val: 0.7316 time: 0.0032s\nEpoch: 0137 loss_train: 1.4081 acc_train: 0.7991 loss_val: 1.4987 acc_val: 0.7332 time: 0.0032s\nEpoch: 0138 loss_train: 1.4031 acc_train: 0.7991 loss_val: 1.4941 acc_val: 0.7343 time: 0.0032s\nEpoch: 0139 loss_train: 1.3982 acc_train: 0.8013 loss_val: 1.4895 acc_val: 0.7360 time: 0.0032s\nEpoch: 0140 loss_train: 1.3933 acc_train: 0.8024 loss_val: 1.4849 acc_val: 0.7381 time: 0.0032s\nEpoch: 0141 loss_train: 1.3885 acc_train: 0.8046 loss_val: 1.4804 acc_val: 0.7392 time: 0.0032s\nEpoch: 0142 loss_train: 1.3837 acc_train: 0.8057 loss_val: 1.4759 acc_val: 0.7398 time: 0.0032s\nEpoch: 0143 loss_train: 1.3789 acc_train: 0.8079 loss_val: 1.4715 acc_val: 0.7403 time: 0.0032s\nEpoch: 0144 loss_train: 1.3741 acc_train: 0.8090 loss_val: 1.4670 acc_val: 0.7420 time: 0.0032s\nEpoch: 0145 loss_train: 1.3694 acc_train: 0.8090 loss_val: 1.4626 acc_val: 0.7425 time: 0.0032s\nEpoch: 0146 loss_train: 1.3647 acc_train: 0.8100 loss_val: 1.4582 acc_val: 0.7436 time: 0.0032s\nEpoch: 0147 loss_train: 1.3601 acc_train: 0.8122 loss_val: 1.4539 acc_val: 0.7436 time: 0.0032s\nEpoch: 0148 loss_train: 1.3555 acc_train: 0.8133 loss_val: 1.4496 acc_val: 0.7436 time: 0.0032s\nEpoch: 0149 loss_train: 1.3509 acc_train: 0.8188 loss_val: 1.4453 acc_val: 0.7436 time: 0.0032s\nEpoch: 0150 loss_train: 1.3463 acc_train: 0.8199 loss_val: 1.4410 acc_val: 0.7441 time: 0.0032s\nEpoch: 0151 loss_train: 1.3418 acc_train: 0.8210 loss_val: 1.4368 acc_val: 0.7490 time: 0.0032s\nEpoch: 0152 loss_train: 1.3373 acc_train: 0.8221 loss_val: 1.4326 acc_val: 0.7512 time: 0.0032s\nEpoch: 0153 loss_train: 1.3328 acc_train: 0.8231 loss_val: 1.4284 acc_val: 0.7529 time: 0.0032s\nEpoch: 0154 loss_train: 1.3284 acc_train: 0.8231 loss_val: 1.4242 acc_val: 0.7545 time: 0.0032s\nEpoch: 0155 loss_train: 1.3240 acc_train: 0.8253 loss_val: 1.4201 acc_val: 0.7561 time: 0.0032s\nEpoch: 0156 loss_train: 1.3196 acc_train: 0.8253 loss_val: 1.4160 acc_val: 0.7583 time: 0.0032s\nEpoch: 0157 loss_train: 1.3153 acc_train: 0.8264 loss_val: 1.4119 acc_val: 0.7594 time: 0.0032s\nEpoch: 0158 loss_train: 1.3110 acc_train: 0.8264 loss_val: 1.4078 acc_val: 0.7610 time: 0.0032s\nEpoch: 0159 loss_train: 1.3067 acc_train: 0.8286 loss_val: 1.4038 acc_val: 0.7627 time: 0.0032s\nEpoch: 0160 loss_train: 1.3024 acc_train: 0.8308 loss_val: 1.3998 acc_val: 0.7638 time: 0.0032s\nEpoch: 0161 loss_train: 1.2982 acc_train: 0.8308 loss_val: 1.3959 acc_val: 0.7649 time: 0.0032s\nEpoch: 0162 loss_train: 1.2940 acc_train: 0.8330 loss_val: 1.3919 acc_val: 0.7665 time: 0.0032s\nEpoch: 0163 loss_train: 1.2898 acc_train: 0.8341 loss_val: 1.3880 acc_val: 0.7670 time: 0.0032s\nEpoch: 0164 loss_train: 1.2856 acc_train: 0.8341 loss_val: 1.3841 acc_val: 0.7670 time: 0.0032s\nEpoch: 0165 loss_train: 1.2815 acc_train: 0.8341 loss_val: 1.3802 acc_val: 0.7670 time: 0.0032s\nEpoch: 0166 loss_train: 1.2774 acc_train: 0.8373 loss_val: 1.3764 acc_val: 0.7681 time: 0.0032s\nEpoch: 0167 loss_train: 1.2734 acc_train: 0.8395 loss_val: 1.3725 acc_val: 0.7687 time: 0.0032s\nEpoch: 0168 loss_train: 1.2693 acc_train: 0.8406 loss_val: 1.3687 acc_val: 0.7692 time: 0.0032s\nEpoch: 0169 loss_train: 1.2653 acc_train: 0.8406 loss_val: 1.3649 acc_val: 0.7692 time: 0.0032s\nEpoch: 0170 loss_train: 1.2613 acc_train: 0.8417 loss_val: 1.3612 acc_val: 0.7687 time: 0.0032s\nEpoch: 0171 loss_train: 1.2574 acc_train: 0.8428 loss_val: 1.3575 acc_val: 0.7698 time: 0.0032s\nEpoch: 0172 loss_train: 1.2534 acc_train: 0.8428 loss_val: 1.3538 acc_val: 0.7714 time: 0.0032s\nEpoch: 0173 loss_train: 1.2495 acc_train: 0.8428 loss_val: 1.3501 acc_val: 0.7720 time: 0.0032s\nEpoch: 0174 loss_train: 1.2456 acc_train: 0.8428 loss_val: 1.3464 acc_val: 0.7747 time: 0.0032s\nEpoch: 0175 loss_train: 1.2418 acc_train: 0.8428 loss_val: 1.3428 acc_val: 0.7747 time: 0.0032s\nEpoch: 0176 loss_train: 1.2380 acc_train: 0.8428 loss_val: 1.3392 acc_val: 0.7752 time: 0.0032s\nEpoch: 0177 loss_train: 1.2341 acc_train: 0.8439 loss_val: 1.3356 acc_val: 0.7769 time: 0.0032s\nEpoch: 0178 loss_train: 1.2304 acc_train: 0.8472 loss_val: 1.3320 acc_val: 0.7774 time: 0.0032s\nEpoch: 0179 loss_train: 1.2266 acc_train: 0.8472 loss_val: 1.3284 acc_val: 0.7774 time: 0.0032s\nEpoch: 0180 loss_train: 1.2229 acc_train: 0.8483 loss_val: 1.3249 acc_val: 0.7780 time: 0.0032s\nEpoch: 0181 loss_train: 1.2192 acc_train: 0.8483 loss_val: 1.3214 acc_val: 0.7780 time: 0.0032s\nEpoch: 0182 loss_train: 1.2155 acc_train: 0.8483 loss_val: 1.3179 acc_val: 0.7785 time: 0.0032s\nEpoch: 0183 loss_train: 1.2118 acc_train: 0.8483 loss_val: 1.3145 acc_val: 0.7801 time: 0.0032s\nEpoch: 0184 loss_train: 1.2082 acc_train: 0.8493 loss_val: 1.3110 acc_val: 0.7818 time: 0.0032s\nEpoch: 0185 loss_train: 1.2046 acc_train: 0.8504 loss_val: 1.3076 acc_val: 0.7829 time: 0.0032s\nEpoch: 0186 loss_train: 1.2010 acc_train: 0.8515 loss_val: 1.3042 acc_val: 0.7834 time: 0.0032s\nEpoch: 0187 loss_train: 1.1974 acc_train: 0.8526 loss_val: 1.3008 acc_val: 0.7840 time: 0.0032s\nEpoch: 0188 loss_train: 1.1939 acc_train: 0.8537 loss_val: 1.2975 acc_val: 0.7840 time: 0.0032s\nEpoch: 0189 loss_train: 1.1903 acc_train: 0.8548 loss_val: 1.2941 acc_val: 0.7840 time: 0.0032s\nEpoch: 0190 loss_train: 1.1868 acc_train: 0.8548 loss_val: 1.2908 acc_val: 0.7856 time: 0.0032s\nEpoch: 0191 loss_train: 1.1834 acc_train: 0.8548 loss_val: 1.2875 acc_val: 0.7867 time: 0.0032s\nEpoch: 0192 loss_train: 1.1799 acc_train: 0.8548 loss_val: 1.2842 acc_val: 0.7872 time: 0.0032s\nEpoch: 0193 loss_train: 1.1765 acc_train: 0.8548 loss_val: 1.2810 acc_val: 0.7872 time: 0.0032s\nEpoch: 0194 loss_train: 1.1731 acc_train: 0.8548 loss_val: 1.2778 acc_val: 0.7883 time: 0.0032s\nEpoch: 0195 loss_train: 1.1697 acc_train: 0.8537 loss_val: 1.2745 acc_val: 0.7889 time: 0.0032s\nEpoch: 0196 loss_train: 1.1663 acc_train: 0.8548 loss_val: 1.2713 acc_val: 0.7894 time: 0.0032s\nEpoch: 0197 loss_train: 1.1630 acc_train: 0.8548 loss_val: 1.2682 acc_val: 0.7905 time: 0.0032s\nEpoch: 0198 loss_train: 1.1596 acc_train: 0.8548 loss_val: 1.2650 acc_val: 0.7905 time: 0.0032s\nEpoch: 0199 loss_train: 1.1563 acc_train: 0.8548 loss_val: 1.2619 acc_val: 0.7911 time: 0.0032s\nEpoch: 0200 loss_train: 1.1530 acc_train: 0.8581 loss_val: 1.2587 acc_val: 0.7921 time: 0.0032s\nEpoch: 0201 loss_train: 1.1498 acc_train: 0.8603 loss_val: 1.2556 acc_val: 0.7927 time: 0.0032s\nEpoch: 0202 loss_train: 1.1465 acc_train: 0.8603 loss_val: 1.2526 acc_val: 0.7932 time: 0.0032s\nEpoch: 0203 loss_train: 1.1433 acc_train: 0.8614 loss_val: 1.2495 acc_val: 0.7943 time: 0.0032s\nEpoch: 0204 loss_train: 1.1401 acc_train: 0.8614 loss_val: 1.2464 acc_val: 0.7954 time: 0.0032s\nEpoch: 0205 loss_train: 1.1369 acc_train: 0.8624 loss_val: 1.2434 acc_val: 0.7954 time: 0.0032s\nEpoch: 0206 loss_train: 1.1338 acc_train: 0.8635 loss_val: 1.2404 acc_val: 0.7960 time: 0.0032s\nEpoch: 0207 loss_train: 1.1306 acc_train: 0.8646 loss_val: 1.2374 acc_val: 0.7960 time: 0.0032s\nEpoch: 0208 loss_train: 1.1275 acc_train: 0.8657 loss_val: 1.2344 acc_val: 0.7971 time: 0.0032s\nEpoch: 0209 loss_train: 1.1244 acc_train: 0.8657 loss_val: 1.2315 acc_val: 0.7981 time: 0.0032s\nEpoch: 0210 loss_train: 1.1213 acc_train: 0.8657 loss_val: 1.2285 acc_val: 0.7981 time: 0.0032s\nEpoch: 0211 loss_train: 1.1183 acc_train: 0.8657 loss_val: 1.2256 acc_val: 0.7992 time: 0.0032s\nEpoch: 0212 loss_train: 1.1152 acc_train: 0.8657 loss_val: 1.2227 acc_val: 0.7998 time: 0.0032s\nEpoch: 0213 loss_train: 1.1122 acc_train: 0.8668 loss_val: 1.2198 acc_val: 0.7998 time: 0.0032s\nEpoch: 0214 loss_train: 1.1092 acc_train: 0.8657 loss_val: 1.2169 acc_val: 0.8003 time: 0.0032s\nEpoch: 0215 loss_train: 1.1062 acc_train: 0.8657 loss_val: 1.2141 acc_val: 0.8003 time: 0.0032s\nEpoch: 0216 loss_train: 1.1032 acc_train: 0.8657 loss_val: 1.2113 acc_val: 0.8009 time: 0.0032s\nEpoch: 0217 loss_train: 1.1003 acc_train: 0.8657 loss_val: 1.2084 acc_val: 0.8009 time: 0.0032s\nEpoch: 0218 loss_train: 1.0973 acc_train: 0.8657 loss_val: 1.2056 acc_val: 0.8009 time: 0.0032s\nEpoch: 0219 loss_train: 1.0944 acc_train: 0.8657 loss_val: 1.2028 acc_val: 0.8014 time: 0.0032s\nEpoch: 0220 loss_train: 1.0915 acc_train: 0.8657 loss_val: 1.2001 acc_val: 0.8020 time: 0.0032s\nEpoch: 0221 loss_train: 1.0886 acc_train: 0.8657 loss_val: 1.1973 acc_val: 0.8025 time: 0.0032s\nEpoch: 0222 loss_train: 1.0858 acc_train: 0.8668 loss_val: 1.1946 acc_val: 0.8025 time: 0.0032s\nEpoch: 0223 loss_train: 1.0829 acc_train: 0.8668 loss_val: 1.1918 acc_val: 0.8025 time: 0.0032s\nEpoch: 0224 loss_train: 1.0801 acc_train: 0.8668 loss_val: 1.1891 acc_val: 0.8031 time: 0.0032s\nEpoch: 0225 loss_train: 1.0773 acc_train: 0.8668 loss_val: 1.1864 acc_val: 0.8047 time: 0.0032s\nEpoch: 0226 loss_train: 1.0745 acc_train: 0.8668 loss_val: 1.1838 acc_val: 0.8052 time: 0.0032s\nEpoch: 0227 loss_train: 1.0717 acc_train: 0.8679 loss_val: 1.1811 acc_val: 0.8052 time: 0.0032s\nEpoch: 0228 loss_train: 1.0689 acc_train: 0.8679 loss_val: 1.1785 acc_val: 0.8052 time: 0.0032s\nEpoch: 0229 loss_train: 1.0662 acc_train: 0.8679 loss_val: 1.1758 acc_val: 0.8058 time: 0.0032s\nEpoch: 0230 loss_train: 1.0635 acc_train: 0.8690 loss_val: 1.1732 acc_val: 0.8058 time: 0.0032s\nEpoch: 0231 loss_train: 1.0608 acc_train: 0.8712 loss_val: 1.1706 acc_val: 0.8069 time: 0.0032s\nEpoch: 0232 loss_train: 1.0581 acc_train: 0.8712 loss_val: 1.1680 acc_val: 0.8074 time: 0.0032s\nEpoch: 0233 loss_train: 1.0554 acc_train: 0.8712 loss_val: 1.1655 acc_val: 0.8074 time: 0.0032s\nEpoch: 0234 loss_train: 1.0527 acc_train: 0.8723 loss_val: 1.1629 acc_val: 0.8069 time: 0.0032s\nEpoch: 0235 loss_train: 1.0501 acc_train: 0.8723 loss_val: 1.1604 acc_val: 0.8080 time: 0.0032s\nEpoch: 0236 loss_train: 1.0474 acc_train: 0.8723 loss_val: 1.1578 acc_val: 0.8085 time: 0.0032s\nEpoch: 0237 loss_train: 1.0448 acc_train: 0.8723 loss_val: 1.1553 acc_val: 0.8101 time: 0.0032s\nEpoch: 0238 loss_train: 1.0422 acc_train: 0.8723 loss_val: 1.1528 acc_val: 0.8112 time: 0.0032s\nEpoch: 0239 loss_train: 1.0396 acc_train: 0.8723 loss_val: 1.1503 acc_val: 0.8123 time: 0.0032s\nEpoch: 0240 loss_train: 1.0371 acc_train: 0.8723 loss_val: 1.1479 acc_val: 0.8140 time: 0.0032s\nEpoch: 0241 loss_train: 1.0345 acc_train: 0.8734 loss_val: 1.1454 acc_val: 0.8140 time: 0.0032s\nEpoch: 0242 loss_train: 1.0320 acc_train: 0.8734 loss_val: 1.1430 acc_val: 0.8140 time: 0.0032s\nEpoch: 0243 loss_train: 1.0295 acc_train: 0.8734 loss_val: 1.1405 acc_val: 0.8140 time: 0.0032s\nEpoch: 0244 loss_train: 1.0270 acc_train: 0.8745 loss_val: 1.1381 acc_val: 0.8145 time: 0.0032s\nEpoch: 0245 loss_train: 1.0245 acc_train: 0.8745 loss_val: 1.1357 acc_val: 0.8156 time: 0.0032s\nEpoch: 0246 loss_train: 1.0220 acc_train: 0.8745 loss_val: 1.1333 acc_val: 0.8156 time: 0.0032s\nEpoch: 0247 loss_train: 1.0195 acc_train: 0.8734 loss_val: 1.1310 acc_val: 0.8151 time: 0.0032s\nEpoch: 0248 loss_train: 1.0171 acc_train: 0.8734 loss_val: 1.1286 acc_val: 0.8151 time: 0.0032s\nEpoch: 0249 loss_train: 1.0146 acc_train: 0.8734 loss_val: 1.1262 acc_val: 0.8151 time: 0.0032s\nEpoch: 0250 loss_train: 1.0122 acc_train: 0.8734 loss_val: 1.1239 acc_val: 0.8161 time: 0.0032s\nEpoch: 0251 loss_train: 1.0098 acc_train: 0.8755 loss_val: 1.1216 acc_val: 0.8172 time: 0.0032s\nEpoch: 0252 loss_train: 1.0074 acc_train: 0.8755 loss_val: 1.1193 acc_val: 0.8172 time: 0.0032s\nEpoch: 0253 loss_train: 1.0050 acc_train: 0.8755 loss_val: 1.1170 acc_val: 0.8178 time: 0.0032s\nEpoch: 0254 loss_train: 1.0027 acc_train: 0.8755 loss_val: 1.1147 acc_val: 0.8183 time: 0.0032s\nEpoch: 0255 loss_train: 1.0003 acc_train: 0.8755 loss_val: 1.1124 acc_val: 0.8183 time: 0.0032s\nEpoch: 0256 loss_train: 0.9980 acc_train: 0.8766 loss_val: 1.1102 acc_val: 0.8189 time: 0.0032s\nEpoch: 0257 loss_train: 0.9957 acc_train: 0.8766 loss_val: 1.1079 acc_val: 0.8200 time: 0.0032s\nEpoch: 0258 loss_train: 0.9933 acc_train: 0.8766 loss_val: 1.1057 acc_val: 0.8200 time: 0.0032s\nEpoch: 0259 loss_train: 0.9910 acc_train: 0.8766 loss_val: 1.1035 acc_val: 0.8205 time: 0.0032s\nEpoch: 0260 loss_train: 0.9888 acc_train: 0.8766 loss_val: 1.1013 acc_val: 0.8205 time: 0.0032s\nEpoch: 0261 loss_train: 0.9865 acc_train: 0.8766 loss_val: 1.0991 acc_val: 0.8205 time: 0.0032s\nEpoch: 0262 loss_train: 0.9842 acc_train: 0.8766 loss_val: 1.0969 acc_val: 0.8211 time: 0.0032s\nEpoch: 0263 loss_train: 0.9820 acc_train: 0.8766 loss_val: 1.0947 acc_val: 0.8216 time: 0.0032s\nEpoch: 0264 loss_train: 0.9798 acc_train: 0.8766 loss_val: 1.0925 acc_val: 0.8221 time: 0.0032s\nEpoch: 0265 loss_train: 0.9775 acc_train: 0.8766 loss_val: 1.0904 acc_val: 0.8221 time: 0.0032s\nEpoch: 0266 loss_train: 0.9753 acc_train: 0.8777 loss_val: 1.0883 acc_val: 0.8221 time: 0.0032s\nEpoch: 0267 loss_train: 0.9731 acc_train: 0.8777 loss_val: 1.0861 acc_val: 0.8227 time: 0.0032s\nEpoch: 0268 loss_train: 0.9710 acc_train: 0.8788 loss_val: 1.0840 acc_val: 0.8227 time: 0.0032s\nEpoch: 0269 loss_train: 0.9688 acc_train: 0.8810 loss_val: 1.0819 acc_val: 0.8232 time: 0.0032s\nEpoch: 0270 loss_train: 0.9666 acc_train: 0.8810 loss_val: 1.0798 acc_val: 0.8232 time: 0.0032s\nEpoch: 0271 loss_train: 0.9645 acc_train: 0.8810 loss_val: 1.0777 acc_val: 0.8243 time: 0.0032s\nEpoch: 0272 loss_train: 0.9623 acc_train: 0.8799 loss_val: 1.0757 acc_val: 0.8254 time: 0.0032s\nEpoch: 0273 loss_train: 0.9602 acc_train: 0.8799 loss_val: 1.0736 acc_val: 0.8254 time: 0.0032s\nEpoch: 0274 loss_train: 0.9581 acc_train: 0.8810 loss_val: 1.0716 acc_val: 0.8254 time: 0.0032s\nEpoch: 0275 loss_train: 0.9560 acc_train: 0.8810 loss_val: 1.0695 acc_val: 0.8254 time: 0.0032s\nEpoch: 0276 loss_train: 0.9539 acc_train: 0.8810 loss_val: 1.0675 acc_val: 0.8260 time: 0.0032s\nEpoch: 0277 loss_train: 0.9519 acc_train: 0.8810 loss_val: 1.0655 acc_val: 0.8265 time: 0.0032s\nEpoch: 0278 loss_train: 0.9498 acc_train: 0.8810 loss_val: 1.0635 acc_val: 0.8265 time: 0.0032s\nEpoch: 0279 loss_train: 0.9477 acc_train: 0.8810 loss_val: 1.0615 acc_val: 0.8271 time: 0.0032s\nEpoch: 0280 loss_train: 0.9457 acc_train: 0.8810 loss_val: 1.0595 acc_val: 0.8276 time: 0.0032s\nEpoch: 0281 loss_train: 0.9437 acc_train: 0.8810 loss_val: 1.0575 acc_val: 0.8287 time: 0.0032s\nEpoch: 0282 loss_train: 0.9417 acc_train: 0.8810 loss_val: 1.0556 acc_val: 0.8287 time: 0.0032s\nEpoch: 0283 loss_train: 0.9397 acc_train: 0.8821 loss_val: 1.0536 acc_val: 0.8282 time: 0.0032s\nEpoch: 0284 loss_train: 0.9377 acc_train: 0.8821 loss_val: 1.0517 acc_val: 0.8282 time: 0.0032s\nEpoch: 0285 loss_train: 0.9357 acc_train: 0.8821 loss_val: 1.0497 acc_val: 0.8282 time: 0.0032s\nEpoch: 0286 loss_train: 0.9337 acc_train: 0.8832 loss_val: 1.0478 acc_val: 0.8282 time: 0.0032s\nEpoch: 0287 loss_train: 0.9317 acc_train: 0.8832 loss_val: 1.0459 acc_val: 0.8298 time: 0.0032s\nEpoch: 0288 loss_train: 0.9298 acc_train: 0.8843 loss_val: 1.0440 acc_val: 0.8298 time: 0.0032s\nEpoch: 0289 loss_train: 0.9279 acc_train: 0.8843 loss_val: 1.0421 acc_val: 0.8298 time: 0.0032s\nEpoch: 0290 loss_train: 0.9259 acc_train: 0.8843 loss_val: 1.0402 acc_val: 0.8303 time: 0.0032s\nEpoch: 0291 loss_train: 0.9240 acc_train: 0.8854 loss_val: 1.0384 acc_val: 0.8309 time: 0.0032s\nEpoch: 0292 loss_train: 0.9221 acc_train: 0.8854 loss_val: 1.0365 acc_val: 0.8303 time: 0.0032s\nEpoch: 0293 loss_train: 0.9202 acc_train: 0.8865 loss_val: 1.0347 acc_val: 0.8314 time: 0.0032s\nEpoch: 0294 loss_train: 0.9183 acc_train: 0.8876 loss_val: 1.0328 acc_val: 0.8320 time: 0.0032s\nEpoch: 0295 loss_train: 0.9164 acc_train: 0.8876 loss_val: 1.0310 acc_val: 0.8320 time: 0.0032s\nEpoch: 0296 loss_train: 0.9146 acc_train: 0.8876 loss_val: 1.0292 acc_val: 0.8320 time: 0.0033s\nEpoch: 0297 loss_train: 0.9127 acc_train: 0.8876 loss_val: 1.0274 acc_val: 0.8325 time: 0.0032s\nEpoch: 0298 loss_train: 0.9109 acc_train: 0.8876 loss_val: 1.0255 acc_val: 0.8331 time: 0.0032s\nEpoch: 0299 loss_train: 0.9090 acc_train: 0.8876 loss_val: 1.0238 acc_val: 0.8342 time: 0.0032s\nEpoch: 0300 loss_train: 0.9072 acc_train: 0.8886 loss_val: 1.0220 acc_val: 0.8347 time: 0.0032s\nEpoch: 0301 loss_train: 0.9054 acc_train: 0.8886 loss_val: 1.0202 acc_val: 0.8352 time: 0.0032s\nEpoch: 0302 loss_train: 0.9036 acc_train: 0.8886 loss_val: 1.0184 acc_val: 0.8352 time: 0.0032s\nEpoch: 0303 loss_train: 0.9018 acc_train: 0.8886 loss_val: 1.0167 acc_val: 0.8352 time: 0.0032s\nEpoch: 0304 loss_train: 0.9000 acc_train: 0.8897 loss_val: 1.0149 acc_val: 0.8352 time: 0.0032s\nEpoch: 0305 loss_train: 0.8982 acc_train: 0.8897 loss_val: 1.0132 acc_val: 0.8352 time: 0.0032s\nEpoch: 0306 loss_train: 0.8964 acc_train: 0.8908 loss_val: 1.0114 acc_val: 0.8352 time: 0.0032s\nEpoch: 0307 loss_train: 0.8947 acc_train: 0.8908 loss_val: 1.0097 acc_val: 0.8352 time: 0.0032s\nEpoch: 0308 loss_train: 0.8929 acc_train: 0.8908 loss_val: 1.0080 acc_val: 0.8352 time: 0.0032s\nEpoch: 0309 loss_train: 0.8912 acc_train: 0.8908 loss_val: 1.0063 acc_val: 0.8358 time: 0.0032s\nEpoch: 0310 loss_train: 0.8895 acc_train: 0.8930 loss_val: 1.0046 acc_val: 0.8358 time: 0.0032s\nEpoch: 0311 loss_train: 0.8877 acc_train: 0.8930 loss_val: 1.0029 acc_val: 0.8358 time: 0.0032s\nEpoch: 0312 loss_train: 0.8860 acc_train: 0.8930 loss_val: 1.0012 acc_val: 0.8363 time: 0.0032s\nEpoch: 0313 loss_train: 0.8843 acc_train: 0.8930 loss_val: 0.9996 acc_val: 0.8363 time: 0.0032s\nEpoch: 0314 loss_train: 0.8826 acc_train: 0.8930 loss_val: 0.9979 acc_val: 0.8363 time: 0.0032s\nEpoch: 0315 loss_train: 0.8809 acc_train: 0.8930 loss_val: 0.9963 acc_val: 0.8369 time: 0.0032s\nEpoch: 0316 loss_train: 0.8793 acc_train: 0.8930 loss_val: 0.9946 acc_val: 0.8369 time: 0.0032s\nEpoch: 0317 loss_train: 0.8776 acc_train: 0.8941 loss_val: 0.9930 acc_val: 0.8369 time: 0.0032s\nEpoch: 0318 loss_train: 0.8759 acc_train: 0.8941 loss_val: 0.9913 acc_val: 0.8369 time: 0.0032s\nEpoch: 0319 loss_train: 0.8743 acc_train: 0.8941 loss_val: 0.9897 acc_val: 0.8369 time: 0.0032s\nEpoch: 0320 loss_train: 0.8726 acc_train: 0.8941 loss_val: 0.9881 acc_val: 0.8380 time: 0.0032s\nEpoch: 0321 loss_train: 0.8710 acc_train: 0.8941 loss_val: 0.9865 acc_val: 0.8380 time: 0.0032s\nEpoch: 0322 loss_train: 0.8694 acc_train: 0.8941 loss_val: 0.9849 acc_val: 0.8402 time: 0.0032s\nEpoch: 0323 loss_train: 0.8677 acc_train: 0.8941 loss_val: 0.9833 acc_val: 0.8407 time: 0.0032s\nEpoch: 0324 loss_train: 0.8661 acc_train: 0.8941 loss_val: 0.9817 acc_val: 0.8412 time: 0.0032s\nEpoch: 0325 loss_train: 0.8645 acc_train: 0.8963 loss_val: 0.9802 acc_val: 0.8412 time: 0.0032s\nEpoch: 0326 loss_train: 0.8629 acc_train: 0.8963 loss_val: 0.9786 acc_val: 0.8418 time: 0.0032s\nEpoch: 0327 loss_train: 0.8614 acc_train: 0.8963 loss_val: 0.9770 acc_val: 0.8423 time: 0.0032s\nEpoch: 0328 loss_train: 0.8598 acc_train: 0.8963 loss_val: 0.9755 acc_val: 0.8434 time: 0.0032s\nEpoch: 0329 loss_train: 0.8582 acc_train: 0.8963 loss_val: 0.9739 acc_val: 0.8434 time: 0.0032s\nEpoch: 0330 loss_train: 0.8567 acc_train: 0.8963 loss_val: 0.9724 acc_val: 0.8445 time: 0.0032s\nEpoch: 0331 loss_train: 0.8551 acc_train: 0.8963 loss_val: 0.9709 acc_val: 0.8445 time: 0.0032s\nEpoch: 0332 loss_train: 0.8536 acc_train: 0.8963 loss_val: 0.9694 acc_val: 0.8445 time: 0.0032s\nEpoch: 0333 loss_train: 0.8520 acc_train: 0.8963 loss_val: 0.9678 acc_val: 0.8440 time: 0.0032s\nEpoch: 0334 loss_train: 0.8505 acc_train: 0.8963 loss_val: 0.9663 acc_val: 0.8440 time: 0.0032s\nEpoch: 0335 loss_train: 0.8490 acc_train: 0.8963 loss_val: 0.9648 acc_val: 0.8440 time: 0.0032s\nEpoch: 0336 loss_train: 0.8475 acc_train: 0.8974 loss_val: 0.9633 acc_val: 0.8445 time: 0.0032s\nEpoch: 0337 loss_train: 0.8459 acc_train: 0.8974 loss_val: 0.9619 acc_val: 0.8451 time: 0.0032s\nEpoch: 0338 loss_train: 0.8444 acc_train: 0.8974 loss_val: 0.9604 acc_val: 0.8456 time: 0.0032s\nEpoch: 0339 loss_train: 0.8430 acc_train: 0.8974 loss_val: 0.9589 acc_val: 0.8456 time: 0.0032s\nEpoch: 0340 loss_train: 0.8415 acc_train: 0.8985 loss_val: 0.9575 acc_val: 0.8456 time: 0.0032s\nEpoch: 0341 loss_train: 0.8400 acc_train: 0.8985 loss_val: 0.9560 acc_val: 0.8456 time: 0.0032s\nEpoch: 0342 loss_train: 0.8385 acc_train: 0.8985 loss_val: 0.9545 acc_val: 0.8456 time: 0.0032s\nEpoch: 0343 loss_train: 0.8371 acc_train: 0.8985 loss_val: 0.9531 acc_val: 0.8462 time: 0.0032s\nEpoch: 0344 loss_train: 0.8356 acc_train: 0.8985 loss_val: 0.9517 acc_val: 0.8462 time: 0.0032s\nEpoch: 0345 loss_train: 0.8342 acc_train: 0.8985 loss_val: 0.9502 acc_val: 0.8462 time: 0.0032s\nEpoch: 0346 loss_train: 0.8327 acc_train: 0.8985 loss_val: 0.9488 acc_val: 0.8462 time: 0.0032s\nEpoch: 0347 loss_train: 0.8313 acc_train: 0.8996 loss_val: 0.9474 acc_val: 0.8467 time: 0.0032s\nEpoch: 0348 loss_train: 0.8299 acc_train: 0.8996 loss_val: 0.9460 acc_val: 0.8467 time: 0.0032s\nEpoch: 0349 loss_train: 0.8285 acc_train: 0.8996 loss_val: 0.9446 acc_val: 0.8472 time: 0.0032s\nEpoch: 0350 loss_train: 0.8270 acc_train: 0.8996 loss_val: 0.9432 acc_val: 0.8472 time: 0.0032s\nEpoch: 0351 loss_train: 0.8256 acc_train: 0.8996 loss_val: 0.9418 acc_val: 0.8472 time: 0.0032s\nEpoch: 0352 loss_train: 0.8242 acc_train: 0.8996 loss_val: 0.9404 acc_val: 0.8478 time: 0.0032s\nEpoch: 0353 loss_train: 0.8228 acc_train: 0.8996 loss_val: 0.9391 acc_val: 0.8483 time: 0.0032s\nEpoch: 0354 loss_train: 0.8215 acc_train: 0.8996 loss_val: 0.9377 acc_val: 0.8483 time: 0.0032s\nEpoch: 0355 loss_train: 0.8201 acc_train: 0.8996 loss_val: 0.9363 acc_val: 0.8483 time: 0.0032s\nEpoch: 0356 loss_train: 0.8187 acc_train: 0.8996 loss_val: 0.9350 acc_val: 0.8483 time: 0.0032s\nEpoch: 0357 loss_train: 0.8174 acc_train: 0.8996 loss_val: 0.9336 acc_val: 0.8489 time: 0.0032s\nEpoch: 0358 loss_train: 0.8160 acc_train: 0.8996 loss_val: 0.9323 acc_val: 0.8494 time: 0.0032s\nEpoch: 0359 loss_train: 0.8146 acc_train: 0.8996 loss_val: 0.9309 acc_val: 0.8500 time: 0.0032s\nEpoch: 0360 loss_train: 0.8133 acc_train: 0.8996 loss_val: 0.9296 acc_val: 0.8500 time: 0.0032s\nEpoch: 0361 loss_train: 0.8120 acc_train: 0.8996 loss_val: 0.9283 acc_val: 0.8505 time: 0.0032s\nEpoch: 0362 loss_train: 0.8106 acc_train: 0.8996 loss_val: 0.9270 acc_val: 0.8516 time: 0.0032s\nEpoch: 0363 loss_train: 0.8093 acc_train: 0.8996 loss_val: 0.9257 acc_val: 0.8522 time: 0.0032s\nEpoch: 0364 loss_train: 0.8080 acc_train: 0.8996 loss_val: 0.9244 acc_val: 0.8522 time: 0.0032s\nEpoch: 0365 loss_train: 0.8067 acc_train: 0.8996 loss_val: 0.9231 acc_val: 0.8527 time: 0.0032s\nEpoch: 0366 loss_train: 0.8054 acc_train: 0.9007 loss_val: 0.9218 acc_val: 0.8527 time: 0.0032s\nEpoch: 0367 loss_train: 0.8041 acc_train: 0.9007 loss_val: 0.9205 acc_val: 0.8538 time: 0.0032s\nEpoch: 0368 loss_train: 0.8028 acc_train: 0.9007 loss_val: 0.9192 acc_val: 0.8538 time: 0.0032s\nEpoch: 0369 loss_train: 0.8015 acc_train: 0.9007 loss_val: 0.9179 acc_val: 0.8543 time: 0.0032s\nEpoch: 0370 loss_train: 0.8002 acc_train: 0.9007 loss_val: 0.9166 acc_val: 0.8543 time: 0.0032s\nEpoch: 0371 loss_train: 0.7989 acc_train: 0.9017 loss_val: 0.9154 acc_val: 0.8543 time: 0.0032s\nEpoch: 0372 loss_train: 0.7977 acc_train: 0.9017 loss_val: 0.9141 acc_val: 0.8549 time: 0.0032s\nEpoch: 0373 loss_train: 0.7964 acc_train: 0.9017 loss_val: 0.9129 acc_val: 0.8560 time: 0.0032s\nEpoch: 0374 loss_train: 0.7952 acc_train: 0.9028 loss_val: 0.9116 acc_val: 0.8565 time: 0.0032s\nEpoch: 0375 loss_train: 0.7939 acc_train: 0.9028 loss_val: 0.9104 acc_val: 0.8576 time: 0.0032s\nEpoch: 0376 loss_train: 0.7927 acc_train: 0.9028 loss_val: 0.9091 acc_val: 0.8582 time: 0.0032s\nEpoch: 0377 loss_train: 0.7914 acc_train: 0.9028 loss_val: 0.9079 acc_val: 0.8582 time: 0.0032s\nEpoch: 0378 loss_train: 0.7902 acc_train: 0.9028 loss_val: 0.9067 acc_val: 0.8582 time: 0.0032s\nEpoch: 0379 loss_train: 0.7890 acc_train: 0.9028 loss_val: 0.9055 acc_val: 0.8582 time: 0.0032s\nEpoch: 0380 loss_train: 0.7877 acc_train: 0.9028 loss_val: 0.9043 acc_val: 0.8582 time: 0.0032s\nEpoch: 0381 loss_train: 0.7865 acc_train: 0.9028 loss_val: 0.9030 acc_val: 0.8587 time: 0.0032s\nEpoch: 0382 loss_train: 0.7853 acc_train: 0.9028 loss_val: 0.9018 acc_val: 0.8592 time: 0.0032s\nEpoch: 0383 loss_train: 0.7841 acc_train: 0.9028 loss_val: 0.9006 acc_val: 0.8598 time: 0.0032s\nEpoch: 0384 loss_train: 0.7829 acc_train: 0.9028 loss_val: 0.8995 acc_val: 0.8598 time: 0.0032s\nEpoch: 0385 loss_train: 0.7817 acc_train: 0.9028 loss_val: 0.8983 acc_val: 0.8609 time: 0.0032s\nEpoch: 0386 loss_train: 0.7805 acc_train: 0.9028 loss_val: 0.8971 acc_val: 0.8609 time: 0.0032s\nEpoch: 0387 loss_train: 0.7793 acc_train: 0.9028 loss_val: 0.8959 acc_val: 0.8609 time: 0.0032s\nEpoch: 0388 loss_train: 0.7782 acc_train: 0.9028 loss_val: 0.8947 acc_val: 0.8609 time: 0.0032s\nEpoch: 0389 loss_train: 0.7770 acc_train: 0.9028 loss_val: 0.8936 acc_val: 0.8609 time: 0.0032s\nEpoch: 0390 loss_train: 0.7758 acc_train: 0.9039 loss_val: 0.8924 acc_val: 0.8609 time: 0.0032s\nEpoch: 0391 loss_train: 0.7747 acc_train: 0.9039 loss_val: 0.8913 acc_val: 0.8609 time: 0.0032s\nEpoch: 0392 loss_train: 0.7735 acc_train: 0.9039 loss_val: 0.8901 acc_val: 0.8609 time: 0.0032s\nEpoch: 0393 loss_train: 0.7724 acc_train: 0.9039 loss_val: 0.8890 acc_val: 0.8609 time: 0.0032s\nEpoch: 0394 loss_train: 0.7712 acc_train: 0.9039 loss_val: 0.8878 acc_val: 0.8614 time: 0.0032s\nEpoch: 0395 loss_train: 0.7701 acc_train: 0.9039 loss_val: 0.8867 acc_val: 0.8614 time: 0.0032s\nEpoch: 0396 loss_train: 0.7689 acc_train: 0.9039 loss_val: 0.8855 acc_val: 0.8620 time: 0.0032s\nEpoch: 0397 loss_train: 0.7678 acc_train: 0.9039 loss_val: 0.8844 acc_val: 0.8620 time: 0.0032s\nEpoch: 0398 loss_train: 0.7667 acc_train: 0.9039 loss_val: 0.8833 acc_val: 0.8620 time: 0.0032s\nEpoch: 0399 loss_train: 0.7656 acc_train: 0.9039 loss_val: 0.8822 acc_val: 0.8620 time: 0.0032s\nEpoch: 0400 loss_train: 0.7645 acc_train: 0.9039 loss_val: 0.8811 acc_val: 0.8620 time: 0.0032s\nEpoch: 0401 loss_train: 0.7633 acc_train: 0.9039 loss_val: 0.8800 acc_val: 0.8620 time: 0.0032s\nEpoch: 0402 loss_train: 0.7622 acc_train: 0.9039 loss_val: 0.8789 acc_val: 0.8625 time: 0.0032s\nEpoch: 0403 loss_train: 0.7611 acc_train: 0.9039 loss_val: 0.8778 acc_val: 0.8620 time: 0.0032s\nEpoch: 0404 loss_train: 0.7601 acc_train: 0.9050 loss_val: 0.8767 acc_val: 0.8620 time: 0.0032s\nEpoch: 0405 loss_train: 0.7590 acc_train: 0.9050 loss_val: 0.8756 acc_val: 0.8620 time: 0.0032s\nEpoch: 0406 loss_train: 0.7579 acc_train: 0.9050 loss_val: 0.8745 acc_val: 0.8620 time: 0.0032s\nEpoch: 0407 loss_train: 0.7568 acc_train: 0.9061 loss_val: 0.8734 acc_val: 0.8620 time: 0.0032s\nEpoch: 0408 loss_train: 0.7557 acc_train: 0.9061 loss_val: 0.8724 acc_val: 0.8620 time: 0.0032s\nEpoch: 0409 loss_train: 0.7547 acc_train: 0.9061 loss_val: 0.8713 acc_val: 0.8625 time: 0.0032s\nEpoch: 0410 loss_train: 0.7536 acc_train: 0.9072 loss_val: 0.8702 acc_val: 0.8631 time: 0.0032s\nEpoch: 0411 loss_train: 0.7525 acc_train: 0.9083 loss_val: 0.8692 acc_val: 0.8631 time: 0.0032s\nEpoch: 0412 loss_train: 0.7515 acc_train: 0.9083 loss_val: 0.8681 acc_val: 0.8636 time: 0.0032s\nEpoch: 0413 loss_train: 0.7504 acc_train: 0.9083 loss_val: 0.8671 acc_val: 0.8642 time: 0.0032s\nEpoch: 0414 loss_train: 0.7494 acc_train: 0.9083 loss_val: 0.8660 acc_val: 0.8642 time: 0.0032s\nEpoch: 0415 loss_train: 0.7483 acc_train: 0.9094 loss_val: 0.8650 acc_val: 0.8647 time: 0.0032s\nEpoch: 0416 loss_train: 0.7473 acc_train: 0.9094 loss_val: 0.8639 acc_val: 0.8647 time: 0.0032s\nEpoch: 0417 loss_train: 0.7463 acc_train: 0.9094 loss_val: 0.8629 acc_val: 0.8658 time: 0.0032s\nEpoch: 0418 loss_train: 0.7452 acc_train: 0.9105 loss_val: 0.8619 acc_val: 0.8658 time: 0.0032s\nEpoch: 0419 loss_train: 0.7442 acc_train: 0.9105 loss_val: 0.8609 acc_val: 0.8658 time: 0.0032s\nEpoch: 0420 loss_train: 0.7432 acc_train: 0.9105 loss_val: 0.8598 acc_val: 0.8663 time: 0.0032s\nEpoch: 0421 loss_train: 0.7422 acc_train: 0.9105 loss_val: 0.8588 acc_val: 0.8669 time: 0.0032s\nEpoch: 0422 loss_train: 0.7412 acc_train: 0.9105 loss_val: 0.8578 acc_val: 0.8669 time: 0.0032s\nEpoch: 0423 loss_train: 0.7402 acc_train: 0.9105 loss_val: 0.8568 acc_val: 0.8669 time: 0.0032s\nEpoch: 0424 loss_train: 0.7392 acc_train: 0.9105 loss_val: 0.8558 acc_val: 0.8680 time: 0.0032s\nEpoch: 0425 loss_train: 0.7382 acc_train: 0.9105 loss_val: 0.8548 acc_val: 0.8674 time: 0.0032s\nEpoch: 0426 loss_train: 0.7372 acc_train: 0.9105 loss_val: 0.8538 acc_val: 0.8696 time: 0.0032s\nEpoch: 0427 loss_train: 0.7362 acc_train: 0.9105 loss_val: 0.8528 acc_val: 0.8696 time: 0.0032s\nEpoch: 0428 loss_train: 0.7352 acc_train: 0.9105 loss_val: 0.8518 acc_val: 0.8696 time: 0.0032s\nEpoch: 0429 loss_train: 0.7342 acc_train: 0.9116 loss_val: 0.8508 acc_val: 0.8696 time: 0.0032s\nEpoch: 0430 loss_train: 0.7332 acc_train: 0.9116 loss_val: 0.8499 acc_val: 0.8702 time: 0.0032s\nEpoch: 0431 loss_train: 0.7323 acc_train: 0.9116 loss_val: 0.8489 acc_val: 0.8702 time: 0.0032s\nEpoch: 0432 loss_train: 0.7313 acc_train: 0.9116 loss_val: 0.8479 acc_val: 0.8702 time: 0.0032s\nEpoch: 0433 loss_train: 0.7303 acc_train: 0.9116 loss_val: 0.8470 acc_val: 0.8707 time: 0.0032s\nEpoch: 0434 loss_train: 0.7294 acc_train: 0.9116 loss_val: 0.8460 acc_val: 0.8707 time: 0.0032s\nEpoch: 0435 loss_train: 0.7284 acc_train: 0.9127 loss_val: 0.8450 acc_val: 0.8707 time: 0.0032s\nEpoch: 0436 loss_train: 0.7275 acc_train: 0.9127 loss_val: 0.8441 acc_val: 0.8707 time: 0.0032s\nEpoch: 0437 loss_train: 0.7265 acc_train: 0.9127 loss_val: 0.8431 acc_val: 0.8718 time: 0.0032s\nEpoch: 0438 loss_train: 0.7256 acc_train: 0.9127 loss_val: 0.8422 acc_val: 0.8718 time: 0.0032s\nEpoch: 0439 loss_train: 0.7246 acc_train: 0.9138 loss_val: 0.8412 acc_val: 0.8718 time: 0.0032s\nEpoch: 0440 loss_train: 0.7237 acc_train: 0.9138 loss_val: 0.8403 acc_val: 0.8718 time: 0.0032s\nEpoch: 0441 loss_train: 0.7228 acc_train: 0.9138 loss_val: 0.8394 acc_val: 0.8718 time: 0.0032s\nEpoch: 0442 loss_train: 0.7218 acc_train: 0.9138 loss_val: 0.8384 acc_val: 0.8729 time: 0.0032s\nEpoch: 0443 loss_train: 0.7209 acc_train: 0.9138 loss_val: 0.8375 acc_val: 0.8729 time: 0.0032s\nEpoch: 0444 loss_train: 0.7200 acc_train: 0.9138 loss_val: 0.8366 acc_val: 0.8734 time: 0.0032s\nEpoch: 0445 loss_train: 0.7191 acc_train: 0.9138 loss_val: 0.8357 acc_val: 0.8734 time: 0.0032s\nEpoch: 0446 loss_train: 0.7182 acc_train: 0.9138 loss_val: 0.8347 acc_val: 0.8734 time: 0.0032s\nEpoch: 0447 loss_train: 0.7173 acc_train: 0.9138 loss_val: 0.8338 acc_val: 0.8734 time: 0.0032s\nEpoch: 0448 loss_train: 0.7164 acc_train: 0.9148 loss_val: 0.8329 acc_val: 0.8734 time: 0.0032s\nEpoch: 0449 loss_train: 0.7155 acc_train: 0.9148 loss_val: 0.8320 acc_val: 0.8740 time: 0.0032s\nEpoch: 0450 loss_train: 0.7146 acc_train: 0.9148 loss_val: 0.8311 acc_val: 0.8745 time: 0.0032s\nEpoch: 0451 loss_train: 0.7137 acc_train: 0.9148 loss_val: 0.8302 acc_val: 0.8745 time: 0.0032s\nEpoch: 0452 loss_train: 0.7128 acc_train: 0.9148 loss_val: 0.8293 acc_val: 0.8745 time: 0.0032s\nEpoch: 0453 loss_train: 0.7119 acc_train: 0.9148 loss_val: 0.8284 acc_val: 0.8745 time: 0.0032s\nEpoch: 0454 loss_train: 0.7110 acc_train: 0.9148 loss_val: 0.8275 acc_val: 0.8751 time: 0.0032s\nEpoch: 0455 loss_train: 0.7101 acc_train: 0.9148 loss_val: 0.8267 acc_val: 0.8751 time: 0.0032s\nEpoch: 0456 loss_train: 0.7093 acc_train: 0.9148 loss_val: 0.8258 acc_val: 0.8751 time: 0.0032s\nEpoch: 0457 loss_train: 0.7084 acc_train: 0.9159 loss_val: 0.8249 acc_val: 0.8756 time: 0.0032s\nEpoch: 0458 loss_train: 0.7075 acc_train: 0.9159 loss_val: 0.8240 acc_val: 0.8756 time: 0.0032s\nEpoch: 0459 loss_train: 0.7067 acc_train: 0.9159 loss_val: 0.8232 acc_val: 0.8756 time: 0.0032s\nEpoch: 0460 loss_train: 0.7058 acc_train: 0.9170 loss_val: 0.8223 acc_val: 0.8751 time: 0.0032s\nEpoch: 0461 loss_train: 0.7049 acc_train: 0.9181 loss_val: 0.8214 acc_val: 0.8751 time: 0.0032s\nEpoch: 0462 loss_train: 0.7041 acc_train: 0.9181 loss_val: 0.8206 acc_val: 0.8751 time: 0.0032s\nEpoch: 0463 loss_train: 0.7032 acc_train: 0.9181 loss_val: 0.8197 acc_val: 0.8751 time: 0.0032s\nEpoch: 0464 loss_train: 0.7024 acc_train: 0.9181 loss_val: 0.8189 acc_val: 0.8751 time: 0.0032s\nEpoch: 0465 loss_train: 0.7015 acc_train: 0.9181 loss_val: 0.8180 acc_val: 0.8756 time: 0.0032s\nEpoch: 0466 loss_train: 0.7007 acc_train: 0.9181 loss_val: 0.8172 acc_val: 0.8762 time: 0.0032s\nEpoch: 0467 loss_train: 0.6999 acc_train: 0.9181 loss_val: 0.8163 acc_val: 0.8767 time: 0.0032s\nEpoch: 0468 loss_train: 0.6990 acc_train: 0.9181 loss_val: 0.8155 acc_val: 0.8773 time: 0.0032s\nEpoch: 0469 loss_train: 0.6982 acc_train: 0.9181 loss_val: 0.8147 acc_val: 0.8773 time: 0.0032s\nEpoch: 0470 loss_train: 0.6974 acc_train: 0.9181 loss_val: 0.8138 acc_val: 0.8773 time: 0.0032s\nEpoch: 0471 loss_train: 0.6966 acc_train: 0.9181 loss_val: 0.8130 acc_val: 0.8773 time: 0.0032s\nEpoch: 0472 loss_train: 0.6957 acc_train: 0.9181 loss_val: 0.8122 acc_val: 0.8773 time: 0.0032s\nEpoch: 0473 loss_train: 0.6949 acc_train: 0.9181 loss_val: 0.8113 acc_val: 0.8767 time: 0.0032s\nEpoch: 0474 loss_train: 0.6941 acc_train: 0.9181 loss_val: 0.8105 acc_val: 0.8767 time: 0.0032s\nEpoch: 0475 loss_train: 0.6933 acc_train: 0.9192 loss_val: 0.8097 acc_val: 0.8767 time: 0.0032s\nEpoch: 0476 loss_train: 0.6925 acc_train: 0.9192 loss_val: 0.8089 acc_val: 0.8767 time: 0.0032s\nEpoch: 0477 loss_train: 0.6917 acc_train: 0.9192 loss_val: 0.8081 acc_val: 0.8767 time: 0.0032s\nEpoch: 0478 loss_train: 0.6909 acc_train: 0.9192 loss_val: 0.8073 acc_val: 0.8773 time: 0.0032s\nEpoch: 0479 loss_train: 0.6901 acc_train: 0.9192 loss_val: 0.8065 acc_val: 0.8773 time: 0.0032s\nEpoch: 0480 loss_train: 0.6893 acc_train: 0.9192 loss_val: 0.8057 acc_val: 0.8773 time: 0.0032s\nEpoch: 0481 loss_train: 0.6885 acc_train: 0.9192 loss_val: 0.8049 acc_val: 0.8773 time: 0.0032s\nEpoch: 0482 loss_train: 0.6877 acc_train: 0.9192 loss_val: 0.8041 acc_val: 0.8778 time: 0.0032s\nEpoch: 0483 loss_train: 0.6869 acc_train: 0.9192 loss_val: 0.8033 acc_val: 0.8778 time: 0.0032s\nEpoch: 0484 loss_train: 0.6861 acc_train: 0.9192 loss_val: 0.8025 acc_val: 0.8778 time: 0.0032s\nEpoch: 0485 loss_train: 0.6854 acc_train: 0.9192 loss_val: 0.8017 acc_val: 0.8778 time: 0.0032s\nEpoch: 0486 loss_train: 0.6846 acc_train: 0.9192 loss_val: 0.8009 acc_val: 0.8778 time: 0.0032s\nEpoch: 0487 loss_train: 0.6838 acc_train: 0.9192 loss_val: 0.8001 acc_val: 0.8783 time: 0.0032s\nEpoch: 0488 loss_train: 0.6830 acc_train: 0.9192 loss_val: 0.7994 acc_val: 0.8783 time: 0.0032s\nEpoch: 0489 loss_train: 0.6823 acc_train: 0.9192 loss_val: 0.7986 acc_val: 0.8783 time: 0.0032s\nEpoch: 0490 loss_train: 0.6815 acc_train: 0.9192 loss_val: 0.7978 acc_val: 0.8783 time: 0.0032s\nEpoch: 0491 loss_train: 0.6808 acc_train: 0.9192 loss_val: 0.7970 acc_val: 0.8783 time: 0.0032s\nEpoch: 0492 loss_train: 0.6800 acc_train: 0.9192 loss_val: 0.7963 acc_val: 0.8783 time: 0.0032s\nEpoch: 0493 loss_train: 0.6792 acc_train: 0.9192 loss_val: 0.7955 acc_val: 0.8783 time: 0.0032s\nEpoch: 0494 loss_train: 0.6785 acc_train: 0.9192 loss_val: 0.7948 acc_val: 0.8783 time: 0.0032s\nEpoch: 0495 loss_train: 0.6777 acc_train: 0.9192 loss_val: 0.7940 acc_val: 0.8783 time: 0.0032s\nEpoch: 0496 loss_train: 0.6770 acc_train: 0.9192 loss_val: 0.7932 acc_val: 0.8783 time: 0.0032s\nEpoch: 0497 loss_train: 0.6762 acc_train: 0.9192 loss_val: 0.7925 acc_val: 0.8783 time: 0.0032s\nEpoch: 0498 loss_train: 0.6755 acc_train: 0.9192 loss_val: 0.7917 acc_val: 0.8783 time: 0.0032s\nEpoch: 0499 loss_train: 0.6748 acc_train: 0.9192 loss_val: 0.7910 acc_val: 0.8783 time: 0.0032s\nEpoch: 0500 loss_train: 0.6740 acc_train: 0.9192 loss_val: 0.7902 acc_val: 0.8783 time: 0.0032s\nEpoch: 0001 loss_train: 0.6733 acc_train: 0.9192 loss_val: 0.7902 acc_val: 0.8783 time: 0.0030s\nRanking optimizing... \nNow Average ERR@k =  0.9075866341590881\nEpoch: 0002 loss_train: 0.6726 acc_train: 0.9192 loss_val: 0.7894 acc_val: 0.8783 time: 0.0042s\nRanking optimizing... \nNow Average ERR@k =  0.9078079462051392\nEpoch: 0003 loss_train: 0.6720 acc_train: 0.9214 loss_val: 0.7885 acc_val: 0.8789 time: 0.0038s\nRanking optimizing... \nNow Average ERR@k =  0.9080208539962769\nEpoch: 0004 loss_train: 0.6715 acc_train: 0.9225 loss_val: 0.7876 acc_val: 0.8789 time: 0.0036s\nRanking optimizing... \nNow Average ERR@k =  0.9082485437393188\nEpoch: 0005 loss_train: 0.6710 acc_train: 0.9225 loss_val: 0.7867 acc_val: 0.8794 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.9086170792579651\nEpoch: 0006 loss_train: 0.6707 acc_train: 0.9225 loss_val: 0.7860 acc_val: 0.8805 time: 0.0036s\nRanking optimizing... \nNow Average ERR@k =  0.9088467955589294\nEpoch: 0007 loss_train: 0.6705 acc_train: 0.9236 loss_val: 0.7853 acc_val: 0.8833 time: 0.0035s\nRanking optimizing... \nNow Average ERR@k =  0.9089442491531372\nEpoch: 0008 loss_train: 0.6705 acc_train: 0.9225 loss_val: 0.7847 acc_val: 0.8849 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.9092094898223877\nEpoch: 0009 loss_train: 0.6706 acc_train: 0.9225 loss_val: 0.7843 acc_val: 0.8865 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.9096792936325073\nEpoch: 0010 loss_train: 0.6708 acc_train: 0.9225 loss_val: 0.7839 acc_val: 0.8865 time: 0.0036s\nRanking optimizing... \nNow Average ERR@k =  0.9099308848381042\nEpoch: 0011 loss_train: 0.6711 acc_train: 0.9247 loss_val: 0.7837 acc_val: 0.8882 time: 0.0035s\nRanking optimizing... \nNow Average ERR@k =  0.9106194376945496\nEpoch: 0012 loss_train: 0.6715 acc_train: 0.9247 loss_val: 0.7835 acc_val: 0.8887 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.9111111164093018\nEpoch: 0013 loss_train: 0.6721 acc_train: 0.9247 loss_val: 0.7835 acc_val: 0.8893 time: 0.0037s\nRanking optimizing... \nNow Average ERR@k =  0.9117481112480164\nEpoch: 0014 loss_train: 0.6728 acc_train: 0.9247 loss_val: 0.7836 acc_val: 0.8903 time: 0.0042s\nRanking optimizing... \nNow Average ERR@k =  0.9116723537445068\nEpoch: 0015 loss_train: 0.6736 acc_train: 0.9258 loss_val: 0.7839 acc_val: 0.8909 time: 0.0044s\nRanking optimizing... \nNow Average ERR@k =  0.9122804403305054\nEpoch: 0016 loss_train: 0.6745 acc_train: 0.9269 loss_val: 0.7842 acc_val: 0.8914 time: 0.0039s\nRanking optimizing... \nNow Average ERR@k =  0.9126256108283997\nEpoch: 0017 loss_train: 0.6753 acc_train: 0.9279 loss_val: 0.7846 acc_val: 0.8936 time: 0.0044s\nRanking optimizing... \nNow Average ERR@k =  0.9130438566207886\nEpoch: 0018 loss_train: 0.6761 acc_train: 0.9279 loss_val: 0.7850 acc_val: 0.8936 time: 0.0042s\nRanking optimizing... \nNow Average ERR@k =  0.9132136106491089\nEpoch: 0019 loss_train: 0.6769 acc_train: 0.9290 loss_val: 0.7854 acc_val: 0.8942 time: 0.0041s\nRanking optimizing... \nNow Average ERR@k =  0.9141271114349365\nEpoch: 0020 loss_train: 0.6777 acc_train: 0.9312 loss_val: 0.7859 acc_val: 0.8947 time: 0.0041s\nRanking optimizing... \nNow Average ERR@k =  0.9146637320518494\nEpoch: 0021 loss_train: 0.6785 acc_train: 0.9312 loss_val: 0.7865 acc_val: 0.8969 time: 0.0046s\nRanking optimizing... \nNow Average ERR@k =  0.915092408657074\nEpoch: 0022 loss_train: 0.6793 acc_train: 0.9334 loss_val: 0.7871 acc_val: 0.8980 time: 0.0040s\nRanking optimizing... \nNow Average ERR@k =  0.9151618480682373\nEpoch: 0023 loss_train: 0.6803 acc_train: 0.9345 loss_val: 0.7879 acc_val: 0.8958 time: 0.0040s\nRanking optimizing... \nNow Average ERR@k =  0.9157090187072754\nEpoch: 0024 loss_train: 0.6814 acc_train: 0.9356 loss_val: 0.7889 acc_val: 0.8953 time: 0.0042s\nRanking optimizing... \nNow Average ERR@k =  0.9161472916603088\nEpoch: 0025 loss_train: 0.6827 acc_train: 0.9356 loss_val: 0.7900 acc_val: 0.8974 time: 0.0040s\nRanking optimizing... \nNow Average ERR@k =  0.9162134528160095\nEpoch: 0026 loss_train: 0.6842 acc_train: 0.9356 loss_val: 0.7912 acc_val: 0.8980 time: 0.0041s\nRanking optimizing... \nNow Average ERR@k =  0.9166776537895203\nEpoch: 0027 loss_train: 0.6858 acc_train: 0.9356 loss_val: 0.7925 acc_val: 0.8980 time: 0.0050s\nRanking optimizing... \nNow Average ERR@k =  0.9167776703834534\nEpoch: 0028 loss_train: 0.6876 acc_train: 0.9367 loss_val: 0.7938 acc_val: 0.8996 time: 0.0046s\nRanking optimizing... \nNow Average ERR@k =  0.9171831607818604\nEpoch: 0029 loss_train: 0.6894 acc_train: 0.9378 loss_val: 0.7952 acc_val: 0.9002 time: 0.0037s\nRanking optimizing... \nNow Average ERR@k =  0.9175125360488892\nEpoch: 0030 loss_train: 0.6913 acc_train: 0.9367 loss_val: 0.7967 acc_val: 0.9034 time: 0.0037s\nRanking optimizing... \nNow Average ERR@k =  0.9179005026817322\nEpoch: 0031 loss_train: 0.6934 acc_train: 0.9367 loss_val: 0.7982 acc_val: 0.9023 time: 0.0040s\nRanking optimizing... \nNow Average ERR@k =  0.9183626770973206\nEpoch: 0032 loss_train: 0.6955 acc_train: 0.9356 loss_val: 0.7998 acc_val: 0.9023 time: 0.0050s\nRanking optimizing... \nNow Average ERR@k =  0.9189839363098145\nEpoch: 0033 loss_train: 0.6978 acc_train: 0.9356 loss_val: 0.8016 acc_val: 0.9029 time: 0.0048s\nRanking optimizing... \nNow Average ERR@k =  0.9191686511039734\nEpoch: 0034 loss_train: 0.7001 acc_train: 0.9345 loss_val: 0.8035 acc_val: 0.9034 time: 0.0045s\nRanking optimizing... \nNow Average ERR@k =  0.9192516207695007\nEpoch: 0035 loss_train: 0.7026 acc_train: 0.9334 loss_val: 0.8056 acc_val: 0.9029 time: 0.0038s\nRanking optimizing... \nNow Average ERR@k =  0.9194031953811646\nEpoch: 0036 loss_train: 0.7052 acc_train: 0.9334 loss_val: 0.8078 acc_val: 0.9023 time: 0.0037s\nRanking optimizing... \nNow Average ERR@k =  0.9193816781044006\nEpoch: 0037 loss_train: 0.7079 acc_train: 0.9334 loss_val: 0.8103 acc_val: 0.9034 time: 0.0040s\nRanking optimizing... \nNow Average ERR@k =  0.9195966124534607\nEpoch: 0038 loss_train: 0.7106 acc_train: 0.9334 loss_val: 0.8128 acc_val: 0.9023 time: 0.0049s\nRanking optimizing... \nNow Average ERR@k =  0.9195461273193359\nEpoch: 0039 loss_train: 0.7134 acc_train: 0.9345 loss_val: 0.8155 acc_val: 0.9018 time: 0.0041s\nRanking optimizing... \nNow Average ERR@k =  0.9200403094291687\nEpoch: 0040 loss_train: 0.7163 acc_train: 0.9356 loss_val: 0.8183 acc_val: 0.9023 time: 0.0039s\nRanking optimizing... \nNow Average ERR@k =  0.9206617474555969\nTest set results: loss= 0.7956 accuracy= 0.9076\n"], ["node classification", "feature", "ERR", "coauthor-cs", "GCN", "coauthor-cs\nTotal size :  18333\nUsing coauthor-cs dataset\nEpoch: 0001 loss_train: 2.7453 acc_train: 0.0437 loss_val: 2.7444 acc_val: 0.0486 time: 0.8810s\nRanking optimizing... \nNow Average ERR@k =  0.7832139134407043\nEpoch: 0002 loss_train: 2.7198 acc_train: 0.0437 loss_val: 2.7204 acc_val: 0.0486 time: 0.0116s\nRanking optimizing... \nNow Average ERR@k =  0.783672034740448\nEpoch: 0003 loss_train: 2.6971 acc_train: 0.0459 loss_val: 2.6977 acc_val: 0.0486 time: 0.0130s\nRanking optimizing... \nNow Average ERR@k =  0.7848142981529236\nEpoch: 0004 loss_train: 2.6755 acc_train: 0.0972 loss_val: 2.6759 acc_val: 0.1260 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7807080149650574\nEpoch: 0005 loss_train: 2.6529 acc_train: 0.1485 loss_val: 2.6545 acc_val: 0.1631 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7773182392120361\nEpoch: 0006 loss_train: 2.6315 acc_train: 0.1670 loss_val: 2.6337 acc_val: 0.1779 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7782667279243469\nEpoch: 0007 loss_train: 2.6131 acc_train: 0.1725 loss_val: 2.6136 acc_val: 0.1779 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.775126576423645\nEpoch: 0008 loss_train: 2.5923 acc_train: 0.1867 loss_val: 2.5934 acc_val: 0.1784 time: 0.0117s\nRanking optimizing... \nNow Average ERR@k =  0.7754024267196655\nEpoch: 0009 loss_train: 2.5705 acc_train: 0.1976 loss_val: 2.5727 acc_val: 0.1784 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7774558067321777\nEpoch: 0010 loss_train: 2.5484 acc_train: 0.2063 loss_val: 2.5513 acc_val: 0.1779 time: 0.0130s\nRanking optimizing... \nNow Average ERR@k =  0.7723451256752014\nEpoch: 0011 loss_train: 2.5252 acc_train: 0.2598 loss_val: 2.5294 acc_val: 0.2073 time: 0.0117s\nRanking optimizing... \nNow Average ERR@k =  0.7763325572013855\nEpoch: 0012 loss_train: 2.5022 acc_train: 0.3144 loss_val: 2.5069 acc_val: 0.3164 time: 0.0132s\nRanking optimizing... \nNow Average ERR@k =  0.7779533267021179\nEpoch: 0013 loss_train: 2.4783 acc_train: 0.3646 loss_val: 2.4839 acc_val: 0.3819 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7729663848876953\nEpoch: 0014 loss_train: 2.4537 acc_train: 0.3755 loss_val: 2.4602 acc_val: 0.4004 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7733867168426514\nEpoch: 0015 loss_train: 2.4323 acc_train: 0.3799 loss_val: 2.4360 acc_val: 0.3906 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7706393003463745\nEpoch: 0016 loss_train: 2.4112 acc_train: 0.3537 loss_val: 2.4113 acc_val: 0.3366 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7707532048225403\nEpoch: 0017 loss_train: 2.3826 acc_train: 0.3242 loss_val: 2.3863 acc_val: 0.2968 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7723799347877502\nEpoch: 0018 loss_train: 2.3563 acc_train: 0.3002 loss_val: 2.3610 acc_val: 0.2711 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7693097591400146\nEpoch: 0019 loss_train: 2.3307 acc_train: 0.2686 loss_val: 2.3355 acc_val: 0.2537 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7706629037857056\nEpoch: 0020 loss_train: 2.3076 acc_train: 0.2653 loss_val: 2.3098 acc_val: 0.2477 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7679525017738342\nEpoch: 0021 loss_train: 2.2772 acc_train: 0.2566 loss_val: 2.2842 acc_val: 0.2439 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7708753347396851\nEpoch: 0022 loss_train: 2.2535 acc_train: 0.2489 loss_val: 2.2585 acc_val: 0.2433 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7701572179794312\nEpoch: 0023 loss_train: 2.2280 acc_train: 0.2413 loss_val: 2.2329 acc_val: 0.2439 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7667023539543152\nEpoch: 0024 loss_train: 2.1990 acc_train: 0.2511 loss_val: 2.2075 acc_val: 0.2444 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7710707187652588\nEpoch: 0025 loss_train: 2.1808 acc_train: 0.2587 loss_val: 2.1822 acc_val: 0.2455 time: 0.0132s\nRanking optimizing... \nNow Average ERR@k =  0.7685797810554504\nEpoch: 0026 loss_train: 2.1464 acc_train: 0.2609 loss_val: 2.1571 acc_val: 0.2510 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7684067487716675\nEpoch: 0027 loss_train: 2.1111 acc_train: 0.2718 loss_val: 2.1322 acc_val: 0.2580 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.766320526599884\nEpoch: 0028 loss_train: 2.1027 acc_train: 0.2718 loss_val: 2.1073 acc_val: 0.2679 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.767879068851471\nEpoch: 0029 loss_train: 2.0677 acc_train: 0.2904 loss_val: 2.0823 acc_val: 0.2842 time: 0.0133s\nRanking optimizing... \nNow Average ERR@k =  0.7649133801460266\nEpoch: 0030 loss_train: 2.0457 acc_train: 0.3002 loss_val: 2.0571 acc_val: 0.3126 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7668651938438416\nEpoch: 0031 loss_train: 2.0130 acc_train: 0.3341 loss_val: 2.0315 acc_val: 0.3404 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7693037986755371\nEpoch: 0032 loss_train: 1.9953 acc_train: 0.3548 loss_val: 2.0053 acc_val: 0.3688 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7701521515846252\nEpoch: 0033 loss_train: 1.9531 acc_train: 0.3668 loss_val: 1.9785 acc_val: 0.3928 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7702021598815918\nEpoch: 0034 loss_train: 1.9438 acc_train: 0.3865 loss_val: 1.9511 acc_val: 0.4103 time: 0.0128s\nRanking optimizing... \nNow Average ERR@k =  0.7698601484298706\nEpoch: 0035 loss_train: 1.9011 acc_train: 0.3996 loss_val: 1.9228 acc_val: 0.4250 time: 0.0120s\nRanking optimizing... \nNow Average ERR@k =  0.7678727507591248\nEpoch: 0036 loss_train: 1.8758 acc_train: 0.4061 loss_val: 1.8938 acc_val: 0.4321 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.7657756805419922\nEpoch: 0037 loss_train: 1.8468 acc_train: 0.4170 loss_val: 1.8642 acc_val: 0.4343 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7696816921234131\nEpoch: 0038 loss_train: 1.8165 acc_train: 0.4269 loss_val: 1.8340 acc_val: 0.4381 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7699811458587646\nEpoch: 0039 loss_train: 1.7846 acc_train: 0.4323 loss_val: 1.8034 acc_val: 0.4430 time: 0.0104s\nRanking optimizing... \nNow Average ERR@k =  0.7692075371742249\nEpoch: 0040 loss_train: 1.7579 acc_train: 0.4421 loss_val: 1.7724 acc_val: 0.4501 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7689555287361145\nEpoch: 0041 loss_train: 1.7229 acc_train: 0.4520 loss_val: 1.7411 acc_val: 0.4626 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.766094982624054\nEpoch: 0042 loss_train: 1.6961 acc_train: 0.4782 loss_val: 1.7093 acc_val: 0.4790 time: 0.0098s\nRanking optimizing... \nNow Average ERR@k =  0.7677857875823975\nEpoch: 0043 loss_train: 1.6521 acc_train: 0.4945 loss_val: 1.6775 acc_val: 0.4905 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.7683431506156921\nEpoch: 0044 loss_train: 1.6218 acc_train: 0.5153 loss_val: 1.6455 acc_val: 0.5025 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7692704200744629\nEpoch: 0045 loss_train: 1.5907 acc_train: 0.5295 loss_val: 1.6135 acc_val: 0.5150 time: 0.0116s\nRanking optimizing... \nNow Average ERR@k =  0.7692199349403381\nEpoch: 0046 loss_train: 1.5634 acc_train: 0.5491 loss_val: 1.5813 acc_val: 0.5265 time: 0.0128s\nRanking optimizing... \nNow Average ERR@k =  0.7663998007774353\nEpoch: 0047 loss_train: 1.5197 acc_train: 0.5579 loss_val: 1.5490 acc_val: 0.5314 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7668957114219666\nEpoch: 0048 loss_train: 1.4894 acc_train: 0.5819 loss_val: 1.5165 acc_val: 0.5417 time: 0.0120s\nRanking optimizing... \nNow Average ERR@k =  0.7675049304962158\nEpoch: 0049 loss_train: 1.4666 acc_train: 0.5786 loss_val: 1.4837 acc_val: 0.5576 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7687623500823975\nEpoch: 0050 loss_train: 1.4224 acc_train: 0.6081 loss_val: 1.4507 acc_val: 0.5777 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.769257664680481\nEpoch: 0051 loss_train: 1.3943 acc_train: 0.6168 loss_val: 1.4177 acc_val: 0.5968 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.767848789691925\nEpoch: 0052 loss_train: 1.3698 acc_train: 0.6310 loss_val: 1.3846 acc_val: 0.6176 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7665963172912598\nEpoch: 0053 loss_train: 1.3224 acc_train: 0.6474 loss_val: 1.3516 acc_val: 0.6399 time: 0.0128s\nRanking optimizing... \nNow Average ERR@k =  0.7699702978134155\nEpoch: 0054 loss_train: 1.2983 acc_train: 0.6703 loss_val: 1.3188 acc_val: 0.6536 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7677820920944214\nEpoch: 0055 loss_train: 1.2603 acc_train: 0.6769 loss_val: 1.2864 acc_val: 0.6688 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7686938047409058\nEpoch: 0056 loss_train: 1.2263 acc_train: 0.7041 loss_val: 1.2542 acc_val: 0.6841 time: 0.0150s\nRanking optimizing... \nNow Average ERR@k =  0.7681002616882324\nEpoch: 0057 loss_train: 1.1880 acc_train: 0.7085 loss_val: 1.2225 acc_val: 0.7005 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.768136203289032\nEpoch: 0058 loss_train: 1.1706 acc_train: 0.7216 loss_val: 1.1913 acc_val: 0.7158 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7658493518829346\nEpoch: 0059 loss_train: 1.1324 acc_train: 0.7500 loss_val: 1.1608 acc_val: 0.7267 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7706286907196045\nEpoch: 0060 loss_train: 1.1184 acc_train: 0.7456 loss_val: 1.1309 acc_val: 0.7420 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7659422755241394\nEpoch: 0061 loss_train: 1.0827 acc_train: 0.7740 loss_val: 1.1018 acc_val: 0.7550 time: 0.0130s\nRanking optimizing... \nNow Average ERR@k =  0.7677733302116394\nEpoch: 0062 loss_train: 1.0513 acc_train: 0.7718 loss_val: 1.0735 acc_val: 0.7665 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7699089050292969\nEpoch: 0063 loss_train: 1.0315 acc_train: 0.7762 loss_val: 1.0460 acc_val: 0.7747 time: 0.0129s\nRanking optimizing... \nNow Average ERR@k =  0.7690987586975098\nEpoch: 0064 loss_train: 0.9947 acc_train: 0.7926 loss_val: 1.0194 acc_val: 0.7856 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7703638076782227\nEpoch: 0065 loss_train: 0.9647 acc_train: 0.8079 loss_val: 0.9936 acc_val: 0.7894 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7665734887123108\nEpoch: 0066 loss_train: 0.9530 acc_train: 0.7991 loss_val: 0.9686 acc_val: 0.7949 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7687370181083679\nEpoch: 0067 loss_train: 0.9239 acc_train: 0.8133 loss_val: 0.9444 acc_val: 0.7981 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7691537141799927\nEpoch: 0068 loss_train: 0.8983 acc_train: 0.8275 loss_val: 0.9210 acc_val: 0.8069 time: 0.0126s\nRanking optimizing... \nNow Average ERR@k =  0.7691293954849243\nEpoch: 0069 loss_train: 0.8767 acc_train: 0.8242 loss_val: 0.8986 acc_val: 0.8151 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7672768831253052\nEpoch: 0070 loss_train: 0.8479 acc_train: 0.8341 loss_val: 0.8769 acc_val: 0.8249 time: 0.0104s\nRanking optimizing... \nNow Average ERR@k =  0.7663697600364685\nEpoch: 0071 loss_train: 0.8481 acc_train: 0.8341 loss_val: 0.8559 acc_val: 0.8271 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7678667306900024\nEpoch: 0072 loss_train: 0.8229 acc_train: 0.8308 loss_val: 0.8358 acc_val: 0.8331 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7688432931900024\nEpoch: 0073 loss_train: 0.8009 acc_train: 0.8493 loss_val: 0.8162 acc_val: 0.8391 time: 0.0123s\nRanking optimizing... \nNow Average ERR@k =  0.7686756253242493\nEpoch: 0074 loss_train: 0.7878 acc_train: 0.8472 loss_val: 0.7973 acc_val: 0.8423 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7692174315452576\nEpoch: 0075 loss_train: 0.7750 acc_train: 0.8384 loss_val: 0.7791 acc_val: 0.8478 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7665347456932068\nEpoch: 0076 loss_train: 0.7591 acc_train: 0.8493 loss_val: 0.7616 acc_val: 0.8500 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.769536018371582\nEpoch: 0077 loss_train: 0.7332 acc_train: 0.8646 loss_val: 0.7449 acc_val: 0.8516 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7691669464111328\nEpoch: 0078 loss_train: 0.7129 acc_train: 0.8592 loss_val: 0.7290 acc_val: 0.8543 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7689149379730225\nEpoch: 0079 loss_train: 0.7046 acc_train: 0.8624 loss_val: 0.7138 acc_val: 0.8609 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7663265466690063\nEpoch: 0080 loss_train: 0.6927 acc_train: 0.8603 loss_val: 0.6992 acc_val: 0.8636 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7680544853210449\nEpoch: 0081 loss_train: 0.6783 acc_train: 0.8701 loss_val: 0.6853 acc_val: 0.8652 time: 0.0138s\nRanking optimizing... \nNow Average ERR@k =  0.7661989331245422\nEpoch: 0082 loss_train: 0.6673 acc_train: 0.8635 loss_val: 0.6721 acc_val: 0.8669 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7684006690979004\nEpoch: 0083 loss_train: 0.6553 acc_train: 0.8690 loss_val: 0.6596 acc_val: 0.8702 time: 0.0118s\nRanking optimizing... \nNow Average ERR@k =  0.771050751209259\nEpoch: 0084 loss_train: 0.6408 acc_train: 0.8723 loss_val: 0.6477 acc_val: 0.8740 time: 0.0101s\nRanking optimizing... \nNow Average ERR@k =  0.7664909958839417\nEpoch: 0085 loss_train: 0.6251 acc_train: 0.8799 loss_val: 0.6365 acc_val: 0.8756 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7674450278282166\nEpoch: 0086 loss_train: 0.6170 acc_train: 0.8745 loss_val: 0.6257 acc_val: 0.8767 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7698561549186707\nEpoch: 0087 loss_train: 0.6136 acc_train: 0.8701 loss_val: 0.6154 acc_val: 0.8773 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7671359777450562\nEpoch: 0088 loss_train: 0.5931 acc_train: 0.8865 loss_val: 0.6054 acc_val: 0.8778 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7681207656860352\nEpoch: 0089 loss_train: 0.5884 acc_train: 0.8777 loss_val: 0.5958 acc_val: 0.8800 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.765099048614502\nEpoch: 0090 loss_train: 0.5809 acc_train: 0.8766 loss_val: 0.5867 acc_val: 0.8805 time: 0.0157s\nRanking optimizing... \nNow Average ERR@k =  0.7692298889160156\nEpoch: 0091 loss_train: 0.5714 acc_train: 0.8777 loss_val: 0.5777 acc_val: 0.8805 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7701846957206726\nEpoch: 0092 loss_train: 0.5519 acc_train: 0.8810 loss_val: 0.5690 acc_val: 0.8805 time: 0.0126s\nRanking optimizing... \nNow Average ERR@k =  0.7669968605041504\nEpoch: 0093 loss_train: 0.5627 acc_train: 0.8788 loss_val: 0.5608 acc_val: 0.8794 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.7685850262641907\nEpoch: 0094 loss_train: 0.5487 acc_train: 0.8843 loss_val: 0.5528 acc_val: 0.8794 time: 0.0120s\nRanking optimizing... \nNow Average ERR@k =  0.7667407989501953\nEpoch: 0095 loss_train: 0.5378 acc_train: 0.8766 loss_val: 0.5452 acc_val: 0.8805 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7678660750389099\nEpoch: 0096 loss_train: 0.5364 acc_train: 0.8865 loss_val: 0.5378 acc_val: 0.8822 time: 0.0124s\nRanking optimizing... \nNow Average ERR@k =  0.7701991200447083\nEpoch: 0097 loss_train: 0.5272 acc_train: 0.8865 loss_val: 0.5307 acc_val: 0.8822 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.768940806388855\nEpoch: 0098 loss_train: 0.5233 acc_train: 0.8821 loss_val: 0.5241 acc_val: 0.8833 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7668461203575134\nEpoch: 0099 loss_train: 0.5050 acc_train: 0.8843 loss_val: 0.5182 acc_val: 0.8854 time: 0.0116s\nRanking optimizing... \nNow Average ERR@k =  0.7690285444259644\nEpoch: 0100 loss_train: 0.5026 acc_train: 0.8886 loss_val: 0.5125 acc_val: 0.8849 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7676876783370972\nEpoch: 0101 loss_train: 0.4945 acc_train: 0.8897 loss_val: 0.5073 acc_val: 0.8865 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.7686195969581604\nEpoch: 0102 loss_train: 0.4791 acc_train: 0.8974 loss_val: 0.5021 acc_val: 0.8893 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7677466869354248\nEpoch: 0103 loss_train: 0.4962 acc_train: 0.8821 loss_val: 0.4970 acc_val: 0.8887 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7670353651046753\nEpoch: 0104 loss_train: 0.4829 acc_train: 0.8886 loss_val: 0.4917 acc_val: 0.8898 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7680859565734863\nEpoch: 0105 loss_train: 0.4722 acc_train: 0.8952 loss_val: 0.4866 acc_val: 0.8903 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7694426774978638\nEpoch: 0106 loss_train: 0.4730 acc_train: 0.8919 loss_val: 0.4815 acc_val: 0.8887 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7669251561164856\nEpoch: 0107 loss_train: 0.4568 acc_train: 0.8886 loss_val: 0.4766 acc_val: 0.8893 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7659324407577515\nEpoch: 0108 loss_train: 0.4733 acc_train: 0.8799 loss_val: 0.4716 acc_val: 0.8898 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7709104418754578\nEpoch: 0109 loss_train: 0.4590 acc_train: 0.8854 loss_val: 0.4665 acc_val: 0.8893 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7679941654205322\nEpoch: 0110 loss_train: 0.4394 acc_train: 0.8985 loss_val: 0.4614 acc_val: 0.8898 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7692791223526001\nEpoch: 0111 loss_train: 0.4497 acc_train: 0.8865 loss_val: 0.4564 acc_val: 0.8909 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7669796347618103\nEpoch: 0112 loss_train: 0.4405 acc_train: 0.8919 loss_val: 0.4515 acc_val: 0.8925 time: 0.0116s\nRanking optimizing... \nNow Average ERR@k =  0.7692400217056274\nEpoch: 0113 loss_train: 0.4389 acc_train: 0.9007 loss_val: 0.4466 acc_val: 0.8953 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7682528495788574\nEpoch: 0114 loss_train: 0.4094 acc_train: 0.9072 loss_val: 0.4417 acc_val: 0.8958 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.769855797290802\nEpoch: 0115 loss_train: 0.4193 acc_train: 0.8963 loss_val: 0.4370 acc_val: 0.8980 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7691578269004822\nEpoch: 0116 loss_train: 0.4182 acc_train: 0.8952 loss_val: 0.4325 acc_val: 0.8980 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7676069140434265\nEpoch: 0117 loss_train: 0.4154 acc_train: 0.8985 loss_val: 0.4284 acc_val: 0.9007 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7695016860961914\nEpoch: 0118 loss_train: 0.4043 acc_train: 0.8963 loss_val: 0.4246 acc_val: 0.8991 time: 0.0119s\nRanking optimizing... \nNow Average ERR@k =  0.7681677937507629\nEpoch: 0119 loss_train: 0.4103 acc_train: 0.8996 loss_val: 0.4210 acc_val: 0.9002 time: 0.0122s\nRanking optimizing... \nNow Average ERR@k =  0.767828106880188\nEpoch: 0120 loss_train: 0.4020 acc_train: 0.9061 loss_val: 0.4172 acc_val: 0.9002 time: 0.0093s\nRanking optimizing... \nNow Average ERR@k =  0.7703753113746643\nEpoch: 0121 loss_train: 0.3991 acc_train: 0.9039 loss_val: 0.4134 acc_val: 0.9018 time: 0.0122s\nRanking optimizing... \nNow Average ERR@k =  0.7690273523330688\nEpoch: 0122 loss_train: 0.3948 acc_train: 0.8985 loss_val: 0.4098 acc_val: 0.9029 time: 0.0124s\nRanking optimizing... \nNow Average ERR@k =  0.7696897387504578\nEpoch: 0123 loss_train: 0.3955 acc_train: 0.9017 loss_val: 0.4061 acc_val: 0.9029 time: 0.0138s\nRanking optimizing... \nNow Average ERR@k =  0.7693970203399658\nEpoch: 0124 loss_train: 0.3826 acc_train: 0.9083 loss_val: 0.4026 acc_val: 0.9029 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7683530449867249\nEpoch: 0125 loss_train: 0.3805 acc_train: 0.9039 loss_val: 0.3993 acc_val: 0.9034 time: 0.0132s\nRanking optimizing... \nNow Average ERR@k =  0.7705122828483582\nEpoch: 0126 loss_train: 0.3784 acc_train: 0.8974 loss_val: 0.3958 acc_val: 0.9051 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7687602639198303\nEpoch: 0127 loss_train: 0.3670 acc_train: 0.9050 loss_val: 0.3923 acc_val: 0.9051 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.7709295153617859\nEpoch: 0128 loss_train: 0.3723 acc_train: 0.9050 loss_val: 0.3889 acc_val: 0.9067 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7719058394432068\nEpoch: 0129 loss_train: 0.3671 acc_train: 0.9105 loss_val: 0.3855 acc_val: 0.9073 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.7691327333450317\nEpoch: 0130 loss_train: 0.3561 acc_train: 0.9148 loss_val: 0.3823 acc_val: 0.9083 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7681190967559814\nEpoch: 0131 loss_train: 0.3608 acc_train: 0.9159 loss_val: 0.3793 acc_val: 0.9094 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7700206637382507\nEpoch: 0132 loss_train: 0.3540 acc_train: 0.9159 loss_val: 0.3762 acc_val: 0.9100 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7703371644020081\nEpoch: 0133 loss_train: 0.3600 acc_train: 0.9105 loss_val: 0.3733 acc_val: 0.9105 time: 0.0116s\nRanking optimizing... \nNow Average ERR@k =  0.7688537240028381\nEpoch: 0134 loss_train: 0.3373 acc_train: 0.9279 loss_val: 0.3704 acc_val: 0.9111 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7713744640350342\nEpoch: 0135 loss_train: 0.3497 acc_train: 0.9203 loss_val: 0.3678 acc_val: 0.9116 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7722193002700806\nEpoch: 0136 loss_train: 0.3271 acc_train: 0.9334 loss_val: 0.3653 acc_val: 0.9111 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7702854871749878\nEpoch: 0137 loss_train: 0.3387 acc_train: 0.9214 loss_val: 0.3630 acc_val: 0.9111 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7697039246559143\nEpoch: 0138 loss_train: 0.3319 acc_train: 0.9258 loss_val: 0.3609 acc_val: 0.9100 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7731587290763855\nEpoch: 0139 loss_train: 0.3274 acc_train: 0.9323 loss_val: 0.3590 acc_val: 0.9111 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7733896970748901\nEpoch: 0140 loss_train: 0.3247 acc_train: 0.9247 loss_val: 0.3574 acc_val: 0.9116 time: 0.0121s\nRanking optimizing... \nNow Average ERR@k =  0.7710059285163879\nEpoch: 0141 loss_train: 0.3275 acc_train: 0.9236 loss_val: 0.3555 acc_val: 0.9127 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7723574638366699\nEpoch: 0142 loss_train: 0.3239 acc_train: 0.9203 loss_val: 0.3533 acc_val: 0.9138 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7721567749977112\nEpoch: 0143 loss_train: 0.3114 acc_train: 0.9247 loss_val: 0.3511 acc_val: 0.9133 time: 0.0131s\nRanking optimizing... \nNow Average ERR@k =  0.7731989026069641\nEpoch: 0144 loss_train: 0.3182 acc_train: 0.9301 loss_val: 0.3492 acc_val: 0.9122 time: 0.0117s\nRanking optimizing... \nNow Average ERR@k =  0.7733769416809082\nEpoch: 0145 loss_train: 0.3178 acc_train: 0.9181 loss_val: 0.3467 acc_val: 0.9122 time: 0.0121s\nRanking optimizing... \nNow Average ERR@k =  0.7734891772270203\nEpoch: 0146 loss_train: 0.3104 acc_train: 0.9290 loss_val: 0.3443 acc_val: 0.9138 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7711734771728516\nEpoch: 0147 loss_train: 0.3133 acc_train: 0.9127 loss_val: 0.3420 acc_val: 0.9154 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.7712646722793579\nEpoch: 0148 loss_train: 0.3111 acc_train: 0.9148 loss_val: 0.3399 acc_val: 0.9165 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7724647521972656\nEpoch: 0149 loss_train: 0.3074 acc_train: 0.9225 loss_val: 0.3372 acc_val: 0.9171 time: 0.0141s\nRanking optimizing... \nNow Average ERR@k =  0.7725728750228882\nEpoch: 0150 loss_train: 0.3047 acc_train: 0.9345 loss_val: 0.3348 acc_val: 0.9171 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7735745310783386\nEpoch: 0151 loss_train: 0.3198 acc_train: 0.9225 loss_val: 0.3326 acc_val: 0.9165 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7703514099121094\nEpoch: 0152 loss_train: 0.3034 acc_train: 0.9312 loss_val: 0.3302 acc_val: 0.9171 time: 0.0117s\nRanking optimizing... \nNow Average ERR@k =  0.7729308605194092\nEpoch: 0153 loss_train: 0.2873 acc_train: 0.9334 loss_val: 0.3282 acc_val: 0.9187 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7704074382781982\nEpoch: 0154 loss_train: 0.3002 acc_train: 0.9312 loss_val: 0.3264 acc_val: 0.9187 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7740364074707031\nEpoch: 0155 loss_train: 0.2903 acc_train: 0.9312 loss_val: 0.3247 acc_val: 0.9193 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7709836959838867\nEpoch: 0156 loss_train: 0.2936 acc_train: 0.9279 loss_val: 0.3232 acc_val: 0.9171 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7728089690208435\nEpoch: 0157 loss_train: 0.2956 acc_train: 0.9356 loss_val: 0.3221 acc_val: 0.9176 time: 0.0117s\nRanking optimizing... \nNow Average ERR@k =  0.7719917297363281\nEpoch: 0158 loss_train: 0.2842 acc_train: 0.9410 loss_val: 0.3217 acc_val: 0.9176 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.7730243802070618\nEpoch: 0159 loss_train: 0.2744 acc_train: 0.9410 loss_val: 0.3215 acc_val: 0.9176 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7730960249900818\nEpoch: 0160 loss_train: 0.2910 acc_train: 0.9323 loss_val: 0.3216 acc_val: 0.9176 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7719947695732117\nEpoch: 0161 loss_train: 0.2981 acc_train: 0.9247 loss_val: 0.3218 acc_val: 0.9171 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7741090059280396\nEpoch: 0162 loss_train: 0.2776 acc_train: 0.9367 loss_val: 0.3218 acc_val: 0.9182 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.775355875492096\nEpoch: 0163 loss_train: 0.2839 acc_train: 0.9356 loss_val: 0.3217 acc_val: 0.9182 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7734372615814209\nEpoch: 0164 loss_train: 0.2914 acc_train: 0.9301 loss_val: 0.3207 acc_val: 0.9187 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7741100192070007\nEpoch: 0165 loss_train: 0.2659 acc_train: 0.9465 loss_val: 0.3193 acc_val: 0.9171 time: 0.0118s\nRanking optimizing... \nNow Average ERR@k =  0.7759960889816284\nEpoch: 0166 loss_train: 0.2693 acc_train: 0.9356 loss_val: 0.3177 acc_val: 0.9171 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7717400193214417\nEpoch: 0167 loss_train: 0.2772 acc_train: 0.9258 loss_val: 0.3157 acc_val: 0.9176 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7723302245140076\nEpoch: 0168 loss_train: 0.2814 acc_train: 0.9290 loss_val: 0.3140 acc_val: 0.9182 time: 0.0095s\nRanking optimizing... \nNow Average ERR@k =  0.7762367129325867\nEpoch: 0169 loss_train: 0.2724 acc_train: 0.9345 loss_val: 0.3120 acc_val: 0.9203 time: 0.0129s\nRanking optimizing... \nNow Average ERR@k =  0.7743323445320129\nEpoch: 0170 loss_train: 0.2723 acc_train: 0.9334 loss_val: 0.3099 acc_val: 0.9225 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7751897573471069\nEpoch: 0171 loss_train: 0.2741 acc_train: 0.9367 loss_val: 0.3081 acc_val: 0.9231 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7734643816947937\nEpoch: 0172 loss_train: 0.2714 acc_train: 0.9301 loss_val: 0.3064 acc_val: 0.9225 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7729601860046387\nEpoch: 0173 loss_train: 0.2618 acc_train: 0.9410 loss_val: 0.3051 acc_val: 0.9231 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7741515040397644\nEpoch: 0174 loss_train: 0.2631 acc_train: 0.9356 loss_val: 0.3041 acc_val: 0.9220 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7736375331878662\nEpoch: 0175 loss_train: 0.2616 acc_train: 0.9389 loss_val: 0.3032 acc_val: 0.9225 time: 0.0127s\nRanking optimizing... \nNow Average ERR@k =  0.7731848955154419\nEpoch: 0176 loss_train: 0.2592 acc_train: 0.9410 loss_val: 0.3024 acc_val: 0.9225 time: 0.0119s\nRanking optimizing... \nNow Average ERR@k =  0.7716318368911743\nEpoch: 0177 loss_train: 0.2694 acc_train: 0.9269 loss_val: 0.3018 acc_val: 0.9236 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7722187042236328\nEpoch: 0178 loss_train: 0.2584 acc_train: 0.9421 loss_val: 0.3014 acc_val: 0.9242 time: 0.0127s\nRanking optimizing... \nNow Average ERR@k =  0.7739316821098328\nEpoch: 0179 loss_train: 0.2740 acc_train: 0.9378 loss_val: 0.3012 acc_val: 0.9236 time: 0.0137s\nRanking optimizing... \nNow Average ERR@k =  0.7735617756843567\nEpoch: 0180 loss_train: 0.2543 acc_train: 0.9389 loss_val: 0.3009 acc_val: 0.9236 time: 0.0116s\nRanking optimizing... \nNow Average ERR@k =  0.7737780213356018\nEpoch: 0181 loss_train: 0.2650 acc_train: 0.9389 loss_val: 0.3007 acc_val: 0.9242 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7731928825378418\nEpoch: 0182 loss_train: 0.2574 acc_train: 0.9410 loss_val: 0.3004 acc_val: 0.9253 time: 0.0130s\nRanking optimizing... \nNow Average ERR@k =  0.7757917046546936\nEpoch: 0183 loss_train: 0.2472 acc_train: 0.9432 loss_val: 0.3000 acc_val: 0.9247 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7769598960876465\nEpoch: 0184 loss_train: 0.2496 acc_train: 0.9421 loss_val: 0.2998 acc_val: 0.9247 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7728559374809265\nEpoch: 0185 loss_train: 0.2641 acc_train: 0.9345 loss_val: 0.2994 acc_val: 0.9231 time: 0.0131s\nRanking optimizing... \nNow Average ERR@k =  0.7766126394271851\nEpoch: 0186 loss_train: 0.2590 acc_train: 0.9367 loss_val: 0.2989 acc_val: 0.9231 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7740833163261414\nEpoch: 0187 loss_train: 0.2554 acc_train: 0.9356 loss_val: 0.2980 acc_val: 0.9242 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7745401859283447\nEpoch: 0188 loss_train: 0.2663 acc_train: 0.9356 loss_val: 0.2968 acc_val: 0.9242 time: 0.0136s\nRanking optimizing... \nNow Average ERR@k =  0.7769348621368408\nEpoch: 0189 loss_train: 0.2713 acc_train: 0.9356 loss_val: 0.2955 acc_val: 0.9247 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7756767868995667\nEpoch: 0190 loss_train: 0.2426 acc_train: 0.9443 loss_val: 0.2943 acc_val: 0.9269 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7744417190551758\nEpoch: 0191 loss_train: 0.2465 acc_train: 0.9410 loss_val: 0.2935 acc_val: 0.9269 time: 0.0133s\nRanking optimizing... \nNow Average ERR@k =  0.7750440239906311\nEpoch: 0192 loss_train: 0.2556 acc_train: 0.9290 loss_val: 0.2928 acc_val: 0.9264 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7724694609642029\nEpoch: 0193 loss_train: 0.2470 acc_train: 0.9432 loss_val: 0.2923 acc_val: 0.9274 time: 0.0138s\nRanking optimizing... \nNow Average ERR@k =  0.7764135599136353\nEpoch: 0194 loss_train: 0.2429 acc_train: 0.9487 loss_val: 0.2920 acc_val: 0.9274 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7785518169403076\nEpoch: 0195 loss_train: 0.2438 acc_train: 0.9454 loss_val: 0.2916 acc_val: 0.9269 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7758376002311707\nEpoch: 0196 loss_train: 0.2529 acc_train: 0.9421 loss_val: 0.2911 acc_val: 0.9280 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.7753846645355225\nEpoch: 0197 loss_train: 0.2482 acc_train: 0.9465 loss_val: 0.2906 acc_val: 0.9280 time: 0.0124s\nRanking optimizing... \nNow Average ERR@k =  0.7741219401359558\nEpoch: 0198 loss_train: 0.2417 acc_train: 0.9432 loss_val: 0.2900 acc_val: 0.9291 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.775338888168335\nEpoch: 0199 loss_train: 0.2513 acc_train: 0.9410 loss_val: 0.2895 acc_val: 0.9280 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7751494646072388\nEpoch: 0200 loss_train: 0.2441 acc_train: 0.9410 loss_val: 0.2891 acc_val: 0.9285 time: 0.0173s\nRanking optimizing... \nNow Average ERR@k =  0.7743061780929565\nEpoch: 0201 loss_train: 0.2370 acc_train: 0.9487 loss_val: 0.2888 acc_val: 0.9285 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7748239636421204\nEpoch: 0202 loss_train: 0.2410 acc_train: 0.9400 loss_val: 0.2885 acc_val: 0.9285 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7760972380638123\nEpoch: 0203 loss_train: 0.2343 acc_train: 0.9410 loss_val: 0.2882 acc_val: 0.9285 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7777587175369263\nEpoch: 0204 loss_train: 0.2348 acc_train: 0.9421 loss_val: 0.2882 acc_val: 0.9285 time: 0.0094s\nRanking optimizing... \nNow Average ERR@k =  0.7731778025627136\nEpoch: 0205 loss_train: 0.2298 acc_train: 0.9487 loss_val: 0.2883 acc_val: 0.9280 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7741252779960632\nEpoch: 0206 loss_train: 0.2398 acc_train: 0.9367 loss_val: 0.2882 acc_val: 0.9274 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.775204598903656\nEpoch: 0207 loss_train: 0.2299 acc_train: 0.9465 loss_val: 0.2882 acc_val: 0.9280 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7761523723602295\nEpoch: 0208 loss_train: 0.2376 acc_train: 0.9465 loss_val: 0.2882 acc_val: 0.9280 time: 0.0121s\nRanking optimizing... \nNow Average ERR@k =  0.7752866744995117\nEpoch: 0209 loss_train: 0.2380 acc_train: 0.9487 loss_val: 0.2882 acc_val: 0.9264 time: 0.0158s\nRanking optimizing... \nNow Average ERR@k =  0.7815139293670654\nEpoch: 0210 loss_train: 0.2349 acc_train: 0.9432 loss_val: 0.2884 acc_val: 0.9264 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7763446569442749\nEpoch: 0211 loss_train: 0.2254 acc_train: 0.9541 loss_val: 0.2885 acc_val: 0.9264 time: 0.0104s\nRanking optimizing... \nNow Average ERR@k =  0.7782570123672485\nEpoch: 0212 loss_train: 0.2337 acc_train: 0.9487 loss_val: 0.2885 acc_val: 0.9269 time: 0.0124s\nRanking optimizing... \nNow Average ERR@k =  0.7749823331832886\nEpoch: 0213 loss_train: 0.2398 acc_train: 0.9378 loss_val: 0.2880 acc_val: 0.9274 time: 0.0131s\nRanking optimizing... \nNow Average ERR@k =  0.77556312084198\nEpoch: 0214 loss_train: 0.2404 acc_train: 0.9432 loss_val: 0.2874 acc_val: 0.9274 time: 0.0130s\nRanking optimizing... \nNow Average ERR@k =  0.7766073346138\nEpoch: 0215 loss_train: 0.2255 acc_train: 0.9520 loss_val: 0.2870 acc_val: 0.9269 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.775976300239563\nEpoch: 0216 loss_train: 0.2377 acc_train: 0.9389 loss_val: 0.2870 acc_val: 0.9285 time: 0.0093s\nRanking optimizing... \nNow Average ERR@k =  0.7765641212463379\nEpoch: 0217 loss_train: 0.2348 acc_train: 0.9443 loss_val: 0.2869 acc_val: 0.9274 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7799510359764099\nEpoch: 0218 loss_train: 0.2243 acc_train: 0.9465 loss_val: 0.2869 acc_val: 0.9274 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7754193544387817\nEpoch: 0219 loss_train: 0.2357 acc_train: 0.9421 loss_val: 0.2868 acc_val: 0.9280 time: 0.0116s\nRanking optimizing... \nNow Average ERR@k =  0.7771880626678467\nEpoch: 0220 loss_train: 0.2344 acc_train: 0.9421 loss_val: 0.2865 acc_val: 0.9269 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7786853909492493\nEpoch: 0221 loss_train: 0.2183 acc_train: 0.9476 loss_val: 0.2860 acc_val: 0.9274 time: 0.0118s\nRanking optimizing... \nNow Average ERR@k =  0.7786363363265991\nEpoch: 0222 loss_train: 0.2410 acc_train: 0.9432 loss_val: 0.2854 acc_val: 0.9280 time: 0.0122s\nRanking optimizing... \nNow Average ERR@k =  0.7807896137237549\nEpoch: 0223 loss_train: 0.2303 acc_train: 0.9443 loss_val: 0.2844 acc_val: 0.9285 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7769579291343689\nEpoch: 0224 loss_train: 0.2181 acc_train: 0.9509 loss_val: 0.2829 acc_val: 0.9280 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7769463062286377\nEpoch: 0225 loss_train: 0.2372 acc_train: 0.9520 loss_val: 0.2820 acc_val: 0.9280 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7750769257545471\nEpoch: 0226 loss_train: 0.2213 acc_train: 0.9574 loss_val: 0.2816 acc_val: 0.9264 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.777945876121521\nEpoch: 0227 loss_train: 0.2289 acc_train: 0.9476 loss_val: 0.2816 acc_val: 0.9264 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7781956791877747\nEpoch: 0228 loss_train: 0.2176 acc_train: 0.9552 loss_val: 0.2821 acc_val: 0.9253 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7785087823867798\nEpoch: 0229 loss_train: 0.2278 acc_train: 0.9541 loss_val: 0.2824 acc_val: 0.9247 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7769325375556946\nEpoch: 0230 loss_train: 0.2260 acc_train: 0.9520 loss_val: 0.2829 acc_val: 0.9269 time: 0.0120s\nRanking optimizing... \nNow Average ERR@k =  0.7772119641304016\nEpoch: 0231 loss_train: 0.2271 acc_train: 0.9454 loss_val: 0.2835 acc_val: 0.9280 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7809134721755981\nEpoch: 0232 loss_train: 0.2332 acc_train: 0.9410 loss_val: 0.2842 acc_val: 0.9264 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.776725172996521\nEpoch: 0233 loss_train: 0.2408 acc_train: 0.9400 loss_val: 0.2846 acc_val: 0.9269 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.778368353843689\nEpoch: 0234 loss_train: 0.2413 acc_train: 0.9443 loss_val: 0.2849 acc_val: 0.9258 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7789000868797302\nEpoch: 0235 loss_train: 0.2198 acc_train: 0.9476 loss_val: 0.2849 acc_val: 0.9253 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7776962518692017\nEpoch: 0236 loss_train: 0.2318 acc_train: 0.9410 loss_val: 0.2848 acc_val: 0.9258 time: 0.0119s\nRanking optimizing... \nNow Average ERR@k =  0.7774544358253479\nEpoch: 0237 loss_train: 0.2357 acc_train: 0.9432 loss_val: 0.2842 acc_val: 0.9264 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7784090638160706\nEpoch: 0238 loss_train: 0.2243 acc_train: 0.9531 loss_val: 0.2837 acc_val: 0.9269 time: 0.0123s\nRanking optimizing... \nNow Average ERR@k =  0.7787855267524719\nEpoch: 0239 loss_train: 0.2306 acc_train: 0.9531 loss_val: 0.2830 acc_val: 0.9269 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7756742238998413\nEpoch: 0240 loss_train: 0.2142 acc_train: 0.9574 loss_val: 0.2824 acc_val: 0.9269 time: 0.0134s\nRanking optimizing... \nNow Average ERR@k =  0.7815584540367126\nEpoch: 0241 loss_train: 0.2302 acc_train: 0.9509 loss_val: 0.2821 acc_val: 0.9274 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7795305848121643\nEpoch: 0242 loss_train: 0.2116 acc_train: 0.9541 loss_val: 0.2821 acc_val: 0.9280 time: 0.0136s\nRanking optimizing... \nNow Average ERR@k =  0.779547393321991\nEpoch: 0243 loss_train: 0.2230 acc_train: 0.9454 loss_val: 0.2821 acc_val: 0.9280 time: 0.0117s\nRanking optimizing... \nNow Average ERR@k =  0.7795180678367615\nEpoch: 0244 loss_train: 0.2284 acc_train: 0.9432 loss_val: 0.2821 acc_val: 0.9285 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7797608971595764\nEpoch: 0245 loss_train: 0.2194 acc_train: 0.9531 loss_val: 0.2819 acc_val: 0.9280 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7786250710487366\nEpoch: 0246 loss_train: 0.2255 acc_train: 0.9465 loss_val: 0.2819 acc_val: 0.9274 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7795689702033997\nEpoch: 0247 loss_train: 0.2183 acc_train: 0.9574 loss_val: 0.2813 acc_val: 0.9269 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.780540943145752\nEpoch: 0248 loss_train: 0.2240 acc_train: 0.9454 loss_val: 0.2811 acc_val: 0.9264 time: 0.0118s\nRanking optimizing... \nNow Average ERR@k =  0.7780725955963135\nEpoch: 0249 loss_train: 0.2360 acc_train: 0.9487 loss_val: 0.2809 acc_val: 0.9258 time: 0.0100s\nRanking optimizing... \nNow Average ERR@k =  0.7777179479598999\nEpoch: 0250 loss_train: 0.2167 acc_train: 0.9531 loss_val: 0.2811 acc_val: 0.9274 time: 0.0128s\nRanking optimizing... \nNow Average ERR@k =  0.7783260941505432\nEpoch: 0251 loss_train: 0.2234 acc_train: 0.9541 loss_val: 0.2812 acc_val: 0.9274 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7818771600723267\nEpoch: 0252 loss_train: 0.2177 acc_train: 0.9498 loss_val: 0.2816 acc_val: 0.9269 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.7802179455757141\nEpoch: 0253 loss_train: 0.2165 acc_train: 0.9541 loss_val: 0.2818 acc_val: 0.9264 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7790037989616394\nEpoch: 0254 loss_train: 0.2132 acc_train: 0.9552 loss_val: 0.2815 acc_val: 0.9258 time: 0.0136s\nRanking optimizing... \nNow Average ERR@k =  0.7800803184509277\nEpoch: 0255 loss_train: 0.2177 acc_train: 0.9552 loss_val: 0.2810 acc_val: 0.9258 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.7792848348617554\nEpoch: 0256 loss_train: 0.2127 acc_train: 0.9509 loss_val: 0.2806 acc_val: 0.9258 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7804216146469116\nEpoch: 0257 loss_train: 0.2002 acc_train: 0.9596 loss_val: 0.2802 acc_val: 0.9264 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7795546650886536\nEpoch: 0258 loss_train: 0.2072 acc_train: 0.9487 loss_val: 0.2797 acc_val: 0.9274 time: 0.0101s\nRanking optimizing... \nNow Average ERR@k =  0.7806926965713501\nEpoch: 0259 loss_train: 0.2283 acc_train: 0.9454 loss_val: 0.2790 acc_val: 0.9274 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.780616044998169\nEpoch: 0260 loss_train: 0.2070 acc_train: 0.9552 loss_val: 0.2786 acc_val: 0.9274 time: 0.0099s\nRanking optimizing... \nNow Average ERR@k =  0.7807138562202454\nEpoch: 0261 loss_train: 0.2293 acc_train: 0.9421 loss_val: 0.2784 acc_val: 0.9280 time: 0.0099s\nRanking optimizing... \nNow Average ERR@k =  0.7792907357215881\nEpoch: 0262 loss_train: 0.2207 acc_train: 0.9454 loss_val: 0.2786 acc_val: 0.9280 time: 0.0099s\nRanking optimizing... \nNow Average ERR@k =  0.7810152173042297\nEpoch: 0263 loss_train: 0.2170 acc_train: 0.9552 loss_val: 0.2792 acc_val: 0.9285 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7797446846961975\nEpoch: 0264 loss_train: 0.2128 acc_train: 0.9552 loss_val: 0.2799 acc_val: 0.9285 time: 0.0123s\nRanking optimizing... \nNow Average ERR@k =  0.7814592719078064\nEpoch: 0265 loss_train: 0.2145 acc_train: 0.9487 loss_val: 0.2811 acc_val: 0.9274 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7823167443275452\nEpoch: 0266 loss_train: 0.2092 acc_train: 0.9487 loss_val: 0.2820 acc_val: 0.9269 time: 0.0121s\nRanking optimizing... \nNow Average ERR@k =  0.7791454792022705\nEpoch: 0267 loss_train: 0.2127 acc_train: 0.9552 loss_val: 0.2835 acc_val: 0.9264 time: 0.0101s\nRanking optimizing... \nNow Average ERR@k =  0.778925895690918\nEpoch: 0268 loss_train: 0.2125 acc_train: 0.9520 loss_val: 0.2850 acc_val: 0.9264 time: 0.0114s\nRanking optimizing... \nNow Average ERR@k =  0.7799449563026428\nEpoch: 0269 loss_train: 0.2088 acc_train: 0.9563 loss_val: 0.2859 acc_val: 0.9253 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7812312841415405\nEpoch: 0270 loss_train: 0.2089 acc_train: 0.9585 loss_val: 0.2864 acc_val: 0.9242 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7821977138519287\nEpoch: 0271 loss_train: 0.2230 acc_train: 0.9520 loss_val: 0.2858 acc_val: 0.9247 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.781308650970459\nEpoch: 0272 loss_train: 0.2232 acc_train: 0.9498 loss_val: 0.2846 acc_val: 0.9264 time: 0.0099s\nRanking optimizing... \nNow Average ERR@k =  0.7815341949462891\nEpoch: 0273 loss_train: 0.2072 acc_train: 0.9531 loss_val: 0.2834 acc_val: 0.9264 time: 0.0098s\nRanking optimizing... \nNow Average ERR@k =  0.780510663986206\nEpoch: 0274 loss_train: 0.2192 acc_train: 0.9421 loss_val: 0.2821 acc_val: 0.9253 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.7788851261138916\nEpoch: 0275 loss_train: 0.2129 acc_train: 0.9563 loss_val: 0.2816 acc_val: 0.9258 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7825775742530823\nEpoch: 0276 loss_train: 0.2120 acc_train: 0.9509 loss_val: 0.2808 acc_val: 0.9264 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.7801755666732788\nEpoch: 0277 loss_train: 0.2348 acc_train: 0.9410 loss_val: 0.2806 acc_val: 0.9280 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.7838343381881714\nEpoch: 0278 loss_train: 0.2086 acc_train: 0.9552 loss_val: 0.2801 acc_val: 0.9274 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.7814421057701111\nEpoch: 0279 loss_train: 0.2105 acc_train: 0.9607 loss_val: 0.2797 acc_val: 0.9274 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.7836937308311462\nEpoch: 0280 loss_train: 0.2085 acc_train: 0.9541 loss_val: 0.2793 acc_val: 0.9274 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.781944990158081\nEpoch: 0281 loss_train: 0.2100 acc_train: 0.9509 loss_val: 0.2795 acc_val: 0.9274 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7810606956481934\nEpoch: 0282 loss_train: 0.2099 acc_train: 0.9552 loss_val: 0.2797 acc_val: 0.9274 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.7835274934768677\nEpoch: 0283 loss_train: 0.2129 acc_train: 0.9541 loss_val: 0.2798 acc_val: 0.9269 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.7811638116836548\nEpoch: 0284 loss_train: 0.2198 acc_train: 0.9585 loss_val: 0.2804 acc_val: 0.9274 time: 0.0125s\nRanking optimizing... \nNow Average ERR@k =  0.7805894613265991\nEpoch: 0285 loss_train: 0.2185 acc_train: 0.9585 loss_val: 0.2811 acc_val: 0.9269 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7799370288848877\nEpoch: 0286 loss_train: 0.2156 acc_train: 0.9509 loss_val: 0.2817 acc_val: 0.9264 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7804429531097412\nEpoch: 0287 loss_train: 0.2035 acc_train: 0.9596 loss_val: 0.2824 acc_val: 0.9264 time: 0.0124s\nRanking optimizing... \nNow Average ERR@k =  0.7776755690574646\nEpoch: 0288 loss_train: 0.2099 acc_train: 0.9454 loss_val: 0.2831 acc_val: 0.9269 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.7831977605819702\nEpoch: 0289 loss_train: 0.2180 acc_train: 0.9552 loss_val: 0.2835 acc_val: 0.9269 time: 0.0124s\nRanking optimizing... \nNow Average ERR@k =  0.781685471534729\nEpoch: 0290 loss_train: 0.2217 acc_train: 0.9465 loss_val: 0.2835 acc_val: 0.9269 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.7842676043510437\nEpoch: 0291 loss_train: 0.2325 acc_train: 0.9410 loss_val: 0.2831 acc_val: 0.9258 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.7832055687904358\nEpoch: 0292 loss_train: 0.2300 acc_train: 0.9465 loss_val: 0.2825 acc_val: 0.9258 time: 0.0130s\nRanking optimizing... \nNow Average ERR@k =  0.7821391820907593\nEpoch: 0293 loss_train: 0.2063 acc_train: 0.9585 loss_val: 0.2814 acc_val: 0.9264 time: 0.0105s\nRanking optimizing... \nNow Average ERR@k =  0.7822081446647644\nEpoch: 0294 loss_train: 0.2095 acc_train: 0.9552 loss_val: 0.2806 acc_val: 0.9264 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.7816793918609619\nEpoch: 0295 loss_train: 0.2200 acc_train: 0.9476 loss_val: 0.2801 acc_val: 0.9274 time: 0.0104s\nRanking optimizing... \nNow Average ERR@k =  0.7830418944358826\nEpoch: 0296 loss_train: 0.2116 acc_train: 0.9541 loss_val: 0.2799 acc_val: 0.9274 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.7804338335990906\nEpoch: 0297 loss_train: 0.2130 acc_train: 0.9498 loss_val: 0.2801 acc_val: 0.9280 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.7834340929985046\nEpoch: 0298 loss_train: 0.2101 acc_train: 0.9651 loss_val: 0.2800 acc_val: 0.9274 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.7823587656021118\nEpoch: 0299 loss_train: 0.2132 acc_train: 0.9563 loss_val: 0.2802 acc_val: 0.9264 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.783501148223877\nEpoch: 0300 loss_train: 0.2113 acc_train: 0.9574 loss_val: 0.2800 acc_val: 0.9258 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.785132110118866\nTest set results: loss= 0.2956 accuracy= 0.9159\n"], ["node classification", "feature", "ERR", "coauthor-phy", "SGC", "Command 'cd node\\ classification; time python REDRESS_feature_ERR.py --dataset coauthor-phy --model SGC' returned non-zero exit status 1."], ["node classification", "feature", "ERR", "coauthor-phy", "GCN", "Command 'cd node\\ classification; time python REDRESS_feature_ERR.py --dataset coauthor-phy --model GCN' returned non-zero exit status 1."], ["node classification", "structural", "NDCG", "ACM", "SGC", "ACM\nUsing ACM dataset\nEpoch: 0001 loss_train: 2.2077 acc_train: 0.0680 loss_val: 2.1825 acc_val: 0.1839 time: 0.5948s\nEpoch: 0002 loss_train: 2.1809 acc_train: 0.1942 loss_val: 2.1628 acc_val: 0.2973 time: 0.0024s\nEpoch: 0003 loss_train: 2.1544 acc_train: 0.3265 loss_val: 2.1434 acc_val: 0.3695 time: 0.0020s\nEpoch: 0004 loss_train: 2.1282 acc_train: 0.4296 loss_val: 2.1241 acc_val: 0.4266 time: 0.0021s\nEpoch: 0005 loss_train: 2.1022 acc_train: 0.5206 loss_val: 2.1051 acc_val: 0.4648 time: 0.0022s\nEpoch: 0006 loss_train: 2.0766 acc_train: 0.5704 loss_val: 2.0863 acc_val: 0.4945 time: 0.0021s\nEpoch: 0007 loss_train: 2.0514 acc_train: 0.6080 loss_val: 2.0678 acc_val: 0.5176 time: 0.0022s\nEpoch: 0008 loss_train: 2.0264 acc_train: 0.6359 loss_val: 2.0495 acc_val: 0.5303 time: 0.0021s\nEpoch: 0009 loss_train: 2.0017 acc_train: 0.6663 loss_val: 2.0315 acc_val: 0.5455 time: 0.0021s\nEpoch: 0010 loss_train: 1.9774 acc_train: 0.6833 loss_val: 2.0137 acc_val: 0.5583 time: 0.0020s\nEpoch: 0011 loss_train: 1.9535 acc_train: 0.6942 loss_val: 1.9962 acc_val: 0.5637 time: 0.0020s\nEpoch: 0012 loss_train: 1.9298 acc_train: 0.7039 loss_val: 1.9789 acc_val: 0.5746 time: 0.0021s\nEpoch: 0013 loss_train: 1.9066 acc_train: 0.7160 loss_val: 1.9619 acc_val: 0.5813 time: 0.0020s\nEpoch: 0014 loss_train: 1.8836 acc_train: 0.7184 loss_val: 1.9451 acc_val: 0.5886 time: 0.0019s\nEpoch: 0015 loss_train: 1.8610 acc_train: 0.7269 loss_val: 1.9285 acc_val: 0.5928 time: 0.0019s\nEpoch: 0016 loss_train: 1.8388 acc_train: 0.7269 loss_val: 1.9123 acc_val: 0.5959 time: 0.0019s\nEpoch: 0017 loss_train: 1.8169 acc_train: 0.7282 loss_val: 1.8962 acc_val: 0.5995 time: 0.0019s\nEpoch: 0018 loss_train: 1.7954 acc_train: 0.7282 loss_val: 1.8805 acc_val: 0.6032 time: 0.0019s\nEpoch: 0019 loss_train: 1.7742 acc_train: 0.7354 loss_val: 1.8649 acc_val: 0.6062 time: 0.0019s\nEpoch: 0020 loss_train: 1.7533 acc_train: 0.7354 loss_val: 1.8497 acc_val: 0.6123 time: 0.0018s\nEpoch: 0021 loss_train: 1.7328 acc_train: 0.7403 loss_val: 1.8347 acc_val: 0.6135 time: 0.0019s\nEpoch: 0022 loss_train: 1.7127 acc_train: 0.7391 loss_val: 1.8199 acc_val: 0.6135 time: 0.0019s\nEpoch: 0023 loss_train: 1.6929 acc_train: 0.7427 loss_val: 1.8054 acc_val: 0.6147 time: 0.0019s\nEpoch: 0024 loss_train: 1.6734 acc_train: 0.7439 loss_val: 1.7912 acc_val: 0.6147 time: 0.0018s\nEpoch: 0025 loss_train: 1.6543 acc_train: 0.7439 loss_val: 1.7772 acc_val: 0.6177 time: 0.0019s\nEpoch: 0026 loss_train: 1.6355 acc_train: 0.7439 loss_val: 1.7635 acc_val: 0.6226 time: 0.0018s\nEpoch: 0027 loss_train: 1.6171 acc_train: 0.7427 loss_val: 1.7500 acc_val: 0.6256 time: 0.0018s\nEpoch: 0028 loss_train: 1.5990 acc_train: 0.7476 loss_val: 1.7368 acc_val: 0.6274 time: 0.0018s\nEpoch: 0029 loss_train: 1.5812 acc_train: 0.7476 loss_val: 1.7238 acc_val: 0.6299 time: 0.0019s\nEpoch: 0030 loss_train: 1.5637 acc_train: 0.7500 loss_val: 1.7111 acc_val: 0.6305 time: 0.0018s\nEpoch: 0031 loss_train: 1.5466 acc_train: 0.7512 loss_val: 1.6986 acc_val: 0.6299 time: 0.0018s\nEpoch: 0032 loss_train: 1.5298 acc_train: 0.7524 loss_val: 1.6864 acc_val: 0.6292 time: 0.0018s\nEpoch: 0033 loss_train: 1.5133 acc_train: 0.7561 loss_val: 1.6745 acc_val: 0.6280 time: 0.0018s\nEpoch: 0034 loss_train: 1.4971 acc_train: 0.7573 loss_val: 1.6627 acc_val: 0.6305 time: 0.0018s\nEpoch: 0035 loss_train: 1.4811 acc_train: 0.7621 loss_val: 1.6512 acc_val: 0.6292 time: 0.0018s\nEpoch: 0036 loss_train: 1.4655 acc_train: 0.7658 loss_val: 1.6400 acc_val: 0.6311 time: 0.0019s\nEpoch: 0037 loss_train: 1.4502 acc_train: 0.7646 loss_val: 1.6290 acc_val: 0.6341 time: 0.0018s\nEpoch: 0038 loss_train: 1.4352 acc_train: 0.7658 loss_val: 1.6182 acc_val: 0.6341 time: 0.0019s\nEpoch: 0039 loss_train: 1.4204 acc_train: 0.7670 loss_val: 1.6076 acc_val: 0.6347 time: 0.0018s\nEpoch: 0040 loss_train: 1.4059 acc_train: 0.7694 loss_val: 1.5973 acc_val: 0.6371 time: 0.0019s\nEpoch: 0041 loss_train: 1.3917 acc_train: 0.7718 loss_val: 1.5871 acc_val: 0.6359 time: 0.0019s\nEpoch: 0042 loss_train: 1.3777 acc_train: 0.7706 loss_val: 1.5772 acc_val: 0.6371 time: 0.0019s\nEpoch: 0043 loss_train: 1.3640 acc_train: 0.7718 loss_val: 1.5675 acc_val: 0.6383 time: 0.0019s\nEpoch: 0044 loss_train: 1.3505 acc_train: 0.7731 loss_val: 1.5580 acc_val: 0.6383 time: 0.0044s\nEpoch: 0045 loss_train: 1.3373 acc_train: 0.7779 loss_val: 1.5487 acc_val: 0.6383 time: 0.0036s\nEpoch: 0046 loss_train: 1.3243 acc_train: 0.7779 loss_val: 1.5396 acc_val: 0.6402 time: 0.0035s\nEpoch: 0047 loss_train: 1.3116 acc_train: 0.7779 loss_val: 1.5307 acc_val: 0.6420 time: 0.0033s\nEpoch: 0048 loss_train: 1.2991 acc_train: 0.7779 loss_val: 1.5220 acc_val: 0.6438 time: 0.0030s\nEpoch: 0049 loss_train: 1.2868 acc_train: 0.7816 loss_val: 1.5134 acc_val: 0.6444 time: 0.0030s\nEpoch: 0050 loss_train: 1.2747 acc_train: 0.7828 loss_val: 1.5051 acc_val: 0.6438 time: 0.0030s\nEpoch: 0051 loss_train: 1.2628 acc_train: 0.7852 loss_val: 1.4969 acc_val: 0.6450 time: 0.0026s\nEpoch: 0052 loss_train: 1.2512 acc_train: 0.7852 loss_val: 1.4888 acc_val: 0.6462 time: 0.0027s\nEpoch: 0053 loss_train: 1.2397 acc_train: 0.7876 loss_val: 1.4810 acc_val: 0.6468 time: 0.0026s\nEpoch: 0054 loss_train: 1.2285 acc_train: 0.7888 loss_val: 1.4733 acc_val: 0.6468 time: 0.0025s\nEpoch: 0055 loss_train: 1.2174 acc_train: 0.7888 loss_val: 1.4657 acc_val: 0.6475 time: 0.0022s\nEpoch: 0056 loss_train: 1.2065 acc_train: 0.7900 loss_val: 1.4583 acc_val: 0.6481 time: 0.0022s\nEpoch: 0057 loss_train: 1.1959 acc_train: 0.7937 loss_val: 1.4510 acc_val: 0.6487 time: 0.0022s\nEpoch: 0058 loss_train: 1.1854 acc_train: 0.7961 loss_val: 1.4439 acc_val: 0.6499 time: 0.0022s\nEpoch: 0059 loss_train: 1.1751 acc_train: 0.7961 loss_val: 1.4370 acc_val: 0.6499 time: 0.0021s\nEpoch: 0060 loss_train: 1.1649 acc_train: 0.7985 loss_val: 1.4301 acc_val: 0.6517 time: 0.0019s\nEpoch: 0061 loss_train: 1.1550 acc_train: 0.7985 loss_val: 1.4234 acc_val: 0.6523 time: 0.0020s\nEpoch: 0062 loss_train: 1.1452 acc_train: 0.7998 loss_val: 1.4168 acc_val: 0.6535 time: 0.0020s\nEpoch: 0063 loss_train: 1.1355 acc_train: 0.7998 loss_val: 1.4104 acc_val: 0.6535 time: 0.0020s\nEpoch: 0064 loss_train: 1.1261 acc_train: 0.7998 loss_val: 1.4041 acc_val: 0.6541 time: 0.0019s\nEpoch: 0065 loss_train: 1.1167 acc_train: 0.8022 loss_val: 1.3978 acc_val: 0.6547 time: 0.0019s\nEpoch: 0066 loss_train: 1.1076 acc_train: 0.8022 loss_val: 1.3917 acc_val: 0.6547 time: 0.0019s\nEpoch: 0067 loss_train: 1.0986 acc_train: 0.8034 loss_val: 1.3858 acc_val: 0.6541 time: 0.0019s\nEpoch: 0068 loss_train: 1.0897 acc_train: 0.8058 loss_val: 1.3799 acc_val: 0.6541 time: 0.0019s\nEpoch: 0069 loss_train: 1.0810 acc_train: 0.8107 loss_val: 1.3741 acc_val: 0.6566 time: 0.0019s\nEpoch: 0070 loss_train: 1.0724 acc_train: 0.8119 loss_val: 1.3685 acc_val: 0.6572 time: 0.0019s\nEpoch: 0071 loss_train: 1.0639 acc_train: 0.8131 loss_val: 1.3630 acc_val: 0.6566 time: 0.0019s\nEpoch: 0072 loss_train: 1.0556 acc_train: 0.8131 loss_val: 1.3575 acc_val: 0.6559 time: 0.0019s\nEpoch: 0073 loss_train: 1.0474 acc_train: 0.8131 loss_val: 1.3522 acc_val: 0.6578 time: 0.0019s\nEpoch: 0074 loss_train: 1.0394 acc_train: 0.8143 loss_val: 1.3469 acc_val: 0.6566 time: 0.0019s\nEpoch: 0075 loss_train: 1.0315 acc_train: 0.8143 loss_val: 1.3418 acc_val: 0.6572 time: 0.0019s\nEpoch: 0076 loss_train: 1.0237 acc_train: 0.8167 loss_val: 1.3368 acc_val: 0.6572 time: 0.0019s\nEpoch: 0077 loss_train: 1.0160 acc_train: 0.8167 loss_val: 1.3318 acc_val: 0.6578 time: 0.0019s\nEpoch: 0078 loss_train: 1.0084 acc_train: 0.8167 loss_val: 1.3270 acc_val: 0.6584 time: 0.0019s\nEpoch: 0079 loss_train: 1.0010 acc_train: 0.8180 loss_val: 1.3222 acc_val: 0.6608 time: 0.0019s\nEpoch: 0080 loss_train: 0.9937 acc_train: 0.8192 loss_val: 1.3175 acc_val: 0.6602 time: 0.0019s\nEpoch: 0081 loss_train: 0.9864 acc_train: 0.8180 loss_val: 1.3129 acc_val: 0.6608 time: 0.0019s\nEpoch: 0082 loss_train: 0.9793 acc_train: 0.8204 loss_val: 1.3084 acc_val: 0.6608 time: 0.0019s\nEpoch: 0083 loss_train: 0.9723 acc_train: 0.8216 loss_val: 1.3040 acc_val: 0.6614 time: 0.0018s\nEpoch: 0084 loss_train: 0.9654 acc_train: 0.8228 loss_val: 1.2997 acc_val: 0.6632 time: 0.0019s\nEpoch: 0085 loss_train: 0.9586 acc_train: 0.8252 loss_val: 1.2955 acc_val: 0.6632 time: 0.0018s\nEpoch: 0086 loss_train: 0.9519 acc_train: 0.8277 loss_val: 1.2913 acc_val: 0.6638 time: 0.0019s\nEpoch: 0087 loss_train: 0.9453 acc_train: 0.8301 loss_val: 1.2872 acc_val: 0.6632 time: 0.0019s\nEpoch: 0088 loss_train: 0.9388 acc_train: 0.8313 loss_val: 1.2832 acc_val: 0.6644 time: 0.0019s\nEpoch: 0089 loss_train: 0.9324 acc_train: 0.8350 loss_val: 1.2792 acc_val: 0.6650 time: 0.0018s\nEpoch: 0090 loss_train: 0.9261 acc_train: 0.8350 loss_val: 1.2754 acc_val: 0.6650 time: 0.0019s\nEpoch: 0091 loss_train: 0.9199 acc_train: 0.8350 loss_val: 1.2716 acc_val: 0.6650 time: 0.0018s\nEpoch: 0092 loss_train: 0.9138 acc_train: 0.8350 loss_val: 1.2678 acc_val: 0.6638 time: 0.0019s\nEpoch: 0093 loss_train: 0.9077 acc_train: 0.8350 loss_val: 1.2642 acc_val: 0.6650 time: 0.0020s\nEpoch: 0094 loss_train: 0.9017 acc_train: 0.8362 loss_val: 1.2606 acc_val: 0.6657 time: 0.0019s\nEpoch: 0095 loss_train: 0.8959 acc_train: 0.8362 loss_val: 1.2571 acc_val: 0.6657 time: 0.0019s\nEpoch: 0096 loss_train: 0.8901 acc_train: 0.8374 loss_val: 1.2536 acc_val: 0.6663 time: 0.0020s\nEpoch: 0097 loss_train: 0.8844 acc_train: 0.8374 loss_val: 1.2502 acc_val: 0.6663 time: 0.0019s\nEpoch: 0098 loss_train: 0.8787 acc_train: 0.8386 loss_val: 1.2469 acc_val: 0.6675 time: 0.0020s\nEpoch: 0099 loss_train: 0.8732 acc_train: 0.8386 loss_val: 1.2436 acc_val: 0.6675 time: 0.0019s\nEpoch: 0100 loss_train: 0.8677 acc_train: 0.8386 loss_val: 1.2404 acc_val: 0.6675 time: 0.0020s\nEpoch: 0101 loss_train: 0.8623 acc_train: 0.8386 loss_val: 1.2372 acc_val: 0.6675 time: 0.0019s\nEpoch: 0102 loss_train: 0.8569 acc_train: 0.8398 loss_val: 1.2341 acc_val: 0.6675 time: 0.0019s\nEpoch: 0103 loss_train: 0.8517 acc_train: 0.8422 loss_val: 1.2311 acc_val: 0.6669 time: 0.0019s\nEpoch: 0104 loss_train: 0.8465 acc_train: 0.8422 loss_val: 1.2281 acc_val: 0.6681 time: 0.0019s\nEpoch: 0105 loss_train: 0.8413 acc_train: 0.8434 loss_val: 1.2252 acc_val: 0.6681 time: 0.0019s\nEpoch: 0106 loss_train: 0.8363 acc_train: 0.8434 loss_val: 1.2223 acc_val: 0.6687 time: 0.0018s\nEpoch: 0107 loss_train: 0.8313 acc_train: 0.8447 loss_val: 1.2195 acc_val: 0.6675 time: 0.0018s\nEpoch: 0108 loss_train: 0.8263 acc_train: 0.8447 loss_val: 1.2167 acc_val: 0.6669 time: 0.0018s\nEpoch: 0109 loss_train: 0.8215 acc_train: 0.8447 loss_val: 1.2139 acc_val: 0.6669 time: 0.0019s\nEpoch: 0110 loss_train: 0.8167 acc_train: 0.8471 loss_val: 1.2113 acc_val: 0.6675 time: 0.0019s\nEpoch: 0111 loss_train: 0.8119 acc_train: 0.8471 loss_val: 1.2086 acc_val: 0.6675 time: 0.0019s\nEpoch: 0112 loss_train: 0.8072 acc_train: 0.8483 loss_val: 1.2060 acc_val: 0.6681 time: 0.0019s\nEpoch: 0113 loss_train: 0.8026 acc_train: 0.8483 loss_val: 1.2035 acc_val: 0.6687 time: 0.0019s\nEpoch: 0114 loss_train: 0.7981 acc_train: 0.8483 loss_val: 1.2010 acc_val: 0.6687 time: 0.0019s\nEpoch: 0115 loss_train: 0.7935 acc_train: 0.8507 loss_val: 1.1986 acc_val: 0.6693 time: 0.0019s\nEpoch: 0116 loss_train: 0.7891 acc_train: 0.8532 loss_val: 1.1962 acc_val: 0.6693 time: 0.0019s\nEpoch: 0117 loss_train: 0.7847 acc_train: 0.8532 loss_val: 1.1938 acc_val: 0.6699 time: 0.0019s\nEpoch: 0118 loss_train: 0.7803 acc_train: 0.8532 loss_val: 1.1915 acc_val: 0.6699 time: 0.0019s\nEpoch: 0119 loss_train: 0.7761 acc_train: 0.8532 loss_val: 1.1892 acc_val: 0.6687 time: 0.0019s\nEpoch: 0120 loss_train: 0.7718 acc_train: 0.8544 loss_val: 1.1870 acc_val: 0.6693 time: 0.0018s\nEpoch: 0121 loss_train: 0.7676 acc_train: 0.8556 loss_val: 1.1848 acc_val: 0.6705 time: 0.0019s\nEpoch: 0122 loss_train: 0.7635 acc_train: 0.8556 loss_val: 1.1826 acc_val: 0.6717 time: 0.0018s\nEpoch: 0123 loss_train: 0.7594 acc_train: 0.8568 loss_val: 1.1805 acc_val: 0.6717 time: 0.0018s\nEpoch: 0124 loss_train: 0.7554 acc_train: 0.8568 loss_val: 1.1784 acc_val: 0.6717 time: 0.0018s\nEpoch: 0125 loss_train: 0.7514 acc_train: 0.8580 loss_val: 1.1764 acc_val: 0.6711 time: 0.0019s\nEpoch: 0126 loss_train: 0.7474 acc_train: 0.8580 loss_val: 1.1743 acc_val: 0.6723 time: 0.0019s\nEpoch: 0127 loss_train: 0.7435 acc_train: 0.8580 loss_val: 1.1724 acc_val: 0.6717 time: 0.0019s\nEpoch: 0128 loss_train: 0.7397 acc_train: 0.8592 loss_val: 1.1704 acc_val: 0.6711 time: 0.0019s\nEpoch: 0129 loss_train: 0.7359 acc_train: 0.8592 loss_val: 1.1685 acc_val: 0.6717 time: 0.0019s\nEpoch: 0130 loss_train: 0.7321 acc_train: 0.8592 loss_val: 1.1667 acc_val: 0.6705 time: 0.0019s\nEpoch: 0131 loss_train: 0.7284 acc_train: 0.8592 loss_val: 1.1648 acc_val: 0.6705 time: 0.0019s\nEpoch: 0132 loss_train: 0.7247 acc_train: 0.8592 loss_val: 1.1630 acc_val: 0.6699 time: 0.0019s\nEpoch: 0133 loss_train: 0.7210 acc_train: 0.8592 loss_val: 1.1613 acc_val: 0.6705 time: 0.0019s\nEpoch: 0134 loss_train: 0.7174 acc_train: 0.8592 loss_val: 1.1595 acc_val: 0.6705 time: 0.0020s\nEpoch: 0135 loss_train: 0.7139 acc_train: 0.8604 loss_val: 1.1578 acc_val: 0.6711 time: 0.0019s\nEpoch: 0136 loss_train: 0.7104 acc_train: 0.8604 loss_val: 1.1561 acc_val: 0.6717 time: 0.0020s\nEpoch: 0137 loss_train: 0.7069 acc_train: 0.8617 loss_val: 1.1545 acc_val: 0.6717 time: 0.0019s\nEpoch: 0138 loss_train: 0.7034 acc_train: 0.8617 loss_val: 1.1529 acc_val: 0.6735 time: 0.0019s\nEpoch: 0139 loss_train: 0.7000 acc_train: 0.8617 loss_val: 1.1513 acc_val: 0.6735 time: 0.0019s\nEpoch: 0140 loss_train: 0.6967 acc_train: 0.8617 loss_val: 1.1497 acc_val: 0.6735 time: 0.0019s\nEpoch: 0141 loss_train: 0.6933 acc_train: 0.8629 loss_val: 1.1482 acc_val: 0.6729 time: 0.0019s\nEpoch: 0142 loss_train: 0.6900 acc_train: 0.8629 loss_val: 1.1467 acc_val: 0.6735 time: 0.0019s\nEpoch: 0143 loss_train: 0.6868 acc_train: 0.8629 loss_val: 1.1452 acc_val: 0.6735 time: 0.0018s\nEpoch: 0144 loss_train: 0.6836 acc_train: 0.8629 loss_val: 1.1437 acc_val: 0.6742 time: 0.0019s\nEpoch: 0145 loss_train: 0.6804 acc_train: 0.8641 loss_val: 1.1423 acc_val: 0.6754 time: 0.0018s\nEpoch: 0146 loss_train: 0.6772 acc_train: 0.8641 loss_val: 1.1409 acc_val: 0.6766 time: 0.0019s\nEpoch: 0147 loss_train: 0.6741 acc_train: 0.8641 loss_val: 1.1395 acc_val: 0.6766 time: 0.0019s\nEpoch: 0148 loss_train: 0.6710 acc_train: 0.8665 loss_val: 1.1382 acc_val: 0.6778 time: 0.0019s\nEpoch: 0149 loss_train: 0.6679 acc_train: 0.8677 loss_val: 1.1369 acc_val: 0.6778 time: 0.0019s\nEpoch: 0150 loss_train: 0.6649 acc_train: 0.8677 loss_val: 1.1356 acc_val: 0.6784 time: 0.0019s\nEpoch: 0151 loss_train: 0.6619 acc_train: 0.8677 loss_val: 1.1343 acc_val: 0.6790 time: 0.0019s\nEpoch: 0152 loss_train: 0.6589 acc_train: 0.8677 loss_val: 1.1330 acc_val: 0.6796 time: 0.0019s\nEpoch: 0153 loss_train: 0.6560 acc_train: 0.8689 loss_val: 1.1318 acc_val: 0.6802 time: 0.0019s\nEpoch: 0154 loss_train: 0.6531 acc_train: 0.8689 loss_val: 1.1306 acc_val: 0.6802 time: 0.0019s\nEpoch: 0155 loss_train: 0.6502 acc_train: 0.8689 loss_val: 1.1294 acc_val: 0.6808 time: 0.0019s\nEpoch: 0156 loss_train: 0.6473 acc_train: 0.8689 loss_val: 1.1282 acc_val: 0.6808 time: 0.0019s\nEpoch: 0157 loss_train: 0.6445 acc_train: 0.8689 loss_val: 1.1271 acc_val: 0.6808 time: 0.0019s\nEpoch: 0158 loss_train: 0.6417 acc_train: 0.8689 loss_val: 1.1260 acc_val: 0.6808 time: 0.0019s\nEpoch: 0159 loss_train: 0.6390 acc_train: 0.8689 loss_val: 1.1249 acc_val: 0.6808 time: 0.0019s\nEpoch: 0160 loss_train: 0.6362 acc_train: 0.8689 loss_val: 1.1238 acc_val: 0.6802 time: 0.0018s\nEpoch: 0161 loss_train: 0.6335 acc_train: 0.8714 loss_val: 1.1227 acc_val: 0.6808 time: 0.0019s\nEpoch: 0162 loss_train: 0.6308 acc_train: 0.8714 loss_val: 1.1217 acc_val: 0.6814 time: 0.0018s\nEpoch: 0163 loss_train: 0.6282 acc_train: 0.8726 loss_val: 1.1206 acc_val: 0.6814 time: 0.0019s\nEpoch: 0164 loss_train: 0.6255 acc_train: 0.8726 loss_val: 1.1196 acc_val: 0.6808 time: 0.0018s\nEpoch: 0165 loss_train: 0.6229 acc_train: 0.8726 loss_val: 1.1186 acc_val: 0.6808 time: 0.0019s\nEpoch: 0166 loss_train: 0.6203 acc_train: 0.8726 loss_val: 1.1177 acc_val: 0.6808 time: 0.0018s\nEpoch: 0167 loss_train: 0.6178 acc_train: 0.8714 loss_val: 1.1167 acc_val: 0.6802 time: 0.0018s\nEpoch: 0168 loss_train: 0.6152 acc_train: 0.8714 loss_val: 1.1158 acc_val: 0.6808 time: 0.0018s\nEpoch: 0169 loss_train: 0.6127 acc_train: 0.8714 loss_val: 1.1149 acc_val: 0.6808 time: 0.0019s\nEpoch: 0170 loss_train: 0.6102 acc_train: 0.8714 loss_val: 1.1140 acc_val: 0.6802 time: 0.0019s\nEpoch: 0171 loss_train: 0.6078 acc_train: 0.8714 loss_val: 1.1131 acc_val: 0.6802 time: 0.0020s\nEpoch: 0172 loss_train: 0.6053 acc_train: 0.8714 loss_val: 1.1122 acc_val: 0.6808 time: 0.0019s\nEpoch: 0173 loss_train: 0.6029 acc_train: 0.8714 loss_val: 1.1114 acc_val: 0.6802 time: 0.0019s\nEpoch: 0174 loss_train: 0.6005 acc_train: 0.8714 loss_val: 1.1105 acc_val: 0.6802 time: 0.0019s\nEpoch: 0175 loss_train: 0.5981 acc_train: 0.8714 loss_val: 1.1097 acc_val: 0.6796 time: 0.0018s\nEpoch: 0176 loss_train: 0.5957 acc_train: 0.8726 loss_val: 1.1089 acc_val: 0.6796 time: 0.0019s\nEpoch: 0177 loss_train: 0.5934 acc_train: 0.8738 loss_val: 1.1081 acc_val: 0.6790 time: 0.0019s\nEpoch: 0178 loss_train: 0.5911 acc_train: 0.8738 loss_val: 1.1073 acc_val: 0.6784 time: 0.0019s\nEpoch: 0179 loss_train: 0.5888 acc_train: 0.8762 loss_val: 1.1066 acc_val: 0.6784 time: 0.0019s\nEpoch: 0180 loss_train: 0.5865 acc_train: 0.8762 loss_val: 1.1058 acc_val: 0.6784 time: 0.0019s\nEpoch: 0181 loss_train: 0.5843 acc_train: 0.8774 loss_val: 1.1051 acc_val: 0.6784 time: 0.0018s\nEpoch: 0182 loss_train: 0.5820 acc_train: 0.8774 loss_val: 1.1044 acc_val: 0.6790 time: 0.0019s\nEpoch: 0183 loss_train: 0.5798 acc_train: 0.8774 loss_val: 1.1037 acc_val: 0.6790 time: 0.0018s\nEpoch: 0184 loss_train: 0.5776 acc_train: 0.8774 loss_val: 1.1030 acc_val: 0.6790 time: 0.0019s\nEpoch: 0185 loss_train: 0.5754 acc_train: 0.8786 loss_val: 1.1023 acc_val: 0.6796 time: 0.0019s\nEpoch: 0186 loss_train: 0.5733 acc_train: 0.8799 loss_val: 1.1017 acc_val: 0.6796 time: 0.0020s\nEpoch: 0187 loss_train: 0.5711 acc_train: 0.8811 loss_val: 1.1010 acc_val: 0.6796 time: 0.0019s\nEpoch: 0188 loss_train: 0.5690 acc_train: 0.8811 loss_val: 1.1004 acc_val: 0.6796 time: 0.0019s\nEpoch: 0189 loss_train: 0.5669 acc_train: 0.8811 loss_val: 1.0998 acc_val: 0.6796 time: 0.0019s\nEpoch: 0190 loss_train: 0.5648 acc_train: 0.8811 loss_val: 1.0992 acc_val: 0.6796 time: 0.0020s\nEpoch: 0191 loss_train: 0.5627 acc_train: 0.8811 loss_val: 1.0986 acc_val: 0.6796 time: 0.0019s\nEpoch: 0192 loss_train: 0.5607 acc_train: 0.8811 loss_val: 1.0980 acc_val: 0.6802 time: 0.0020s\nEpoch: 0193 loss_train: 0.5587 acc_train: 0.8811 loss_val: 1.0974 acc_val: 0.6808 time: 0.0019s\nEpoch: 0194 loss_train: 0.5566 acc_train: 0.8811 loss_val: 1.0969 acc_val: 0.6808 time: 0.0019s\nEpoch: 0195 loss_train: 0.5546 acc_train: 0.8811 loss_val: 1.0963 acc_val: 0.6808 time: 0.0019s\nEpoch: 0196 loss_train: 0.5526 acc_train: 0.8823 loss_val: 1.0958 acc_val: 0.6808 time: 0.0019s\nEpoch: 0197 loss_train: 0.5507 acc_train: 0.8835 loss_val: 1.0953 acc_val: 0.6814 time: 0.0019s\nEpoch: 0198 loss_train: 0.5487 acc_train: 0.8835 loss_val: 1.0947 acc_val: 0.6814 time: 0.0019s\nEpoch: 0199 loss_train: 0.5468 acc_train: 0.8847 loss_val: 1.0942 acc_val: 0.6814 time: 0.0019s\nEpoch: 0200 loss_train: 0.5449 acc_train: 0.8871 loss_val: 1.0937 acc_val: 0.6814 time: 0.0019s\nEpoch: 0001 loss_train: 0.5430 acc_train: 0.8871 loss_val: 1.0937 acc_val: 0.6814 time: 0.0015s\nRanking optimizing... \nNow Average NDCG@k =  0.3798716366291046\nEpoch: 0002 loss_train: 0.5411 acc_train: 0.8871 loss_val: 1.0933 acc_val: 0.6814 time: 0.0043s\nRanking optimizing... \nNow Average NDCG@k =  0.3799534738063812\nEpoch: 0003 loss_train: 0.5392 acc_train: 0.8871 loss_val: 1.0929 acc_val: 0.6820 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.3800012767314911\nEpoch: 0004 loss_train: 0.5373 acc_train: 0.8871 loss_val: 1.0924 acc_val: 0.6820 time: 0.0034s\nRanking optimizing... \nNow Average NDCG@k =  0.3798603117465973\nEpoch: 0005 loss_train: 0.5355 acc_train: 0.8883 loss_val: 1.0921 acc_val: 0.6833 time: 0.0041s\nRanking optimizing... \nNow Average NDCG@k =  0.3798736333847046\nEpoch: 0006 loss_train: 0.5337 acc_train: 0.8883 loss_val: 1.0917 acc_val: 0.6826 time: 0.0034s\nRanking optimizing... \nNow Average NDCG@k =  0.37993186712265015\nEpoch: 0007 loss_train: 0.5319 acc_train: 0.8896 loss_val: 1.0914 acc_val: 0.6820 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.3802066147327423\nEpoch: 0008 loss_train: 0.5301 acc_train: 0.8896 loss_val: 1.0911 acc_val: 0.6814 time: 0.0032s\nRanking optimizing... \nNow Average NDCG@k =  0.38061845302581787\nEpoch: 0009 loss_train: 0.5284 acc_train: 0.8896 loss_val: 1.0908 acc_val: 0.6814 time: 0.0032s\nRanking optimizing... \nNow Average NDCG@k =  0.38095083832740784\nEpoch: 0010 loss_train: 0.5267 acc_train: 0.8920 loss_val: 1.0906 acc_val: 0.6814 time: 0.0032s\nRanking optimizing... \nNow Average NDCG@k =  0.3813154697418213\nEpoch: 0011 loss_train: 0.5250 acc_train: 0.8932 loss_val: 1.0904 acc_val: 0.6814 time: 0.0028s\nRanking optimizing... \nNow Average NDCG@k =  0.38171008229255676\nEpoch: 0012 loss_train: 0.5233 acc_train: 0.8932 loss_val: 1.0903 acc_val: 0.6796 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.3819046914577484\nEpoch: 0013 loss_train: 0.5217 acc_train: 0.8920 loss_val: 1.0902 acc_val: 0.6790 time: 0.0028s\nRanking optimizing... \nNow Average NDCG@k =  0.38202977180480957\nEpoch: 0014 loss_train: 0.5201 acc_train: 0.8920 loss_val: 1.0901 acc_val: 0.6796 time: 0.0030s\nRanking optimizing... \nNow Average NDCG@k =  0.3826867341995239\nEpoch: 0015 loss_train: 0.5184 acc_train: 0.8920 loss_val: 1.0901 acc_val: 0.6802 time: 0.0032s\nRanking optimizing... \nNow Average NDCG@k =  0.3831416666507721\nEpoch: 0016 loss_train: 0.5169 acc_train: 0.8920 loss_val: 1.0901 acc_val: 0.6796 time: 0.0032s\nRanking optimizing... \nNow Average NDCG@k =  0.38333073258399963\nEpoch: 0017 loss_train: 0.5153 acc_train: 0.8932 loss_val: 1.0901 acc_val: 0.6796 time: 0.0029s\nRanking optimizing... \nNow Average NDCG@k =  0.3839068114757538\nEpoch: 0018 loss_train: 0.5137 acc_train: 0.8932 loss_val: 1.0901 acc_val: 0.6796 time: 0.0036s\nRanking optimizing... \nNow Average NDCG@k =  0.38440099358558655\nEpoch: 0019 loss_train: 0.5122 acc_train: 0.8932 loss_val: 1.0902 acc_val: 0.6796 time: 0.0032s\nRanking optimizing... \nNow Average NDCG@k =  0.3846946954727173\nEpoch: 0020 loss_train: 0.5106 acc_train: 0.8944 loss_val: 1.0903 acc_val: 0.6796 time: 0.0028s\nRanking optimizing... \nNow Average NDCG@k =  0.38486582040786743\nEpoch: 0021 loss_train: 0.5091 acc_train: 0.8944 loss_val: 1.0904 acc_val: 0.6802 time: 0.0035s\nRanking optimizing... \nNow Average NDCG@k =  0.3851931095123291\nEpoch: 0022 loss_train: 0.5076 acc_train: 0.8944 loss_val: 1.0905 acc_val: 0.6796 time: 0.0034s\nRanking optimizing... \nNow Average NDCG@k =  0.3855396807193756\nEpoch: 0023 loss_train: 0.5061 acc_train: 0.8944 loss_val: 1.0907 acc_val: 0.6796 time: 0.0041s\nRanking optimizing... \nNow Average NDCG@k =  0.38577258586883545\nEpoch: 0024 loss_train: 0.5047 acc_train: 0.8944 loss_val: 1.0908 acc_val: 0.6796 time: 0.0027s\nRanking optimizing... \nNow Average NDCG@k =  0.38612744212150574\nEpoch: 0025 loss_train: 0.5032 acc_train: 0.8944 loss_val: 1.0909 acc_val: 0.6802 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.3864381015300751\nEpoch: 0026 loss_train: 0.5018 acc_train: 0.8944 loss_val: 1.0910 acc_val: 0.6784 time: 0.0025s\nRanking optimizing... \nNow Average NDCG@k =  0.3869975209236145\nEpoch: 0027 loss_train: 0.5004 acc_train: 0.8944 loss_val: 1.0911 acc_val: 0.6772 time: 0.0035s\nRanking optimizing... \nNow Average NDCG@k =  0.3873177766799927\nEpoch: 0028 loss_train: 0.4989 acc_train: 0.8968 loss_val: 1.0912 acc_val: 0.6760 time: 0.0030s\nRanking optimizing... \nNow Average NDCG@k =  0.3875797688961029\nEpoch: 0029 loss_train: 0.4975 acc_train: 0.8968 loss_val: 1.0914 acc_val: 0.6760 time: 0.0068s\nRanking optimizing... \nNow Average NDCG@k =  0.38777074217796326\nEpoch: 0030 loss_train: 0.4961 acc_train: 0.8968 loss_val: 1.0915 acc_val: 0.6754 time: 0.0028s\nRanking optimizing... \nNow Average NDCG@k =  0.38813644647598267\nEpoch: 0031 loss_train: 0.4948 acc_train: 0.8968 loss_val: 1.0916 acc_val: 0.6760 time: 0.0038s\nRanking optimizing... \nNow Average NDCG@k =  0.3884178400039673\nEpoch: 0032 loss_train: 0.4934 acc_train: 0.8968 loss_val: 1.0917 acc_val: 0.6760 time: 0.0028s\nRanking optimizing... \nNow Average NDCG@k =  0.3888902962207794\nEpoch: 0033 loss_train: 0.4920 acc_train: 0.8968 loss_val: 1.0918 acc_val: 0.6766 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.3890688121318817\nEpoch: 0034 loss_train: 0.4907 acc_train: 0.8981 loss_val: 1.0920 acc_val: 0.6766 time: 0.0040s\nRanking optimizing... \nNow Average NDCG@k =  0.38930588960647583\nEpoch: 0035 loss_train: 0.4894 acc_train: 0.8981 loss_val: 1.0921 acc_val: 0.6766 time: 0.0030s\nRanking optimizing... \nNow Average NDCG@k =  0.3896041512489319\nEpoch: 0036 loss_train: 0.4880 acc_train: 0.8981 loss_val: 1.0922 acc_val: 0.6766 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.3900657892227173\nEpoch: 0037 loss_train: 0.4867 acc_train: 0.8981 loss_val: 1.0924 acc_val: 0.6760 time: 0.0035s\nRanking optimizing... \nNow Average NDCG@k =  0.3903460204601288\nEpoch: 0038 loss_train: 0.4854 acc_train: 0.8981 loss_val: 1.0925 acc_val: 0.6760 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.3907136619091034\nEpoch: 0039 loss_train: 0.4841 acc_train: 0.8993 loss_val: 1.0927 acc_val: 0.6760 time: 0.0028s\nRanking optimizing... \nNow Average NDCG@k =  0.3910103440284729\nEpoch: 0040 loss_train: 0.4829 acc_train: 0.8993 loss_val: 1.0929 acc_val: 0.6754 time: 0.0033s\nRanking optimizing... \nNow Average NDCG@k =  0.3912472426891327\nEpoch: 0041 loss_train: 0.4816 acc_train: 0.9005 loss_val: 1.0930 acc_val: 0.6742 time: 0.0028s\nRanking optimizing... \nNow Average NDCG@k =  0.3913831114768982\nEpoch: 0042 loss_train: 0.4803 acc_train: 0.9005 loss_val: 1.0932 acc_val: 0.6735 time: 0.0034s\nRanking optimizing... \nNow Average NDCG@k =  0.3916579484939575\nEpoch: 0043 loss_train: 0.4791 acc_train: 0.9017 loss_val: 1.0934 acc_val: 0.6735 time: 0.0025s\nRanking optimizing... \nNow Average NDCG@k =  0.3917772173881531\nEpoch: 0044 loss_train: 0.4778 acc_train: 0.9017 loss_val: 1.0936 acc_val: 0.6729 time: 0.0034s\nRanking optimizing... \nNow Average NDCG@k =  0.39194604754447937\nEpoch: 0045 loss_train: 0.4766 acc_train: 0.9029 loss_val: 1.0938 acc_val: 0.6729 time: 0.0034s\nRanking optimizing... \nNow Average NDCG@k =  0.39214903116226196\nEpoch: 0046 loss_train: 0.4753 acc_train: 0.9029 loss_val: 1.0940 acc_val: 0.6729 time: 0.0034s\nRanking optimizing... \nNow Average NDCG@k =  0.39238426089286804\nEpoch: 0047 loss_train: 0.4741 acc_train: 0.9029 loss_val: 1.0942 acc_val: 0.6729 time: 0.0069s\nRanking optimizing... \nNow Average NDCG@k =  0.3925956189632416\nEpoch: 0048 loss_train: 0.4729 acc_train: 0.9041 loss_val: 1.0944 acc_val: 0.6729 time: 0.0024s\nRanking optimizing... \nNow Average NDCG@k =  0.3928475081920624\nEpoch: 0049 loss_train: 0.4717 acc_train: 0.9041 loss_val: 1.0947 acc_val: 0.6735 time: 0.0025s\nRanking optimizing... \nNow Average NDCG@k =  0.3931790590286255\nEpoch: 0050 loss_train: 0.4705 acc_train: 0.9053 loss_val: 1.0949 acc_val: 0.6735 time: 0.0028s\nRanking optimizing... \nNow Average NDCG@k =  0.3933291733264923\nTest set results: loss= 1.0691 accuracy= 0.6689\n"], ["node classification", "structural", "NDCG", "ACM", "GCN", "ACM\nUsing ACM dataset\nEpoch: 0001 loss_train: 2.2421 acc_train: 0.1080 loss_val: 2.2444 acc_val: 0.1080 time: 0.8635s\nRanking optimizing... \nNow Average NDCG@k =  0.1612471491098404\nEpoch: 0002 loss_train: 2.2124 acc_train: 0.1262 loss_val: 2.2194 acc_val: 0.1159 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.16470009088516235\nEpoch: 0003 loss_train: 2.1846 acc_train: 0.1456 loss_val: 2.1961 acc_val: 0.1280 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.16491755843162537\nEpoch: 0004 loss_train: 2.1604 acc_train: 0.1735 loss_val: 2.1734 acc_val: 0.1566 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.17129221558570862\nEpoch: 0005 loss_train: 2.1367 acc_train: 0.2269 loss_val: 2.1512 acc_val: 0.2257 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.17161200940608978\nEpoch: 0006 loss_train: 2.1127 acc_train: 0.2913 loss_val: 2.1294 acc_val: 0.2785 time: 0.0095s\nRanking optimizing... \nNow Average NDCG@k =  0.17493276298046112\nEpoch: 0007 loss_train: 2.0873 acc_train: 0.3410 loss_val: 2.1077 acc_val: 0.3083 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.183452308177948\nEpoch: 0008 loss_train: 2.0595 acc_train: 0.3629 loss_val: 2.0862 acc_val: 0.3307 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.18651267886161804\nEpoch: 0009 loss_train: 2.0365 acc_train: 0.3981 loss_val: 2.0643 acc_val: 0.3525 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.19266413152217865\nEpoch: 0010 loss_train: 2.0102 acc_train: 0.4138 loss_val: 2.0421 acc_val: 0.3817 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.19569112360477448\nEpoch: 0011 loss_train: 1.9879 acc_train: 0.4345 loss_val: 2.0192 acc_val: 0.4120 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.20052824914455414\nEpoch: 0012 loss_train: 1.9557 acc_train: 0.4721 loss_val: 1.9957 acc_val: 0.4508 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.20561912655830383\nEpoch: 0013 loss_train: 1.9292 acc_train: 0.4879 loss_val: 1.9714 acc_val: 0.4739 time: 0.0064s\nRanking optimizing... \nNow Average NDCG@k =  0.21067434549331665\nEpoch: 0014 loss_train: 1.9019 acc_train: 0.5243 loss_val: 1.9463 acc_val: 0.4921 time: 0.0090s\nRanking optimizing... \nNow Average NDCG@k =  0.20758739113807678\nEpoch: 0015 loss_train: 1.8723 acc_train: 0.5400 loss_val: 1.9203 acc_val: 0.5091 time: 0.0064s\nRanking optimizing... \nNow Average NDCG@k =  0.2146604210138321\nEpoch: 0016 loss_train: 1.8330 acc_train: 0.5583 loss_val: 1.8934 acc_val: 0.5261 time: 0.0066s\nRanking optimizing... \nNow Average NDCG@k =  0.21673378348350525\nEpoch: 0017 loss_train: 1.8059 acc_train: 0.5667 loss_val: 1.8655 acc_val: 0.5364 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.218722864985466\nEpoch: 0018 loss_train: 1.7734 acc_train: 0.5813 loss_val: 1.8365 acc_val: 0.5540 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.2230014204978943\nEpoch: 0019 loss_train: 1.7461 acc_train: 0.5995 loss_val: 1.8067 acc_val: 0.5607 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.21863733232021332\nEpoch: 0020 loss_train: 1.7117 acc_train: 0.5922 loss_val: 1.7760 acc_val: 0.5698 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.22357842326164246\nEpoch: 0021 loss_train: 1.6633 acc_train: 0.6153 loss_val: 1.7446 acc_val: 0.5795 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.2281797081232071\nEpoch: 0022 loss_train: 1.6366 acc_train: 0.6129 loss_val: 1.7127 acc_val: 0.5837 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.22593624889850616\nEpoch: 0023 loss_train: 1.5906 acc_train: 0.6432 loss_val: 1.6802 acc_val: 0.5910 time: 0.0077s\nRanking optimizing... \nNow Average NDCG@k =  0.2260800153017044\nEpoch: 0024 loss_train: 1.5549 acc_train: 0.6481 loss_val: 1.6473 acc_val: 0.6007 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.22682034969329834\nEpoch: 0025 loss_train: 1.5267 acc_train: 0.6493 loss_val: 1.6141 acc_val: 0.6117 time: 0.0063s\nRanking optimizing... \nNow Average NDCG@k =  0.2274334579706192\nEpoch: 0026 loss_train: 1.4823 acc_train: 0.6614 loss_val: 1.5808 acc_val: 0.6232 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.2278347611427307\nEpoch: 0027 loss_train: 1.4491 acc_train: 0.6578 loss_val: 1.5473 acc_val: 0.6317 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.2247016876935959\nEpoch: 0028 loss_train: 1.4050 acc_train: 0.6760 loss_val: 1.5140 acc_val: 0.6371 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.22367949783802032\nEpoch: 0029 loss_train: 1.3644 acc_train: 0.6723 loss_val: 1.4808 acc_val: 0.6414 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.2292860448360443\nEpoch: 0030 loss_train: 1.3296 acc_train: 0.6772 loss_val: 1.4480 acc_val: 0.6481 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.22642920911312103\nEpoch: 0031 loss_train: 1.2957 acc_train: 0.6808 loss_val: 1.4156 acc_val: 0.6578 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.22381475567817688\nEpoch: 0032 loss_train: 1.2579 acc_train: 0.6905 loss_val: 1.3838 acc_val: 0.6620 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.22372975945472717\nEpoch: 0033 loss_train: 1.2298 acc_train: 0.6954 loss_val: 1.3526 acc_val: 0.6657 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.22665591537952423\nEpoch: 0034 loss_train: 1.1939 acc_train: 0.6930 loss_val: 1.3222 acc_val: 0.6693 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.22199852764606476\nEpoch: 0035 loss_train: 1.1587 acc_train: 0.7051 loss_val: 1.2926 acc_val: 0.6760 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.22268767654895782\nEpoch: 0036 loss_train: 1.1318 acc_train: 0.7112 loss_val: 1.2639 acc_val: 0.6790 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.22343187034130096\nEpoch: 0037 loss_train: 1.0921 acc_train: 0.7245 loss_val: 1.2363 acc_val: 0.6802 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.2193271666765213\nEpoch: 0038 loss_train: 1.0585 acc_train: 0.7318 loss_val: 1.2097 acc_val: 0.6845 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.21892733871936798\nEpoch: 0039 loss_train: 1.0364 acc_train: 0.7403 loss_val: 1.1841 acc_val: 0.6948 time: 0.0117s\nRanking optimizing... \nNow Average NDCG@k =  0.21804285049438477\nEpoch: 0040 loss_train: 1.0079 acc_train: 0.7476 loss_val: 1.1598 acc_val: 0.6990 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.22110840678215027\nEpoch: 0041 loss_train: 0.9783 acc_train: 0.7500 loss_val: 1.1366 acc_val: 0.7033 time: 0.0066s\nRanking optimizing... \nNow Average NDCG@k =  0.21916796267032623\nEpoch: 0042 loss_train: 0.9499 acc_train: 0.7561 loss_val: 1.1145 acc_val: 0.7100 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.21923038363456726\nEpoch: 0043 loss_train: 0.9260 acc_train: 0.7682 loss_val: 1.0938 acc_val: 0.7136 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.21681194007396698\nEpoch: 0044 loss_train: 0.8988 acc_train: 0.7621 loss_val: 1.0742 acc_val: 0.7154 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.21571291983127594\nEpoch: 0045 loss_train: 0.8818 acc_train: 0.7670 loss_val: 1.0558 acc_val: 0.7172 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.2184673249721527\nEpoch: 0046 loss_train: 0.8702 acc_train: 0.7646 loss_val: 1.0384 acc_val: 0.7160 time: 0.0077s\nRanking optimizing... \nNow Average NDCG@k =  0.21553906798362732\nEpoch: 0047 loss_train: 0.8242 acc_train: 0.7816 loss_val: 1.0223 acc_val: 0.7178 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.21472978591918945\nEpoch: 0048 loss_train: 0.8336 acc_train: 0.7694 loss_val: 1.0072 acc_val: 0.7191 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.21405673027038574\nEpoch: 0049 loss_train: 0.7853 acc_train: 0.7816 loss_val: 0.9933 acc_val: 0.7215 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.21533723175525665\nEpoch: 0050 loss_train: 0.7760 acc_train: 0.7767 loss_val: 0.9804 acc_val: 0.7209 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.21422499418258667\nEpoch: 0051 loss_train: 0.7653 acc_train: 0.7816 loss_val: 0.9685 acc_val: 0.7203 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.21439771354198456\nEpoch: 0052 loss_train: 0.7588 acc_train: 0.7973 loss_val: 0.9574 acc_val: 0.7197 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.2147064059972763\nEpoch: 0053 loss_train: 0.7431 acc_train: 0.7973 loss_val: 0.9470 acc_val: 0.7178 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.21868659555912018\nEpoch: 0054 loss_train: 0.7051 acc_train: 0.7973 loss_val: 0.9375 acc_val: 0.7166 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.21294377744197845\nEpoch: 0055 loss_train: 0.6944 acc_train: 0.8034 loss_val: 0.9287 acc_val: 0.7178 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.2146083116531372\nEpoch: 0056 loss_train: 0.6896 acc_train: 0.7949 loss_val: 0.9205 acc_val: 0.7184 time: 0.0063s\nRanking optimizing... \nNow Average NDCG@k =  0.210635244846344\nEpoch: 0057 loss_train: 0.6913 acc_train: 0.7985 loss_val: 0.9128 acc_val: 0.7184 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.20970264077186584\nEpoch: 0058 loss_train: 0.6694 acc_train: 0.8010 loss_val: 0.9057 acc_val: 0.7184 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.20985542237758636\nEpoch: 0059 loss_train: 0.6481 acc_train: 0.7998 loss_val: 0.8991 acc_val: 0.7203 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.21138404309749603\nEpoch: 0060 loss_train: 0.6534 acc_train: 0.8058 loss_val: 0.8930 acc_val: 0.7203 time: 0.0097s\nRanking optimizing... \nNow Average NDCG@k =  0.21327942609786987\nEpoch: 0061 loss_train: 0.6426 acc_train: 0.8155 loss_val: 0.8875 acc_val: 0.7221 time: 0.0094s\nRanking optimizing... \nNow Average NDCG@k =  0.2111569046974182\nEpoch: 0062 loss_train: 0.6210 acc_train: 0.8058 loss_val: 0.8825 acc_val: 0.7221 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.2115129828453064\nEpoch: 0063 loss_train: 0.6133 acc_train: 0.8058 loss_val: 0.8780 acc_val: 0.7233 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.21234405040740967\nEpoch: 0064 loss_train: 0.6100 acc_train: 0.8022 loss_val: 0.8739 acc_val: 0.7239 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.21407751739025116\nEpoch: 0065 loss_train: 0.5997 acc_train: 0.8095 loss_val: 0.8702 acc_val: 0.7221 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.21310846507549286\nEpoch: 0066 loss_train: 0.5872 acc_train: 0.8143 loss_val: 0.8668 acc_val: 0.7215 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.21184304356575012\nEpoch: 0067 loss_train: 0.5929 acc_train: 0.8167 loss_val: 0.8638 acc_val: 0.7221 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.21059510111808777\nEpoch: 0068 loss_train: 0.5753 acc_train: 0.8143 loss_val: 0.8612 acc_val: 0.7245 time: 0.0068s\nRanking optimizing... \nNow Average NDCG@k =  0.2117592841386795\nEpoch: 0069 loss_train: 0.5656 acc_train: 0.8204 loss_val: 0.8589 acc_val: 0.7233 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.21549148857593536\nEpoch: 0070 loss_train: 0.5461 acc_train: 0.8289 loss_val: 0.8569 acc_val: 0.7209 time: 0.0063s\nRanking optimizing... \nNow Average NDCG@k =  0.2092607617378235\nEpoch: 0071 loss_train: 0.5490 acc_train: 0.8350 loss_val: 0.8551 acc_val: 0.7215 time: 0.0124s\nRanking optimizing... \nNow Average NDCG@k =  0.20994101464748383\nEpoch: 0072 loss_train: 0.5482 acc_train: 0.8325 loss_val: 0.8534 acc_val: 0.7227 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.21254807710647583\nEpoch: 0073 loss_train: 0.5202 acc_train: 0.8434 loss_val: 0.8519 acc_val: 0.7233 time: 0.0109s\nRanking optimizing... \nNow Average NDCG@k =  0.2165534794330597\nEpoch: 0074 loss_train: 0.5190 acc_train: 0.8398 loss_val: 0.8507 acc_val: 0.7263 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.21057987213134766\nEpoch: 0075 loss_train: 0.5144 acc_train: 0.8325 loss_val: 0.8496 acc_val: 0.7251 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.21257756650447845\nEpoch: 0076 loss_train: 0.5031 acc_train: 0.8422 loss_val: 0.8487 acc_val: 0.7239 time: 0.0122s\nRanking optimizing... \nNow Average NDCG@k =  0.21290157735347748\nEpoch: 0077 loss_train: 0.4992 acc_train: 0.8568 loss_val: 0.8480 acc_val: 0.7245 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.2141137719154358\nEpoch: 0078 loss_train: 0.4960 acc_train: 0.8398 loss_val: 0.8476 acc_val: 0.7221 time: 0.0063s\nRanking optimizing... \nNow Average NDCG@k =  0.21400700509548187\nEpoch: 0079 loss_train: 0.5035 acc_train: 0.8325 loss_val: 0.8476 acc_val: 0.7227 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.21228717267513275\nEpoch: 0080 loss_train: 0.4845 acc_train: 0.8495 loss_val: 0.8477 acc_val: 0.7239 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.21120774745941162\nEpoch: 0081 loss_train: 0.4814 acc_train: 0.8483 loss_val: 0.8481 acc_val: 0.7245 time: 0.0088s\nRanking optimizing... \nNow Average NDCG@k =  0.21654681861400604\nEpoch: 0082 loss_train: 0.4705 acc_train: 0.8434 loss_val: 0.8486 acc_val: 0.7227 time: 0.0077s\nRanking optimizing... \nNow Average NDCG@k =  0.21190671622753143\nEpoch: 0083 loss_train: 0.4523 acc_train: 0.8750 loss_val: 0.8493 acc_val: 0.7221 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.21818126738071442\nEpoch: 0084 loss_train: 0.4622 acc_train: 0.8592 loss_val: 0.8501 acc_val: 0.7221 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.21721337735652924\nEpoch: 0085 loss_train: 0.4488 acc_train: 0.8629 loss_val: 0.8507 acc_val: 0.7251 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.22050529718399048\nEpoch: 0086 loss_train: 0.4507 acc_train: 0.8604 loss_val: 0.8512 acc_val: 0.7275 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.2153911292552948\nEpoch: 0087 loss_train: 0.4455 acc_train: 0.8532 loss_val: 0.8518 acc_val: 0.7282 time: 0.0063s\nRanking optimizing... \nNow Average NDCG@k =  0.21769650280475616\nEpoch: 0088 loss_train: 0.4504 acc_train: 0.8568 loss_val: 0.8522 acc_val: 0.7263 time: 0.0060s\nRanking optimizing... \nNow Average NDCG@k =  0.2190243899822235\nEpoch: 0089 loss_train: 0.4289 acc_train: 0.8629 loss_val: 0.8529 acc_val: 0.7275 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.21636515855789185\nEpoch: 0090 loss_train: 0.4373 acc_train: 0.8653 loss_val: 0.8537 acc_val: 0.7282 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.21759547293186188\nEpoch: 0091 loss_train: 0.4295 acc_train: 0.8617 loss_val: 0.8545 acc_val: 0.7282 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.21929408609867096\nEpoch: 0092 loss_train: 0.4158 acc_train: 0.8786 loss_val: 0.8556 acc_val: 0.7257 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.22089187800884247\nEpoch: 0093 loss_train: 0.4013 acc_train: 0.8701 loss_val: 0.8569 acc_val: 0.7251 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.21700073778629303\nEpoch: 0094 loss_train: 0.4124 acc_train: 0.8786 loss_val: 0.8582 acc_val: 0.7251 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.21649305522441864\nEpoch: 0095 loss_train: 0.4061 acc_train: 0.8677 loss_val: 0.8595 acc_val: 0.7257 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.22058142721652985\nEpoch: 0096 loss_train: 0.4034 acc_train: 0.8811 loss_val: 0.8607 acc_val: 0.7257 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.2193627506494522\nEpoch: 0097 loss_train: 0.4033 acc_train: 0.8750 loss_val: 0.8619 acc_val: 0.7245 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.2236681878566742\nEpoch: 0098 loss_train: 0.3893 acc_train: 0.8677 loss_val: 0.8630 acc_val: 0.7227 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.22156937420368195\nEpoch: 0099 loss_train: 0.3865 acc_train: 0.8823 loss_val: 0.8645 acc_val: 0.7221 time: 0.0066s\nRanking optimizing... \nNow Average NDCG@k =  0.2224385291337967\nEpoch: 0100 loss_train: 0.3741 acc_train: 0.8774 loss_val: 0.8663 acc_val: 0.7239 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.21971744298934937\nEpoch: 0101 loss_train: 0.3906 acc_train: 0.8762 loss_val: 0.8684 acc_val: 0.7233 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.22190411388874054\nEpoch: 0102 loss_train: 0.3833 acc_train: 0.8811 loss_val: 0.8707 acc_val: 0.7227 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.22414660453796387\nEpoch: 0103 loss_train: 0.3688 acc_train: 0.8944 loss_val: 0.8729 acc_val: 0.7239 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.22512944042682648\nEpoch: 0104 loss_train: 0.3762 acc_train: 0.8835 loss_val: 0.8753 acc_val: 0.7215 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.22110122442245483\nEpoch: 0105 loss_train: 0.3695 acc_train: 0.8835 loss_val: 0.8776 acc_val: 0.7215 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.22130852937698364\nEpoch: 0106 loss_train: 0.3620 acc_train: 0.8811 loss_val: 0.8799 acc_val: 0.7215 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.2212802767753601\nEpoch: 0107 loss_train: 0.3653 acc_train: 0.8859 loss_val: 0.8822 acc_val: 0.7221 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.2217988520860672\nEpoch: 0108 loss_train: 0.3724 acc_train: 0.8738 loss_val: 0.8846 acc_val: 0.7209 time: 0.0060s\nRanking optimizing... \nNow Average NDCG@k =  0.22262482345104218\nEpoch: 0109 loss_train: 0.3483 acc_train: 0.8944 loss_val: 0.8871 acc_val: 0.7215 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.22426873445510864\nEpoch: 0110 loss_train: 0.3560 acc_train: 0.8968 loss_val: 0.8900 acc_val: 0.7191 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.22847838699817657\nEpoch: 0111 loss_train: 0.3572 acc_train: 0.8871 loss_val: 0.8927 acc_val: 0.7191 time: 0.0077s\nRanking optimizing... \nNow Average NDCG@k =  0.22501204907894135\nEpoch: 0112 loss_train: 0.3640 acc_train: 0.8883 loss_val: 0.8952 acc_val: 0.7197 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.22761552035808563\nEpoch: 0113 loss_train: 0.3578 acc_train: 0.8956 loss_val: 0.8977 acc_val: 0.7191 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.2245035469532013\nEpoch: 0114 loss_train: 0.3322 acc_train: 0.8944 loss_val: 0.9000 acc_val: 0.7203 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.22506828606128693\nEpoch: 0115 loss_train: 0.3291 acc_train: 0.8956 loss_val: 0.9028 acc_val: 0.7197 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.22495251893997192\nEpoch: 0116 loss_train: 0.3520 acc_train: 0.8871 loss_val: 0.9055 acc_val: 0.7197 time: 0.0064s\nRanking optimizing... \nNow Average NDCG@k =  0.22597651183605194\nEpoch: 0117 loss_train: 0.3466 acc_train: 0.8908 loss_val: 0.9083 acc_val: 0.7191 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.22786365449428558\nEpoch: 0118 loss_train: 0.3459 acc_train: 0.8859 loss_val: 0.9110 acc_val: 0.7178 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.22215086221694946\nEpoch: 0119 loss_train: 0.3373 acc_train: 0.9005 loss_val: 0.9137 acc_val: 0.7166 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.22699856758117676\nEpoch: 0120 loss_train: 0.3310 acc_train: 0.9029 loss_val: 0.9164 acc_val: 0.7160 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.2257787436246872\nEpoch: 0121 loss_train: 0.3208 acc_train: 0.9078 loss_val: 0.9192 acc_val: 0.7160 time: 0.0119s\nRanking optimizing... \nNow Average NDCG@k =  0.22680649161338806\nEpoch: 0122 loss_train: 0.3377 acc_train: 0.8908 loss_val: 0.9218 acc_val: 0.7142 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.23239928483963013\nEpoch: 0123 loss_train: 0.3115 acc_train: 0.9005 loss_val: 0.9247 acc_val: 0.7154 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.22639130055904388\nEpoch: 0124 loss_train: 0.3252 acc_train: 0.8981 loss_val: 0.9275 acc_val: 0.7154 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.22894501686096191\nEpoch: 0125 loss_train: 0.3252 acc_train: 0.9017 loss_val: 0.9306 acc_val: 0.7166 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.22715704143047333\nEpoch: 0126 loss_train: 0.3110 acc_train: 0.8993 loss_val: 0.9337 acc_val: 0.7178 time: 0.0072s\nRanking optimizing... \nNow Average NDCG@k =  0.22562550008296967\nEpoch: 0127 loss_train: 0.3202 acc_train: 0.9114 loss_val: 0.9366 acc_val: 0.7160 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.22479642927646637\nEpoch: 0128 loss_train: 0.3207 acc_train: 0.9102 loss_val: 0.9395 acc_val: 0.7160 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.22606171667575836\nEpoch: 0129 loss_train: 0.2959 acc_train: 0.9138 loss_val: 0.9421 acc_val: 0.7130 time: 0.0060s\nRanking optimizing... \nNow Average NDCG@k =  0.23192010819911957\nEpoch: 0130 loss_train: 0.3099 acc_train: 0.8968 loss_val: 0.9445 acc_val: 0.7106 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.2286212146282196\nEpoch: 0131 loss_train: 0.3089 acc_train: 0.9138 loss_val: 0.9464 acc_val: 0.7124 time: 0.0076s\nRanking optimizing... \nNow Average NDCG@k =  0.22755956649780273\nEpoch: 0132 loss_train: 0.2976 acc_train: 0.9138 loss_val: 0.9480 acc_val: 0.7118 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.22892244160175323\nEpoch: 0133 loss_train: 0.2793 acc_train: 0.9199 loss_val: 0.9496 acc_val: 0.7118 time: 0.0063s\nRanking optimizing... \nNow Average NDCG@k =  0.22935350239276886\nEpoch: 0134 loss_train: 0.3060 acc_train: 0.9090 loss_val: 0.9518 acc_val: 0.7124 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.2321883738040924\nEpoch: 0135 loss_train: 0.2946 acc_train: 0.9187 loss_val: 0.9541 acc_val: 0.7148 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.23074565827846527\nEpoch: 0136 loss_train: 0.2951 acc_train: 0.9090 loss_val: 0.9566 acc_val: 0.7148 time: 0.0092s\nRanking optimizing... \nNow Average NDCG@k =  0.23443546891212463\nEpoch: 0137 loss_train: 0.2964 acc_train: 0.9078 loss_val: 0.9594 acc_val: 0.7148 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.2272556573152542\nEpoch: 0138 loss_train: 0.2812 acc_train: 0.9138 loss_val: 0.9623 acc_val: 0.7142 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.2264101207256317\nEpoch: 0139 loss_train: 0.3062 acc_train: 0.9005 loss_val: 0.9652 acc_val: 0.7148 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.23136694729328156\nEpoch: 0140 loss_train: 0.2982 acc_train: 0.9041 loss_val: 0.9681 acc_val: 0.7124 time: 0.0064s\nRanking optimizing... \nNow Average NDCG@k =  0.23008915781974792\nEpoch: 0141 loss_train: 0.2924 acc_train: 0.9114 loss_val: 0.9706 acc_val: 0.7118 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.23140670359134674\nEpoch: 0142 loss_train: 0.2704 acc_train: 0.9235 loss_val: 0.9732 acc_val: 0.7112 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.2315373718738556\nEpoch: 0143 loss_train: 0.2879 acc_train: 0.9066 loss_val: 0.9759 acc_val: 0.7100 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.23234090209007263\nEpoch: 0144 loss_train: 0.2878 acc_train: 0.9187 loss_val: 0.9788 acc_val: 0.7093 time: 0.0089s\nRanking optimizing... \nNow Average NDCG@k =  0.2346087247133255\nEpoch: 0145 loss_train: 0.2726 acc_train: 0.9138 loss_val: 0.9816 acc_val: 0.7087 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.23049278557300568\nEpoch: 0146 loss_train: 0.2890 acc_train: 0.9041 loss_val: 0.9842 acc_val: 0.7063 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.23434799909591675\nEpoch: 0147 loss_train: 0.2920 acc_train: 0.8956 loss_val: 0.9871 acc_val: 0.7045 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.23186105489730835\nEpoch: 0148 loss_train: 0.2754 acc_train: 0.9138 loss_val: 0.9897 acc_val: 0.7033 time: 0.0078s\nRanking optimizing... \nNow Average NDCG@k =  0.23308175802230835\nEpoch: 0149 loss_train: 0.2675 acc_train: 0.9199 loss_val: 0.9920 acc_val: 0.7051 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.23318350315093994\nEpoch: 0150 loss_train: 0.2662 acc_train: 0.9114 loss_val: 0.9937 acc_val: 0.7057 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.2347654402256012\nEpoch: 0151 loss_train: 0.2607 acc_train: 0.9223 loss_val: 0.9954 acc_val: 0.7051 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.23415717482566833\nEpoch: 0152 loss_train: 0.2638 acc_train: 0.9150 loss_val: 0.9976 acc_val: 0.7051 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.23486745357513428\nEpoch: 0153 loss_train: 0.2713 acc_train: 0.9175 loss_val: 0.9997 acc_val: 0.7075 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.2317797839641571\nEpoch: 0154 loss_train: 0.2693 acc_train: 0.9248 loss_val: 1.0021 acc_val: 0.7063 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.23457331955432892\nEpoch: 0155 loss_train: 0.2571 acc_train: 0.9248 loss_val: 1.0041 acc_val: 0.7069 time: 0.0063s\nRanking optimizing... \nNow Average NDCG@k =  0.23414567112922668\nEpoch: 0156 loss_train: 0.2798 acc_train: 0.9223 loss_val: 1.0063 acc_val: 0.7069 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.234869584441185\nEpoch: 0157 loss_train: 0.2635 acc_train: 0.9187 loss_val: 1.0085 acc_val: 0.7063 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.2354145050048828\nEpoch: 0158 loss_train: 0.2441 acc_train: 0.9284 loss_val: 1.0110 acc_val: 0.7069 time: 0.0063s\nRanking optimizing... \nNow Average NDCG@k =  0.23779180645942688\nEpoch: 0159 loss_train: 0.2706 acc_train: 0.9187 loss_val: 1.0133 acc_val: 0.7057 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.23801757395267487\nEpoch: 0160 loss_train: 0.2642 acc_train: 0.9248 loss_val: 1.0163 acc_val: 0.7051 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.23729030787944794\nEpoch: 0161 loss_train: 0.2562 acc_train: 0.9150 loss_val: 1.0195 acc_val: 0.7063 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.23668381571769714\nEpoch: 0162 loss_train: 0.2447 acc_train: 0.9308 loss_val: 1.0230 acc_val: 0.7057 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.23725607991218567\nEpoch: 0163 loss_train: 0.2621 acc_train: 0.9187 loss_val: 1.0265 acc_val: 0.7027 time: 0.0060s\nRanking optimizing... \nNow Average NDCG@k =  0.2365029901266098\nEpoch: 0164 loss_train: 0.2550 acc_train: 0.9175 loss_val: 1.0304 acc_val: 0.7033 time: 0.0059s\nRanking optimizing... \nNow Average NDCG@k =  0.2386123090982437\nEpoch: 0165 loss_train: 0.2362 acc_train: 0.9320 loss_val: 1.0340 acc_val: 0.7027 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.2336876094341278\nEpoch: 0166 loss_train: 0.2533 acc_train: 0.9320 loss_val: 1.0376 acc_val: 0.7021 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.23843319714069366\nEpoch: 0167 loss_train: 0.2575 acc_train: 0.9199 loss_val: 1.0412 acc_val: 0.7027 time: 0.0075s\nRanking optimizing... \nNow Average NDCG@k =  0.23948605358600616\nEpoch: 0168 loss_train: 0.2481 acc_train: 0.9175 loss_val: 1.0445 acc_val: 0.7033 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.23981860280036926\nEpoch: 0169 loss_train: 0.2447 acc_train: 0.9260 loss_val: 1.0478 acc_val: 0.7039 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.23440657556056976\nEpoch: 0170 loss_train: 0.2404 acc_train: 0.9248 loss_val: 1.0507 acc_val: 0.7045 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.237155020236969\nEpoch: 0171 loss_train: 0.2449 acc_train: 0.9199 loss_val: 1.0536 acc_val: 0.7051 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.2407299429178238\nEpoch: 0172 loss_train: 0.2497 acc_train: 0.9211 loss_val: 1.0559 acc_val: 0.7039 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.2394401729106903\nEpoch: 0173 loss_train: 0.2360 acc_train: 0.9248 loss_val: 1.0581 acc_val: 0.7015 time: 0.0077s\nRanking optimizing... \nNow Average NDCG@k =  0.23703989386558533\nEpoch: 0174 loss_train: 0.2246 acc_train: 0.9333 loss_val: 1.0602 acc_val: 0.6990 time: 0.0064s\nRanking optimizing... \nNow Average NDCG@k =  0.23859478533267975\nEpoch: 0175 loss_train: 0.2434 acc_train: 0.9308 loss_val: 1.0623 acc_val: 0.6984 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.24002602696418762\nEpoch: 0176 loss_train: 0.2299 acc_train: 0.9381 loss_val: 1.0648 acc_val: 0.6990 time: 0.0123s\nRanking optimizing... \nNow Average NDCG@k =  0.23719993233680725\nEpoch: 0177 loss_train: 0.2419 acc_train: 0.9320 loss_val: 1.0674 acc_val: 0.6978 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.240209698677063\nEpoch: 0178 loss_train: 0.2310 acc_train: 0.9320 loss_val: 1.0705 acc_val: 0.6978 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.23875148594379425\nEpoch: 0179 loss_train: 0.2259 acc_train: 0.9357 loss_val: 1.0738 acc_val: 0.6978 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.23932768404483795\nEpoch: 0180 loss_train: 0.2458 acc_train: 0.9187 loss_val: 1.0768 acc_val: 0.6966 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.23923172056674957\nEpoch: 0181 loss_train: 0.2396 acc_train: 0.9211 loss_val: 1.0794 acc_val: 0.6960 time: 0.0080s\nRanking optimizing... \nNow Average NDCG@k =  0.24289174377918243\nEpoch: 0182 loss_train: 0.2198 acc_train: 0.9381 loss_val: 1.0822 acc_val: 0.6966 time: 0.0065s\nRanking optimizing... \nNow Average NDCG@k =  0.24018779397010803\nEpoch: 0183 loss_train: 0.2351 acc_train: 0.9308 loss_val: 1.0849 acc_val: 0.6978 time: 0.0061s\nRanking optimizing... \nNow Average NDCG@k =  0.23997926712036133\nEpoch: 0184 loss_train: 0.2277 acc_train: 0.9260 loss_val: 1.0870 acc_val: 0.6978 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.24197956919670105\nEpoch: 0185 loss_train: 0.2204 acc_train: 0.9405 loss_val: 1.0886 acc_val: 0.6966 time: 0.0087s\nRanking optimizing... \nNow Average NDCG@k =  0.23676763474941254\nEpoch: 0186 loss_train: 0.2119 acc_train: 0.9381 loss_val: 1.0900 acc_val: 0.6996 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.23722977936267853\nEpoch: 0187 loss_train: 0.2318 acc_train: 0.9223 loss_val: 1.0919 acc_val: 0.7002 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.2387896627187729\nEpoch: 0188 loss_train: 0.2344 acc_train: 0.9260 loss_val: 1.0944 acc_val: 0.6996 time: 0.0060s\nRanking optimizing... \nNow Average NDCG@k =  0.24055948853492737\nEpoch: 0189 loss_train: 0.2182 acc_train: 0.9430 loss_val: 1.0970 acc_val: 0.6996 time: 0.0084s\nRanking optimizing... \nNow Average NDCG@k =  0.23855145275592804\nEpoch: 0190 loss_train: 0.2122 acc_train: 0.9345 loss_val: 1.1000 acc_val: 0.7002 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.23968133330345154\nEpoch: 0191 loss_train: 0.2192 acc_train: 0.9345 loss_val: 1.1029 acc_val: 0.7008 time: 0.0064s\nRanking optimizing... \nNow Average NDCG@k =  0.23826327919960022\nEpoch: 0192 loss_train: 0.2107 acc_train: 0.9320 loss_val: 1.1051 acc_val: 0.7008 time: 0.0062s\nRanking optimizing... \nNow Average NDCG@k =  0.24032090604305267\nEpoch: 0193 loss_train: 0.2170 acc_train: 0.9333 loss_val: 1.1076 acc_val: 0.7008 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.23820403218269348\nEpoch: 0194 loss_train: 0.2240 acc_train: 0.9308 loss_val: 1.1101 acc_val: 0.7021 time: 0.0079s\nRanking optimizing... \nNow Average NDCG@k =  0.24139946699142456\nEpoch: 0195 loss_train: 0.2159 acc_train: 0.9345 loss_val: 1.1127 acc_val: 0.7039 time: 0.0083s\nRanking optimizing... \nNow Average NDCG@k =  0.23991969227790833\nEpoch: 0196 loss_train: 0.2193 acc_train: 0.9284 loss_val: 1.1152 acc_val: 0.7027 time: 0.0081s\nRanking optimizing... \nNow Average NDCG@k =  0.24382717907428741\nEpoch: 0197 loss_train: 0.2199 acc_train: 0.9405 loss_val: 1.1178 acc_val: 0.7015 time: 0.0098s\nRanking optimizing... \nNow Average NDCG@k =  0.24696679413318634\nEpoch: 0198 loss_train: 0.2202 acc_train: 0.9308 loss_val: 1.1203 acc_val: 0.7015 time: 0.0082s\nRanking optimizing... \nNow Average NDCG@k =  0.24273619055747986\nEpoch: 0199 loss_train: 0.2130 acc_train: 0.9333 loss_val: 1.1231 acc_val: 0.7008 time: 0.0085s\nRanking optimizing... \nNow Average NDCG@k =  0.24293918907642365\nEpoch: 0200 loss_train: 0.2271 acc_train: 0.9333 loss_val: 1.1261 acc_val: 0.6996 time: 0.0086s\nRanking optimizing... \nNow Average NDCG@k =  0.24524645507335663\nTest set results: loss= 1.2073 accuracy= 0.6828\n"], ["node classification", "structural", "NDCG", "coauthor-cs", "SGC", "Command 'cd node\\ classification; time python REDRESS_structural_NDCG.py --dataset coauthor-cs --model SGC' returned non-zero exit status 1."], ["node classification", "structural", "NDCG", "coauthor-cs", "GCN", "Command 'cd node\\ classification; time python REDRESS_structural_NDCG.py --dataset coauthor-cs --model GCN' returned non-zero exit status 1."], ["node classification", "structural", "NDCG", "coauthor-phy", "SGC", "Command 'cd node\\ classification; time python REDRESS_structural_NDCG.py --dataset coauthor-phy --model SGC' returned non-zero exit status 1."], ["node classification", "structural", "NDCG", "coauthor-phy", "GCN", "Command 'cd node\\ classification; time python REDRESS_structural_NDCG.py --dataset coauthor-phy --model GCN' returned non-zero exit status 1."], ["node classification", "structural", "ERR", "ACM", "SGC", "ACM\nUsing ACM dataset\nstart\nfinished\nEpoch: 0001 loss_train: 2.2171 acc_train: 0.0461 loss_val: 2.1957 acc_val: 0.1086 time: 0.6197s\nEpoch: 0002 loss_train: 2.1912 acc_train: 0.1129 loss_val: 2.1745 acc_val: 0.1930 time: 0.0025s\nEpoch: 0003 loss_train: 2.1656 acc_train: 0.2354 loss_val: 2.1535 acc_val: 0.3216 time: 0.0021s\nEpoch: 0004 loss_train: 2.1403 acc_train: 0.3993 loss_val: 2.1327 acc_val: 0.4502 time: 0.0021s\nEpoch: 0005 loss_train: 2.1153 acc_train: 0.5437 loss_val: 2.1123 acc_val: 0.5309 time: 0.0021s\nEpoch: 0006 loss_train: 2.0906 acc_train: 0.6104 loss_val: 2.0920 acc_val: 0.5758 time: 0.0020s\nEpoch: 0007 loss_train: 2.0662 acc_train: 0.6590 loss_val: 2.0721 acc_val: 0.5965 time: 0.0021s\nEpoch: 0008 loss_train: 2.0421 acc_train: 0.6808 loss_val: 2.0524 acc_val: 0.6123 time: 0.0020s\nEpoch: 0009 loss_train: 2.0184 acc_train: 0.6917 loss_val: 2.0330 acc_val: 0.6189 time: 0.0020s\nEpoch: 0010 loss_train: 1.9950 acc_train: 0.7027 loss_val: 2.0139 acc_val: 0.6280 time: 0.0020s\nEpoch: 0011 loss_train: 1.9719 acc_train: 0.7184 loss_val: 1.9951 acc_val: 0.6286 time: 0.0020s\nEpoch: 0012 loss_train: 1.9491 acc_train: 0.7160 loss_val: 1.9766 acc_val: 0.6317 time: 0.0019s\nEpoch: 0013 loss_train: 1.9266 acc_train: 0.7197 loss_val: 1.9584 acc_val: 0.6365 time: 0.0020s\nEpoch: 0014 loss_train: 1.9045 acc_train: 0.7221 loss_val: 1.9405 acc_val: 0.6390 time: 0.0019s\nEpoch: 0015 loss_train: 1.8827 acc_train: 0.7209 loss_val: 1.9228 acc_val: 0.6396 time: 0.0020s\nEpoch: 0016 loss_train: 1.8612 acc_train: 0.7209 loss_val: 1.9055 acc_val: 0.6420 time: 0.0019s\nEpoch: 0017 loss_train: 1.8401 acc_train: 0.7245 loss_val: 1.8884 acc_val: 0.6432 time: 0.0019s\nEpoch: 0018 loss_train: 1.8193 acc_train: 0.7245 loss_val: 1.8717 acc_val: 0.6426 time: 0.0019s\nEpoch: 0019 loss_train: 1.7988 acc_train: 0.7318 loss_val: 1.8552 acc_val: 0.6426 time: 0.0020s\nEpoch: 0020 loss_train: 1.7786 acc_train: 0.7330 loss_val: 1.8391 acc_val: 0.6438 time: 0.0019s\nEpoch: 0021 loss_train: 1.7588 acc_train: 0.7342 loss_val: 1.8232 acc_val: 0.6426 time: 0.0019s\nEpoch: 0022 loss_train: 1.7393 acc_train: 0.7354 loss_val: 1.8076 acc_val: 0.6456 time: 0.0019s\nEpoch: 0023 loss_train: 1.7201 acc_train: 0.7403 loss_val: 1.7923 acc_val: 0.6462 time: 0.0019s\nEpoch: 0024 loss_train: 1.7012 acc_train: 0.7391 loss_val: 1.7772 acc_val: 0.6475 time: 0.0019s\nEpoch: 0025 loss_train: 1.6826 acc_train: 0.7415 loss_val: 1.7625 acc_val: 0.6505 time: 0.0020s\nEpoch: 0026 loss_train: 1.6644 acc_train: 0.7403 loss_val: 1.7480 acc_val: 0.6499 time: 0.0019s\nEpoch: 0027 loss_train: 1.6465 acc_train: 0.7427 loss_val: 1.7338 acc_val: 0.6511 time: 0.0020s\nEpoch: 0028 loss_train: 1.6289 acc_train: 0.7427 loss_val: 1.7199 acc_val: 0.6517 time: 0.0020s\nEpoch: 0029 loss_train: 1.6116 acc_train: 0.7476 loss_val: 1.7063 acc_val: 0.6529 time: 0.0020s\nEpoch: 0030 loss_train: 1.5946 acc_train: 0.7488 loss_val: 1.6929 acc_val: 0.6535 time: 0.0019s\nEpoch: 0031 loss_train: 1.5779 acc_train: 0.7524 loss_val: 1.6797 acc_val: 0.6535 time: 0.0019s\nEpoch: 0032 loss_train: 1.5615 acc_train: 0.7524 loss_val: 1.6669 acc_val: 0.6535 time: 0.0019s\nEpoch: 0033 loss_train: 1.5454 acc_train: 0.7536 loss_val: 1.6542 acc_val: 0.6553 time: 0.0019s\nEpoch: 0034 loss_train: 1.5296 acc_train: 0.7561 loss_val: 1.6419 acc_val: 0.6566 time: 0.0019s\nEpoch: 0035 loss_train: 1.5141 acc_train: 0.7573 loss_val: 1.6298 acc_val: 0.6572 time: 0.0019s\nEpoch: 0036 loss_train: 1.4989 acc_train: 0.7585 loss_val: 1.6179 acc_val: 0.6590 time: 0.0019s\nEpoch: 0037 loss_train: 1.4840 acc_train: 0.7597 loss_val: 1.6062 acc_val: 0.6602 time: 0.0019s\nEpoch: 0038 loss_train: 1.4693 acc_train: 0.7609 loss_val: 1.5948 acc_val: 0.6614 time: 0.0019s\nEpoch: 0039 loss_train: 1.4549 acc_train: 0.7609 loss_val: 1.5837 acc_val: 0.6632 time: 0.0019s\nEpoch: 0040 loss_train: 1.4407 acc_train: 0.7621 loss_val: 1.5727 acc_val: 0.6650 time: 0.0018s\nEpoch: 0041 loss_train: 1.4268 acc_train: 0.7621 loss_val: 1.5620 acc_val: 0.6669 time: 0.0019s\nEpoch: 0042 loss_train: 1.4132 acc_train: 0.7633 loss_val: 1.5515 acc_val: 0.6681 time: 0.0019s\nEpoch: 0043 loss_train: 1.3998 acc_train: 0.7633 loss_val: 1.5412 acc_val: 0.6705 time: 0.0018s\nEpoch: 0044 loss_train: 1.3866 acc_train: 0.7633 loss_val: 1.5311 acc_val: 0.6711 time: 0.0019s\nEpoch: 0045 loss_train: 1.3737 acc_train: 0.7658 loss_val: 1.5212 acc_val: 0.6717 time: 0.0019s\nEpoch: 0046 loss_train: 1.3610 acc_train: 0.7682 loss_val: 1.5115 acc_val: 0.6723 time: 0.0019s\nEpoch: 0047 loss_train: 1.3486 acc_train: 0.7706 loss_val: 1.5020 acc_val: 0.6723 time: 0.0020s\nEpoch: 0048 loss_train: 1.3363 acc_train: 0.7743 loss_val: 1.4927 acc_val: 0.6723 time: 0.0019s\nEpoch: 0049 loss_train: 1.3243 acc_train: 0.7779 loss_val: 1.4836 acc_val: 0.6723 time: 0.0019s\nEpoch: 0050 loss_train: 1.3125 acc_train: 0.7779 loss_val: 1.4747 acc_val: 0.6735 time: 0.0020s\nEpoch: 0051 loss_train: 1.3009 acc_train: 0.7803 loss_val: 1.4659 acc_val: 0.6742 time: 0.0019s\nEpoch: 0052 loss_train: 1.2896 acc_train: 0.7828 loss_val: 1.4574 acc_val: 0.6748 time: 0.0020s\nEpoch: 0053 loss_train: 1.2784 acc_train: 0.7828 loss_val: 1.4490 acc_val: 0.6754 time: 0.0019s\nEpoch: 0054 loss_train: 1.2674 acc_train: 0.7828 loss_val: 1.4407 acc_val: 0.6754 time: 0.0020s\nEpoch: 0055 loss_train: 1.2566 acc_train: 0.7840 loss_val: 1.4327 acc_val: 0.6742 time: 0.0019s\nEpoch: 0056 loss_train: 1.2460 acc_train: 0.7852 loss_val: 1.4248 acc_val: 0.6742 time: 0.0019s\nEpoch: 0057 loss_train: 1.2356 acc_train: 0.7900 loss_val: 1.4171 acc_val: 0.6729 time: 0.0019s\nEpoch: 0058 loss_train: 1.2253 acc_train: 0.7913 loss_val: 1.4095 acc_val: 0.6735 time: 0.0019s\nEpoch: 0059 loss_train: 1.2153 acc_train: 0.7913 loss_val: 1.4021 acc_val: 0.6735 time: 0.0019s\nEpoch: 0060 loss_train: 1.2054 acc_train: 0.7925 loss_val: 1.3948 acc_val: 0.6742 time: 0.0019s\nEpoch: 0061 loss_train: 1.1956 acc_train: 0.7913 loss_val: 1.3877 acc_val: 0.6754 time: 0.0018s\nEpoch: 0062 loss_train: 1.1861 acc_train: 0.7925 loss_val: 1.3807 acc_val: 0.6772 time: 0.0019s\nEpoch: 0063 loss_train: 1.1767 acc_train: 0.7937 loss_val: 1.3739 acc_val: 0.6784 time: 0.0019s\nEpoch: 0064 loss_train: 1.1674 acc_train: 0.7961 loss_val: 1.3672 acc_val: 0.6784 time: 0.0019s\nEpoch: 0065 loss_train: 1.1583 acc_train: 0.7961 loss_val: 1.3607 acc_val: 0.6796 time: 0.0019s\nEpoch: 0066 loss_train: 1.1494 acc_train: 0.7985 loss_val: 1.3542 acc_val: 0.6820 time: 0.0020s\nEpoch: 0067 loss_train: 1.1406 acc_train: 0.7985 loss_val: 1.3479 acc_val: 0.6820 time: 0.0019s\nEpoch: 0068 loss_train: 1.1320 acc_train: 0.7985 loss_val: 1.3417 acc_val: 0.6839 time: 0.0020s\nEpoch: 0069 loss_train: 1.1235 acc_train: 0.8034 loss_val: 1.3357 acc_val: 0.6851 time: 0.0019s\nEpoch: 0070 loss_train: 1.1151 acc_train: 0.8034 loss_val: 1.3297 acc_val: 0.6845 time: 0.0019s\nEpoch: 0071 loss_train: 1.1068 acc_train: 0.8058 loss_val: 1.3239 acc_val: 0.6851 time: 0.0019s\nEpoch: 0072 loss_train: 1.0987 acc_train: 0.8083 loss_val: 1.3182 acc_val: 0.6857 time: 0.0020s\nEpoch: 0073 loss_train: 1.0908 acc_train: 0.8107 loss_val: 1.3126 acc_val: 0.6869 time: 0.0019s\nEpoch: 0074 loss_train: 1.0829 acc_train: 0.8119 loss_val: 1.3071 acc_val: 0.6869 time: 0.0020s\nEpoch: 0075 loss_train: 1.0752 acc_train: 0.8119 loss_val: 1.3017 acc_val: 0.6875 time: 0.0019s\nEpoch: 0076 loss_train: 1.0676 acc_train: 0.8107 loss_val: 1.2964 acc_val: 0.6893 time: 0.0064s\nEpoch: 0077 loss_train: 1.0601 acc_train: 0.8119 loss_val: 1.2912 acc_val: 0.6887 time: 0.0021s\nEpoch: 0078 loss_train: 1.0527 acc_train: 0.8119 loss_val: 1.2861 acc_val: 0.6899 time: 0.0019s\nEpoch: 0079 loss_train: 1.0455 acc_train: 0.8143 loss_val: 1.2811 acc_val: 0.6893 time: 0.0019s\nEpoch: 0080 loss_train: 1.0383 acc_train: 0.8143 loss_val: 1.2762 acc_val: 0.6899 time: 0.0019s\nEpoch: 0081 loss_train: 1.0313 acc_train: 0.8167 loss_val: 1.2714 acc_val: 0.6899 time: 0.0018s\nEpoch: 0082 loss_train: 1.0244 acc_train: 0.8155 loss_val: 1.2666 acc_val: 0.6905 time: 0.0019s\nEpoch: 0083 loss_train: 1.0175 acc_train: 0.8167 loss_val: 1.2620 acc_val: 0.6893 time: 0.0018s\nEpoch: 0084 loss_train: 1.0108 acc_train: 0.8192 loss_val: 1.2574 acc_val: 0.6899 time: 0.0019s\nEpoch: 0085 loss_train: 1.0042 acc_train: 0.8204 loss_val: 1.2529 acc_val: 0.6893 time: 0.0018s\nEpoch: 0086 loss_train: 0.9976 acc_train: 0.8216 loss_val: 1.2485 acc_val: 0.6899 time: 0.0019s\nEpoch: 0087 loss_train: 0.9912 acc_train: 0.8216 loss_val: 1.2442 acc_val: 0.6905 time: 0.0019s\nEpoch: 0088 loss_train: 0.9848 acc_train: 0.8216 loss_val: 1.2399 acc_val: 0.6905 time: 0.0018s\nEpoch: 0089 loss_train: 0.9786 acc_train: 0.8240 loss_val: 1.2357 acc_val: 0.6905 time: 0.0019s\nEpoch: 0090 loss_train: 0.9724 acc_train: 0.8240 loss_val: 1.2316 acc_val: 0.6917 time: 0.0019s\nEpoch: 0091 loss_train: 0.9664 acc_train: 0.8240 loss_val: 1.2276 acc_val: 0.6930 time: 0.0019s\nEpoch: 0092 loss_train: 0.9604 acc_train: 0.8265 loss_val: 1.2236 acc_val: 0.6930 time: 0.0018s\nEpoch: 0093 loss_train: 0.9545 acc_train: 0.8265 loss_val: 1.2197 acc_val: 0.6942 time: 0.0019s\nEpoch: 0094 loss_train: 0.9486 acc_train: 0.8265 loss_val: 1.2159 acc_val: 0.6936 time: 0.0019s\nEpoch: 0095 loss_train: 0.9429 acc_train: 0.8277 loss_val: 1.2121 acc_val: 0.6942 time: 0.0020s\nEpoch: 0096 loss_train: 0.9372 acc_train: 0.8277 loss_val: 1.2084 acc_val: 0.6954 time: 0.0019s\nEpoch: 0097 loss_train: 0.9316 acc_train: 0.8277 loss_val: 1.2047 acc_val: 0.6960 time: 0.0020s\nEpoch: 0098 loss_train: 0.9261 acc_train: 0.8289 loss_val: 1.2012 acc_val: 0.6978 time: 0.0019s\nEpoch: 0099 loss_train: 0.9207 acc_train: 0.8289 loss_val: 1.1976 acc_val: 0.6978 time: 0.0020s\nEpoch: 0100 loss_train: 0.9153 acc_train: 0.8289 loss_val: 1.1942 acc_val: 0.6972 time: 0.0019s\nEpoch: 0101 loss_train: 0.9100 acc_train: 0.8301 loss_val: 1.1908 acc_val: 0.6966 time: 0.0020s\nEpoch: 0102 loss_train: 0.9048 acc_train: 0.8313 loss_val: 1.1874 acc_val: 0.6966 time: 0.0019s\nEpoch: 0103 loss_train: 0.8996 acc_train: 0.8325 loss_val: 1.1841 acc_val: 0.6972 time: 0.0020s\nEpoch: 0104 loss_train: 0.8945 acc_train: 0.8350 loss_val: 1.1809 acc_val: 0.6978 time: 0.0020s\nEpoch: 0105 loss_train: 0.8895 acc_train: 0.8350 loss_val: 1.1777 acc_val: 0.6984 time: 0.0020s\nEpoch: 0106 loss_train: 0.8845 acc_train: 0.8350 loss_val: 1.1745 acc_val: 0.6990 time: 0.0019s\nEpoch: 0107 loss_train: 0.8796 acc_train: 0.8362 loss_val: 1.1714 acc_val: 0.6990 time: 0.0020s\nEpoch: 0108 loss_train: 0.8748 acc_train: 0.8362 loss_val: 1.1684 acc_val: 0.6996 time: 0.0019s\nEpoch: 0109 loss_train: 0.8700 acc_train: 0.8362 loss_val: 1.1654 acc_val: 0.6996 time: 0.0020s\nEpoch: 0110 loss_train: 0.8653 acc_train: 0.8374 loss_val: 1.1625 acc_val: 0.6996 time: 0.0019s\nEpoch: 0111 loss_train: 0.8606 acc_train: 0.8374 loss_val: 1.1596 acc_val: 0.6996 time: 0.0020s\nEpoch: 0112 loss_train: 0.8560 acc_train: 0.8386 loss_val: 1.1567 acc_val: 0.7008 time: 0.0019s\nEpoch: 0113 loss_train: 0.8515 acc_train: 0.8386 loss_val: 1.1539 acc_val: 0.7002 time: 0.0020s\nEpoch: 0114 loss_train: 0.8470 acc_train: 0.8386 loss_val: 1.1512 acc_val: 0.7015 time: 0.0020s\nEpoch: 0115 loss_train: 0.8426 acc_train: 0.8386 loss_val: 1.1484 acc_val: 0.7015 time: 0.0020s\nEpoch: 0116 loss_train: 0.8382 acc_train: 0.8386 loss_val: 1.1458 acc_val: 0.7015 time: 0.0019s\nEpoch: 0117 loss_train: 0.8339 acc_train: 0.8374 loss_val: 1.1431 acc_val: 0.7015 time: 0.0020s\nEpoch: 0118 loss_train: 0.8296 acc_train: 0.8374 loss_val: 1.1406 acc_val: 0.7027 time: 0.0019s\nEpoch: 0119 loss_train: 0.8253 acc_train: 0.8374 loss_val: 1.1380 acc_val: 0.7021 time: 0.0019s\nEpoch: 0120 loss_train: 0.8212 acc_train: 0.8374 loss_val: 1.1355 acc_val: 0.7021 time: 0.0019s\nEpoch: 0121 loss_train: 0.8170 acc_train: 0.8374 loss_val: 1.1330 acc_val: 0.7021 time: 0.0019s\nEpoch: 0122 loss_train: 0.8129 acc_train: 0.8386 loss_val: 1.1306 acc_val: 0.7008 time: 0.0019s\nEpoch: 0123 loss_train: 0.8089 acc_train: 0.8386 loss_val: 1.1282 acc_val: 0.7002 time: 0.0019s\nEpoch: 0124 loss_train: 0.8049 acc_train: 0.8386 loss_val: 1.1258 acc_val: 0.7002 time: 0.0019s\nEpoch: 0125 loss_train: 0.8010 acc_train: 0.8398 loss_val: 1.1235 acc_val: 0.7002 time: 0.0019s\nEpoch: 0126 loss_train: 0.7971 acc_train: 0.8398 loss_val: 1.1212 acc_val: 0.7002 time: 0.0019s\nEpoch: 0127 loss_train: 0.7932 acc_train: 0.8386 loss_val: 1.1190 acc_val: 0.7008 time: 0.0019s\nEpoch: 0128 loss_train: 0.7894 acc_train: 0.8398 loss_val: 1.1168 acc_val: 0.7021 time: 0.0019s\nEpoch: 0129 loss_train: 0.7856 acc_train: 0.8410 loss_val: 1.1146 acc_val: 0.7027 time: 0.0019s\nEpoch: 0130 loss_train: 0.7819 acc_train: 0.8410 loss_val: 1.1125 acc_val: 0.7021 time: 0.0019s\nEpoch: 0131 loss_train: 0.7782 acc_train: 0.8410 loss_val: 1.1104 acc_val: 0.7033 time: 0.0020s\nEpoch: 0132 loss_train: 0.7745 acc_train: 0.8410 loss_val: 1.1083 acc_val: 0.7033 time: 0.0020s\nEpoch: 0133 loss_train: 0.7709 acc_train: 0.8410 loss_val: 1.1062 acc_val: 0.7033 time: 0.0019s\nEpoch: 0134 loss_train: 0.7673 acc_train: 0.8422 loss_val: 1.1042 acc_val: 0.7039 time: 0.0020s\nEpoch: 0135 loss_train: 0.7638 acc_train: 0.8422 loss_val: 1.1022 acc_val: 0.7039 time: 0.0019s\nEpoch: 0136 loss_train: 0.7603 acc_train: 0.8422 loss_val: 1.1003 acc_val: 0.7033 time: 0.0019s\nEpoch: 0137 loss_train: 0.7568 acc_train: 0.8422 loss_val: 1.0983 acc_val: 0.7033 time: 0.0019s\nEpoch: 0138 loss_train: 0.7534 acc_train: 0.8447 loss_val: 1.0964 acc_val: 0.7027 time: 0.0020s\nEpoch: 0139 loss_train: 0.7500 acc_train: 0.8447 loss_val: 1.0946 acc_val: 0.7027 time: 0.0019s\nEpoch: 0140 loss_train: 0.7466 acc_train: 0.8459 loss_val: 1.0927 acc_val: 0.7033 time: 0.0020s\nEpoch: 0141 loss_train: 0.7433 acc_train: 0.8459 loss_val: 1.0909 acc_val: 0.7039 time: 0.0020s\nEpoch: 0142 loss_train: 0.7400 acc_train: 0.8459 loss_val: 1.0891 acc_val: 0.7039 time: 0.0020s\nEpoch: 0143 loss_train: 0.7368 acc_train: 0.8471 loss_val: 1.0874 acc_val: 0.7033 time: 0.0020s\nEpoch: 0144 loss_train: 0.7336 acc_train: 0.8471 loss_val: 1.0857 acc_val: 0.7027 time: 0.0020s\nEpoch: 0145 loss_train: 0.7304 acc_train: 0.8483 loss_val: 1.0840 acc_val: 0.7027 time: 0.0020s\nEpoch: 0146 loss_train: 0.7272 acc_train: 0.8483 loss_val: 1.0823 acc_val: 0.7027 time: 0.0020s\nEpoch: 0147 loss_train: 0.7241 acc_train: 0.8483 loss_val: 1.0806 acc_val: 0.7033 time: 0.0019s\nEpoch: 0148 loss_train: 0.7210 acc_train: 0.8519 loss_val: 1.0790 acc_val: 0.7039 time: 0.0019s\nEpoch: 0149 loss_train: 0.7179 acc_train: 0.8519 loss_val: 1.0774 acc_val: 0.7039 time: 0.0019s\nEpoch: 0150 loss_train: 0.7149 acc_train: 0.8532 loss_val: 1.0758 acc_val: 0.7039 time: 0.0019s\nEpoch: 0151 loss_train: 0.7118 acc_train: 0.8532 loss_val: 1.0743 acc_val: 0.7039 time: 0.0019s\nEpoch: 0152 loss_train: 0.7089 acc_train: 0.8544 loss_val: 1.0727 acc_val: 0.7045 time: 0.0019s\nEpoch: 0153 loss_train: 0.7059 acc_train: 0.8556 loss_val: 1.0712 acc_val: 0.7045 time: 0.0019s\nEpoch: 0154 loss_train: 0.7030 acc_train: 0.8568 loss_val: 1.0697 acc_val: 0.7045 time: 0.0019s\nEpoch: 0155 loss_train: 0.7001 acc_train: 0.8580 loss_val: 1.0683 acc_val: 0.7045 time: 0.0019s\nEpoch: 0156 loss_train: 0.6972 acc_train: 0.8580 loss_val: 1.0668 acc_val: 0.7051 time: 0.0019s\nEpoch: 0157 loss_train: 0.6944 acc_train: 0.8580 loss_val: 1.0654 acc_val: 0.7057 time: 0.0018s\nEpoch: 0158 loss_train: 0.6916 acc_train: 0.8592 loss_val: 1.0640 acc_val: 0.7057 time: 0.0019s\nEpoch: 0159 loss_train: 0.6888 acc_train: 0.8592 loss_val: 1.0626 acc_val: 0.7063 time: 0.0019s\nEpoch: 0160 loss_train: 0.6860 acc_train: 0.8617 loss_val: 1.0613 acc_val: 0.7057 time: 0.0019s\nEpoch: 0161 loss_train: 0.6833 acc_train: 0.8617 loss_val: 1.0599 acc_val: 0.7057 time: 0.0018s\nEpoch: 0162 loss_train: 0.6805 acc_train: 0.8617 loss_val: 1.0586 acc_val: 0.7057 time: 0.0020s\nEpoch: 0163 loss_train: 0.6778 acc_train: 0.8617 loss_val: 1.0573 acc_val: 0.7063 time: 0.0019s\nEpoch: 0164 loss_train: 0.6752 acc_train: 0.8641 loss_val: 1.0560 acc_val: 0.7063 time: 0.0020s\nEpoch: 0165 loss_train: 0.6725 acc_train: 0.8641 loss_val: 1.0548 acc_val: 0.7069 time: 0.0019s\nEpoch: 0166 loss_train: 0.6699 acc_train: 0.8641 loss_val: 1.0535 acc_val: 0.7063 time: 0.0019s\nEpoch: 0167 loss_train: 0.6673 acc_train: 0.8653 loss_val: 1.0523 acc_val: 0.7063 time: 0.0019s\nEpoch: 0168 loss_train: 0.6647 acc_train: 0.8653 loss_val: 1.0511 acc_val: 0.7057 time: 0.0020s\nEpoch: 0169 loss_train: 0.6622 acc_train: 0.8653 loss_val: 1.0499 acc_val: 0.7057 time: 0.0019s\nEpoch: 0170 loss_train: 0.6597 acc_train: 0.8653 loss_val: 1.0487 acc_val: 0.7045 time: 0.0020s\nEpoch: 0171 loss_train: 0.6572 acc_train: 0.8653 loss_val: 1.0476 acc_val: 0.7045 time: 0.0019s\nEpoch: 0172 loss_train: 0.6547 acc_train: 0.8665 loss_val: 1.0464 acc_val: 0.7045 time: 0.0020s\nEpoch: 0173 loss_train: 0.6522 acc_train: 0.8665 loss_val: 1.0453 acc_val: 0.7045 time: 0.0019s\nEpoch: 0174 loss_train: 0.6498 acc_train: 0.8665 loss_val: 1.0442 acc_val: 0.7045 time: 0.0019s\nEpoch: 0175 loss_train: 0.6473 acc_train: 0.8665 loss_val: 1.0431 acc_val: 0.7039 time: 0.0019s\nEpoch: 0176 loss_train: 0.6449 acc_train: 0.8665 loss_val: 1.0421 acc_val: 0.7039 time: 0.0019s\nEpoch: 0177 loss_train: 0.6425 acc_train: 0.8677 loss_val: 1.0410 acc_val: 0.7057 time: 0.0019s\nEpoch: 0178 loss_train: 0.6402 acc_train: 0.8677 loss_val: 1.0400 acc_val: 0.7057 time: 0.0019s\nEpoch: 0179 loss_train: 0.6378 acc_train: 0.8665 loss_val: 1.0389 acc_val: 0.7051 time: 0.0019s\nEpoch: 0180 loss_train: 0.6355 acc_train: 0.8665 loss_val: 1.0379 acc_val: 0.7063 time: 0.0019s\nEpoch: 0181 loss_train: 0.6332 acc_train: 0.8665 loss_val: 1.0369 acc_val: 0.7063 time: 0.0019s\nEpoch: 0182 loss_train: 0.6309 acc_train: 0.8665 loss_val: 1.0360 acc_val: 0.7063 time: 0.0019s\nEpoch: 0183 loss_train: 0.6286 acc_train: 0.8665 loss_val: 1.0350 acc_val: 0.7051 time: 0.0019s\nEpoch: 0184 loss_train: 0.6264 acc_train: 0.8677 loss_val: 1.0341 acc_val: 0.7051 time: 0.0018s\nEpoch: 0185 loss_train: 0.6242 acc_train: 0.8677 loss_val: 1.0331 acc_val: 0.7051 time: 0.0019s\nEpoch: 0186 loss_train: 0.6219 acc_train: 0.8677 loss_val: 1.0322 acc_val: 0.7051 time: 0.0018s\nEpoch: 0187 loss_train: 0.6197 acc_train: 0.8689 loss_val: 1.0313 acc_val: 0.7051 time: 0.0019s\nEpoch: 0188 loss_train: 0.6176 acc_train: 0.8689 loss_val: 1.0304 acc_val: 0.7051 time: 0.0019s\nEpoch: 0189 loss_train: 0.6154 acc_train: 0.8689 loss_val: 1.0295 acc_val: 0.7051 time: 0.0020s\nEpoch: 0190 loss_train: 0.6133 acc_train: 0.8689 loss_val: 1.0287 acc_val: 0.7051 time: 0.0019s\nEpoch: 0191 loss_train: 0.6111 acc_train: 0.8701 loss_val: 1.0278 acc_val: 0.7051 time: 0.0020s\nEpoch: 0192 loss_train: 0.6090 acc_train: 0.8701 loss_val: 1.0270 acc_val: 0.7045 time: 0.0019s\nEpoch: 0193 loss_train: 0.6069 acc_train: 0.8714 loss_val: 1.0261 acc_val: 0.7045 time: 0.0020s\nEpoch: 0194 loss_train: 0.6048 acc_train: 0.8714 loss_val: 1.0253 acc_val: 0.7033 time: 0.0019s\nEpoch: 0195 loss_train: 0.6028 acc_train: 0.8714 loss_val: 1.0245 acc_val: 0.7045 time: 0.0020s\nEpoch: 0196 loss_train: 0.6007 acc_train: 0.8726 loss_val: 1.0237 acc_val: 0.7045 time: 0.0020s\nEpoch: 0197 loss_train: 0.5987 acc_train: 0.8726 loss_val: 1.0230 acc_val: 0.7045 time: 0.0022s\nEpoch: 0198 loss_train: 0.5967 acc_train: 0.8750 loss_val: 1.0222 acc_val: 0.7051 time: 0.0022s\nEpoch: 0199 loss_train: 0.5947 acc_train: 0.8750 loss_val: 1.0215 acc_val: 0.7039 time: 0.0020s\nEpoch: 0200 loss_train: 0.5927 acc_train: 0.8762 loss_val: 1.0207 acc_val: 0.7033 time: 0.0020s\nEpoch: 0001 loss_train: 0.5907 acc_train: 0.8762 loss_val: 1.0207 acc_val: 0.7033 time: 0.0016s\nRanking optimizing... \nNow Average ERR@k =  0.47347623109817505\nEpoch: 0002 loss_train: 0.5888 acc_train: 0.8786 loss_val: 1.0200 acc_val: 0.7039 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.47342896461486816\nEpoch: 0003 loss_train: 0.5868 acc_train: 0.8799 loss_val: 1.0193 acc_val: 0.7033 time: 0.0038s\nRanking optimizing... \nNow Average ERR@k =  0.4736282229423523\nEpoch: 0004 loss_train: 0.5849 acc_train: 0.8799 loss_val: 1.0186 acc_val: 0.7021 time: 0.0040s\nRanking optimizing... \nNow Average ERR@k =  0.47405365109443665\nEpoch: 0005 loss_train: 0.5830 acc_train: 0.8811 loss_val: 1.0180 acc_val: 0.7015 time: 0.0054s\nRanking optimizing... \nNow Average ERR@k =  0.4746839702129364\nEpoch: 0006 loss_train: 0.5812 acc_train: 0.8823 loss_val: 1.0174 acc_val: 0.7021 time: 0.0035s\nRanking optimizing... \nNow Average ERR@k =  0.4754335582256317\nEpoch: 0007 loss_train: 0.5794 acc_train: 0.8823 loss_val: 1.0168 acc_val: 0.7021 time: 0.0036s\nRanking optimizing... \nNow Average ERR@k =  0.47593316435813904\nEpoch: 0008 loss_train: 0.5776 acc_train: 0.8823 loss_val: 1.0163 acc_val: 0.7021 time: 0.0056s\nRanking optimizing... \nNow Average ERR@k =  0.47616949677467346\nEpoch: 0009 loss_train: 0.5759 acc_train: 0.8835 loss_val: 1.0158 acc_val: 0.7021 time: 0.0052s\nRanking optimizing... \nNow Average ERR@k =  0.4766171872615814\nEpoch: 0010 loss_train: 0.5742 acc_train: 0.8835 loss_val: 1.0154 acc_val: 0.7021 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.47770926356315613\nEpoch: 0011 loss_train: 0.5726 acc_train: 0.8835 loss_val: 1.0150 acc_val: 0.7002 time: 0.0057s\nRanking optimizing... \nNow Average ERR@k =  0.47849076986312866\nEpoch: 0012 loss_train: 0.5710 acc_train: 0.8823 loss_val: 1.0147 acc_val: 0.7002 time: 0.0033s\nRanking optimizing... \nNow Average ERR@k =  0.4790646731853485\nEpoch: 0013 loss_train: 0.5694 acc_train: 0.8847 loss_val: 1.0144 acc_val: 0.7027 time: 0.0037s\nRanking optimizing... \nNow Average ERR@k =  0.4794646203517914\nEpoch: 0014 loss_train: 0.5679 acc_train: 0.8847 loss_val: 1.0141 acc_val: 0.7027 time: 0.0059s\nRanking optimizing... \nNow Average ERR@k =  0.47976070642471313\nEpoch: 0015 loss_train: 0.5664 acc_train: 0.8859 loss_val: 1.0139 acc_val: 0.7015 time: 0.0037s\nRanking optimizing... \nNow Average ERR@k =  0.48042288422584534\nEpoch: 0016 loss_train: 0.5650 acc_train: 0.8859 loss_val: 1.0138 acc_val: 0.7015 time: 0.0036s\nRanking optimizing... \nNow Average ERR@k =  0.4812559485435486\nEpoch: 0017 loss_train: 0.5636 acc_train: 0.8871 loss_val: 1.0137 acc_val: 0.7027 time: 0.0036s\nRanking optimizing... \nNow Average ERR@k =  0.48147183656692505\nEpoch: 0018 loss_train: 0.5622 acc_train: 0.8871 loss_val: 1.0136 acc_val: 0.7027 time: 0.0033s\nRanking optimizing... \nNow Average ERR@k =  0.4822085499763489\nEpoch: 0019 loss_train: 0.5608 acc_train: 0.8871 loss_val: 1.0135 acc_val: 0.7027 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.48284658789634705\nEpoch: 0020 loss_train: 0.5595 acc_train: 0.8871 loss_val: 1.0135 acc_val: 0.7027 time: 0.0051s\nRanking optimizing... \nNow Average ERR@k =  0.48362913727760315\nEpoch: 0021 loss_train: 0.5581 acc_train: 0.8883 loss_val: 1.0135 acc_val: 0.7027 time: 0.0033s\nRanking optimizing... \nNow Average ERR@k =  0.4839136302471161\nEpoch: 0022 loss_train: 0.5569 acc_train: 0.8908 loss_val: 1.0136 acc_val: 0.7027 time: 0.0032s\nRanking optimizing... \nNow Average ERR@k =  0.48459765315055847\nEpoch: 0023 loss_train: 0.5556 acc_train: 0.8920 loss_val: 1.0136 acc_val: 0.7002 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.4847879409790039\nEpoch: 0024 loss_train: 0.5543 acc_train: 0.8920 loss_val: 1.0137 acc_val: 0.7008 time: 0.0037s\nRanking optimizing... \nNow Average ERR@k =  0.48465269804000854\nEpoch: 0025 loss_train: 0.5531 acc_train: 0.8920 loss_val: 1.0138 acc_val: 0.6996 time: 0.0042s\nRanking optimizing... \nNow Average ERR@k =  0.4847762882709503\nEpoch: 0026 loss_train: 0.5519 acc_train: 0.8920 loss_val: 1.0139 acc_val: 0.7002 time: 0.0027s\nRanking optimizing... \nNow Average ERR@k =  0.4849260151386261\nEpoch: 0027 loss_train: 0.5508 acc_train: 0.8908 loss_val: 1.0141 acc_val: 0.7002 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.4853666126728058\nEpoch: 0028 loss_train: 0.5496 acc_train: 0.8920 loss_val: 1.0142 acc_val: 0.7002 time: 0.0049s\nRanking optimizing... \nNow Average ERR@k =  0.4859374463558197\nEpoch: 0029 loss_train: 0.5485 acc_train: 0.8920 loss_val: 1.0144 acc_val: 0.6984 time: 0.0035s\nRanking optimizing... \nNow Average ERR@k =  0.4863585829734802\nEpoch: 0030 loss_train: 0.5473 acc_train: 0.8920 loss_val: 1.0145 acc_val: 0.6978 time: 0.0035s\nRanking optimizing... \nNow Average ERR@k =  0.486801415681839\nEpoch: 0031 loss_train: 0.5462 acc_train: 0.8932 loss_val: 1.0147 acc_val: 0.6978 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.48724445700645447\nEpoch: 0032 loss_train: 0.5451 acc_train: 0.8944 loss_val: 1.0148 acc_val: 0.6978 time: 0.0035s\nRanking optimizing... \nNow Average ERR@k =  0.4878624677658081\nEpoch: 0033 loss_train: 0.5440 acc_train: 0.8944 loss_val: 1.0150 acc_val: 0.6972 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.48899728059768677\nEpoch: 0034 loss_train: 0.5429 acc_train: 0.8944 loss_val: 1.0152 acc_val: 0.6960 time: 0.0029s\nRanking optimizing... \nNow Average ERR@k =  0.48921191692352295\nEpoch: 0035 loss_train: 0.5418 acc_train: 0.8944 loss_val: 1.0153 acc_val: 0.6960 time: 0.0037s\nRanking optimizing... \nNow Average ERR@k =  0.48937568068504333\nEpoch: 0036 loss_train: 0.5408 acc_train: 0.8956 loss_val: 1.0155 acc_val: 0.6960 time: 0.0026s\nRanking optimizing... \nNow Average ERR@k =  0.48970505595207214\nEpoch: 0037 loss_train: 0.5397 acc_train: 0.8956 loss_val: 1.0156 acc_val: 0.6972 time: 0.0033s\nRanking optimizing... \nNow Average ERR@k =  0.48997628688812256\nEpoch: 0038 loss_train: 0.5386 acc_train: 0.8968 loss_val: 1.0158 acc_val: 0.6960 time: 0.0033s\nRanking optimizing... \nNow Average ERR@k =  0.4906100332736969\nEpoch: 0039 loss_train: 0.5376 acc_train: 0.8968 loss_val: 1.0159 acc_val: 0.6960 time: 0.0036s\nRanking optimizing... \nNow Average ERR@k =  0.490748792886734\nEpoch: 0040 loss_train: 0.5365 acc_train: 0.8968 loss_val: 1.0161 acc_val: 0.6960 time: 0.0028s\nRanking optimizing... \nNow Average ERR@k =  0.4910202920436859\nEpoch: 0041 loss_train: 0.5355 acc_train: 0.8968 loss_val: 1.0162 acc_val: 0.6948 time: 0.0042s\nRanking optimizing... \nNow Average ERR@k =  0.4913906157016754\nEpoch: 0042 loss_train: 0.5345 acc_train: 0.8968 loss_val: 1.0163 acc_val: 0.6942 time: 0.0021s\nRanking optimizing... \nNow Average ERR@k =  0.4918118417263031\nEpoch: 0043 loss_train: 0.5335 acc_train: 0.8968 loss_val: 1.0165 acc_val: 0.6948 time: 0.0056s\nRanking optimizing... \nNow Average ERR@k =  0.4919314682483673\nEpoch: 0044 loss_train: 0.5325 acc_train: 0.8968 loss_val: 1.0166 acc_val: 0.6948 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.4922613203525543\nEpoch: 0045 loss_train: 0.5315 acc_train: 0.8981 loss_val: 1.0167 acc_val: 0.6948 time: 0.0035s\nRanking optimizing... \nNow Average ERR@k =  0.4922424554824829\nEpoch: 0046 loss_train: 0.5306 acc_train: 0.8981 loss_val: 1.0167 acc_val: 0.6948 time: 0.0046s\nRanking optimizing... \nNow Average ERR@k =  0.49192363023757935\nEpoch: 0047 loss_train: 0.5296 acc_train: 0.8993 loss_val: 1.0168 acc_val: 0.6942 time: 0.0029s\nRanking optimizing... \nNow Average ERR@k =  0.49248456954956055\nEpoch: 0048 loss_train: 0.5287 acc_train: 0.8993 loss_val: 1.0169 acc_val: 0.6942 time: 0.0029s\nRanking optimizing... \nNow Average ERR@k =  0.4925234019756317\nEpoch: 0049 loss_train: 0.5277 acc_train: 0.8993 loss_val: 1.0170 acc_val: 0.6942 time: 0.0034s\nRanking optimizing... \nNow Average ERR@k =  0.4928485155105591\nEpoch: 0050 loss_train: 0.5268 acc_train: 0.8993 loss_val: 1.0171 acc_val: 0.6954 time: 0.0036s\nRanking optimizing... \nNow Average ERR@k =  0.49331557750701904\nTest set results: loss= 1.0435 accuracy= 0.6841\n"], ["node classification", "structural", "ERR", "ACM", "GCN", "ACM\nUsing ACM dataset\nstart\nfinished\nEpoch: 0001 loss_train: 2.2132 acc_train: 0.1177 loss_val: 2.2135 acc_val: 0.1244 time: 0.8788s\nRanking optimizing... \nNow Average ERR@k =  0.24533455073833466\nEpoch: 0002 loss_train: 2.1847 acc_train: 0.1614 loss_val: 2.1900 acc_val: 0.1566 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.2457105815410614\nEpoch: 0003 loss_train: 2.1609 acc_train: 0.1917 loss_val: 2.1681 acc_val: 0.1942 time: 0.0094s\nRanking optimizing... \nNow Average ERR@k =  0.2521750032901764\nEpoch: 0004 loss_train: 2.1370 acc_train: 0.2391 loss_val: 2.1474 acc_val: 0.2342 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.260146826505661\nEpoch: 0005 loss_train: 2.1141 acc_train: 0.2706 loss_val: 2.1275 acc_val: 0.2725 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.2676529884338379\nEpoch: 0006 loss_train: 2.0926 acc_train: 0.2985 loss_val: 2.1081 acc_val: 0.3010 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.2683471441268921\nEpoch: 0007 loss_train: 2.0720 acc_train: 0.3301 loss_val: 2.0893 acc_val: 0.3428 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.2714273929595947\nEpoch: 0008 loss_train: 2.0507 acc_train: 0.3665 loss_val: 2.0708 acc_val: 0.3756 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.2757166624069214\nEpoch: 0009 loss_train: 2.0304 acc_train: 0.3823 loss_val: 2.0523 acc_val: 0.3908 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.2787116467952728\nEpoch: 0010 loss_train: 2.0117 acc_train: 0.4187 loss_val: 2.0340 acc_val: 0.4078 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.2789330780506134\nEpoch: 0011 loss_train: 1.9856 acc_train: 0.4308 loss_val: 2.0150 acc_val: 0.4217 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.2854135036468506\nEpoch: 0012 loss_train: 1.9681 acc_train: 0.4430 loss_val: 1.9957 acc_val: 0.4411 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.28857341408729553\nEpoch: 0013 loss_train: 1.9476 acc_train: 0.4709 loss_val: 1.9760 acc_val: 0.4636 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.299260675907135\nEpoch: 0014 loss_train: 1.9229 acc_train: 0.5194 loss_val: 1.9559 acc_val: 0.4982 time: 0.0103s\nRanking optimizing... \nNow Average ERR@k =  0.30218014121055603\nEpoch: 0015 loss_train: 1.8977 acc_train: 0.5473 loss_val: 1.9356 acc_val: 0.5273 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.3070097267627716\nEpoch: 0016 loss_train: 1.8756 acc_train: 0.5485 loss_val: 1.9151 acc_val: 0.5564 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.30864930152893066\nEpoch: 0017 loss_train: 1.8585 acc_train: 0.5813 loss_val: 1.8945 acc_val: 0.5728 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.3118512034416199\nEpoch: 0018 loss_train: 1.8318 acc_train: 0.6044 loss_val: 1.8737 acc_val: 0.5898 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.3137071132659912\nEpoch: 0019 loss_train: 1.8093 acc_train: 0.6153 loss_val: 1.8528 acc_val: 0.6007 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.3219478130340576\nEpoch: 0020 loss_train: 1.7822 acc_train: 0.6347 loss_val: 1.8321 acc_val: 0.6092 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3176640570163727\nEpoch: 0021 loss_train: 1.7599 acc_train: 0.6517 loss_val: 1.8113 acc_val: 0.6165 time: 0.0100s\nRanking optimizing... \nNow Average ERR@k =  0.32106366753578186\nEpoch: 0022 loss_train: 1.7403 acc_train: 0.6420 loss_val: 1.7902 acc_val: 0.6208 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.3257139027118683\nEpoch: 0023 loss_train: 1.7160 acc_train: 0.6481 loss_val: 1.7687 acc_val: 0.6262 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.32828766107559204\nEpoch: 0024 loss_train: 1.6855 acc_train: 0.6663 loss_val: 1.7466 acc_val: 0.6292 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3200784921646118\nEpoch: 0025 loss_train: 1.6624 acc_train: 0.6735 loss_val: 1.7239 acc_val: 0.6311 time: 0.0063s\nRanking optimizing... \nNow Average ERR@k =  0.3282005786895752\nEpoch: 0026 loss_train: 1.6351 acc_train: 0.6735 loss_val: 1.7012 acc_val: 0.6341 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3298722505569458\nEpoch: 0027 loss_train: 1.6096 acc_train: 0.6675 loss_val: 1.6781 acc_val: 0.6414 time: 0.0064s\nRanking optimizing... \nNow Average ERR@k =  0.3291495442390442\nEpoch: 0028 loss_train: 1.5772 acc_train: 0.6820 loss_val: 1.6543 acc_val: 0.6402 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.3297024667263031\nEpoch: 0029 loss_train: 1.5575 acc_train: 0.6881 loss_val: 1.6303 acc_val: 0.6408 time: 0.0062s\nRanking optimizing... \nNow Average ERR@k =  0.33178356289863586\nEpoch: 0030 loss_train: 1.5281 acc_train: 0.6917 loss_val: 1.6063 acc_val: 0.6432 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.3292197287082672\nEpoch: 0031 loss_train: 1.4992 acc_train: 0.6845 loss_val: 1.5819 acc_val: 0.6450 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.3245909512042999\nEpoch: 0032 loss_train: 1.4625 acc_train: 0.7051 loss_val: 1.5572 acc_val: 0.6505 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3291700482368469\nEpoch: 0033 loss_train: 1.4415 acc_train: 0.7039 loss_val: 1.5323 acc_val: 0.6499 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3299788534641266\nEpoch: 0034 loss_train: 1.4159 acc_train: 0.7087 loss_val: 1.5070 acc_val: 0.6511 time: 0.0078s\nRanking optimizing... \nNow Average ERR@k =  0.3334263265132904\nEpoch: 0035 loss_train: 1.3879 acc_train: 0.7063 loss_val: 1.4821 acc_val: 0.6529 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3277793228626251\nEpoch: 0036 loss_train: 1.3543 acc_train: 0.7087 loss_val: 1.4571 acc_val: 0.6572 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.33514314889907837\nEpoch: 0037 loss_train: 1.3417 acc_train: 0.7197 loss_val: 1.4325 acc_val: 0.6632 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.32930365204811096\nEpoch: 0038 loss_train: 1.3093 acc_train: 0.7148 loss_val: 1.4078 acc_val: 0.6644 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.33289477229118347\nEpoch: 0039 loss_train: 1.2853 acc_train: 0.7221 loss_val: 1.3833 acc_val: 0.6669 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.33290648460388184\nEpoch: 0040 loss_train: 1.2417 acc_train: 0.7221 loss_val: 1.3592 acc_val: 0.6711 time: 0.0077s\nRanking optimizing... \nNow Average ERR@k =  0.33324623107910156\nEpoch: 0041 loss_train: 1.2148 acc_train: 0.7294 loss_val: 1.3357 acc_val: 0.6742 time: 0.0077s\nRanking optimizing... \nNow Average ERR@k =  0.3325832784175873\nEpoch: 0042 loss_train: 1.2015 acc_train: 0.7209 loss_val: 1.3127 acc_val: 0.6754 time: 0.0075s\nRanking optimizing... \nNow Average ERR@k =  0.3349079489707947\nEpoch: 0043 loss_train: 1.1648 acc_train: 0.7379 loss_val: 1.2902 acc_val: 0.6778 time: 0.0076s\nRanking optimizing... \nNow Average ERR@k =  0.3332380950450897\nEpoch: 0044 loss_train: 1.1536 acc_train: 0.7294 loss_val: 1.2684 acc_val: 0.6778 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.33412209153175354\nEpoch: 0045 loss_train: 1.1262 acc_train: 0.7379 loss_val: 1.2471 acc_val: 0.6802 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.3357641100883484\nEpoch: 0046 loss_train: 1.1094 acc_train: 0.7233 loss_val: 1.2268 acc_val: 0.6833 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.3341306746006012\nEpoch: 0047 loss_train: 1.0756 acc_train: 0.7464 loss_val: 1.2069 acc_val: 0.6845 time: 0.0098s\nRanking optimizing... \nNow Average ERR@k =  0.33538082242012024\nEpoch: 0048 loss_train: 1.0561 acc_train: 0.7318 loss_val: 1.1883 acc_val: 0.6863 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.3363530933856964\nEpoch: 0049 loss_train: 1.0438 acc_train: 0.7439 loss_val: 1.1703 acc_val: 0.6869 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.33682554960250854\nEpoch: 0050 loss_train: 1.0227 acc_train: 0.7597 loss_val: 1.1528 acc_val: 0.6851 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.3399054706096649\nEpoch: 0051 loss_train: 1.0106 acc_train: 0.7427 loss_val: 1.1359 acc_val: 0.6869 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.33365321159362793\nEpoch: 0052 loss_train: 0.9795 acc_train: 0.7451 loss_val: 1.1198 acc_val: 0.6887 time: 0.0093s\nRanking optimizing... \nNow Average ERR@k =  0.3328058421611786\nEpoch: 0053 loss_train: 0.9557 acc_train: 0.7633 loss_val: 1.1045 acc_val: 0.6899 time: 0.0066s\nRanking optimizing... \nNow Average ERR@k =  0.3365383446216583\nEpoch: 0054 loss_train: 0.9452 acc_train: 0.7573 loss_val: 1.0897 acc_val: 0.6905 time: 0.0122s\nRanking optimizing... \nNow Average ERR@k =  0.3342674672603607\nEpoch: 0055 loss_train: 0.9299 acc_train: 0.7597 loss_val: 1.0759 acc_val: 0.6911 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.3325099050998688\nEpoch: 0056 loss_train: 0.9132 acc_train: 0.7718 loss_val: 1.0631 acc_val: 0.6924 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.3366686701774597\nEpoch: 0057 loss_train: 0.8862 acc_train: 0.7743 loss_val: 1.0512 acc_val: 0.6911 time: 0.0104s\nRanking optimizing... \nNow Average ERR@k =  0.3374083936214447\nEpoch: 0058 loss_train: 0.8785 acc_train: 0.7706 loss_val: 1.0399 acc_val: 0.6905 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3377096354961395\nEpoch: 0059 loss_train: 0.8608 acc_train: 0.7718 loss_val: 1.0296 acc_val: 0.6911 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.33968663215637207\nEpoch: 0060 loss_train: 0.8515 acc_train: 0.7840 loss_val: 1.0198 acc_val: 0.6930 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.33474424481391907\nEpoch: 0061 loss_train: 0.8363 acc_train: 0.7816 loss_val: 1.0104 acc_val: 0.6960 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3375578820705414\nEpoch: 0062 loss_train: 0.8330 acc_train: 0.7682 loss_val: 1.0019 acc_val: 0.6960 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.33857572078704834\nEpoch: 0063 loss_train: 0.8233 acc_train: 0.7706 loss_val: 0.9937 acc_val: 0.6966 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3374612331390381\nEpoch: 0064 loss_train: 0.8021 acc_train: 0.7876 loss_val: 0.9858 acc_val: 0.6972 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.3397846519947052\nEpoch: 0065 loss_train: 0.7975 acc_train: 0.7973 loss_val: 0.9781 acc_val: 0.6978 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.34281137585639954\nEpoch: 0066 loss_train: 0.7796 acc_train: 0.7961 loss_val: 0.9710 acc_val: 0.6996 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.34208616614341736\nEpoch: 0067 loss_train: 0.7657 acc_train: 0.7852 loss_val: 0.9644 acc_val: 0.7008 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.34258419275283813\nEpoch: 0068 loss_train: 0.7767 acc_train: 0.7791 loss_val: 0.9583 acc_val: 0.7008 time: 0.0078s\nRanking optimizing... \nNow Average ERR@k =  0.3447170853614807\nEpoch: 0069 loss_train: 0.7479 acc_train: 0.7949 loss_val: 0.9524 acc_val: 0.7015 time: 0.0099s\nRanking optimizing... \nNow Average ERR@k =  0.344875305891037\nEpoch: 0070 loss_train: 0.7563 acc_train: 0.7985 loss_val: 0.9470 acc_val: 0.7008 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.3436414301395416\nEpoch: 0071 loss_train: 0.7447 acc_train: 0.7937 loss_val: 0.9418 acc_val: 0.7015 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.3451555073261261\nEpoch: 0072 loss_train: 0.7267 acc_train: 0.8131 loss_val: 0.9371 acc_val: 0.7021 time: 0.0113s\nRanking optimizing... \nNow Average ERR@k =  0.3422740697860718\nEpoch: 0073 loss_train: 0.7230 acc_train: 0.7937 loss_val: 0.9326 acc_val: 0.7021 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.34557947516441345\nEpoch: 0074 loss_train: 0.7083 acc_train: 0.8022 loss_val: 0.9288 acc_val: 0.7021 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.3417535126209259\nEpoch: 0075 loss_train: 0.7195 acc_train: 0.7961 loss_val: 0.9254 acc_val: 0.7015 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.3469824492931366\nEpoch: 0076 loss_train: 0.7071 acc_train: 0.7961 loss_val: 0.9221 acc_val: 0.7027 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.3508375287055969\nEpoch: 0077 loss_train: 0.6930 acc_train: 0.8010 loss_val: 0.9190 acc_val: 0.6990 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.34781351685523987\nEpoch: 0078 loss_train: 0.6982 acc_train: 0.7913 loss_val: 0.9162 acc_val: 0.6990 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.3472044765949249\nEpoch: 0079 loss_train: 0.6954 acc_train: 0.8034 loss_val: 0.9136 acc_val: 0.6984 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.3467237949371338\nEpoch: 0080 loss_train: 0.6779 acc_train: 0.8119 loss_val: 0.9113 acc_val: 0.7002 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.35062867403030396\nEpoch: 0081 loss_train: 0.6615 acc_train: 0.8022 loss_val: 0.9089 acc_val: 0.6996 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.35043197870254517\nEpoch: 0082 loss_train: 0.6651 acc_train: 0.7985 loss_val: 0.9066 acc_val: 0.6966 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.3473905622959137\nEpoch: 0083 loss_train: 0.6654 acc_train: 0.8058 loss_val: 0.9044 acc_val: 0.6984 time: 0.0098s\nRanking optimizing... \nNow Average ERR@k =  0.3502095937728882\nEpoch: 0084 loss_train: 0.6475 acc_train: 0.8180 loss_val: 0.9025 acc_val: 0.7002 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.3495556712150574\nEpoch: 0085 loss_train: 0.6491 acc_train: 0.8095 loss_val: 0.9003 acc_val: 0.7008 time: 0.0100s\nRanking optimizing... \nNow Average ERR@k =  0.3534291684627533\nEpoch: 0086 loss_train: 0.6606 acc_train: 0.8070 loss_val: 0.8984 acc_val: 0.7021 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.35165512561798096\nEpoch: 0087 loss_train: 0.6523 acc_train: 0.8046 loss_val: 0.8965 acc_val: 0.7039 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.35300660133361816\nEpoch: 0088 loss_train: 0.6321 acc_train: 0.8192 loss_val: 0.8949 acc_val: 0.7039 time: 0.0059s\nRanking optimizing... \nNow Average ERR@k =  0.35190361738204956\nEpoch: 0089 loss_train: 0.6367 acc_train: 0.8119 loss_val: 0.8935 acc_val: 0.7057 time: 0.0058s\nRanking optimizing... \nNow Average ERR@k =  0.35462406277656555\nEpoch: 0090 loss_train: 0.6174 acc_train: 0.8131 loss_val: 0.8920 acc_val: 0.7069 time: 0.0062s\nRanking optimizing... \nNow Average ERR@k =  0.35763368010520935\nEpoch: 0091 loss_train: 0.6237 acc_train: 0.8167 loss_val: 0.8908 acc_val: 0.7087 time: 0.0057s\nRanking optimizing... \nNow Average ERR@k =  0.3567705452442169\nEpoch: 0092 loss_train: 0.5962 acc_train: 0.8228 loss_val: 0.8898 acc_val: 0.7087 time: 0.0087s\nRanking optimizing... \nNow Average ERR@k =  0.3554193079471588\nEpoch: 0093 loss_train: 0.6102 acc_train: 0.8192 loss_val: 0.8892 acc_val: 0.7093 time: 0.0099s\nRanking optimizing... \nNow Average ERR@k =  0.3564654588699341\nEpoch: 0094 loss_train: 0.5986 acc_train: 0.8277 loss_val: 0.8886 acc_val: 0.7100 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.35655462741851807\nEpoch: 0095 loss_train: 0.6032 acc_train: 0.8131 loss_val: 0.8882 acc_val: 0.7081 time: 0.0063s\nRanking optimizing... \nNow Average ERR@k =  0.35513418912887573\nEpoch: 0096 loss_train: 0.5865 acc_train: 0.8398 loss_val: 0.8879 acc_val: 0.7087 time: 0.0061s\nRanking optimizing... \nNow Average ERR@k =  0.35362711548805237\nEpoch: 0097 loss_train: 0.5996 acc_train: 0.8107 loss_val: 0.8876 acc_val: 0.7081 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.3544221818447113\nEpoch: 0098 loss_train: 0.5743 acc_train: 0.8289 loss_val: 0.8876 acc_val: 0.7087 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3544940650463104\nEpoch: 0099 loss_train: 0.6055 acc_train: 0.8240 loss_val: 0.8876 acc_val: 0.7081 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.36138901114463806\nEpoch: 0100 loss_train: 0.5692 acc_train: 0.8362 loss_val: 0.8876 acc_val: 0.7081 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.35640594363212585\nEpoch: 0101 loss_train: 0.5835 acc_train: 0.8301 loss_val: 0.8874 acc_val: 0.7069 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3591282367706299\nEpoch: 0102 loss_train: 0.5596 acc_train: 0.8350 loss_val: 0.8872 acc_val: 0.7069 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.36874908208847046\nEpoch: 0103 loss_train: 0.5606 acc_train: 0.8362 loss_val: 0.8867 acc_val: 0.7063 time: 0.0111s\nRanking optimizing... \nNow Average ERR@k =  0.3565708100795746\nEpoch: 0104 loss_train: 0.5533 acc_train: 0.8313 loss_val: 0.8865 acc_val: 0.7069 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.35939520597457886\nEpoch: 0105 loss_train: 0.5557 acc_train: 0.8350 loss_val: 0.8864 acc_val: 0.7069 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.3593482971191406\nEpoch: 0106 loss_train: 0.5646 acc_train: 0.8301 loss_val: 0.8863 acc_val: 0.7112 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.3620396852493286\nEpoch: 0107 loss_train: 0.5539 acc_train: 0.8277 loss_val: 0.8864 acc_val: 0.7093 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.36283010244369507\nEpoch: 0108 loss_train: 0.5559 acc_train: 0.8410 loss_val: 0.8868 acc_val: 0.7093 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.3591930866241455\nEpoch: 0109 loss_train: 0.5448 acc_train: 0.8447 loss_val: 0.8872 acc_val: 0.7087 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.3638094663619995\nEpoch: 0110 loss_train: 0.5273 acc_train: 0.8495 loss_val: 0.8877 acc_val: 0.7069 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.3646460771560669\nEpoch: 0111 loss_train: 0.5394 acc_train: 0.8337 loss_val: 0.8883 acc_val: 0.7069 time: 0.0075s\nRanking optimizing... \nNow Average ERR@k =  0.364280104637146\nEpoch: 0112 loss_train: 0.5373 acc_train: 0.8495 loss_val: 0.8892 acc_val: 0.7075 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.36125075817108154\nEpoch: 0113 loss_train: 0.5345 acc_train: 0.8422 loss_val: 0.8904 acc_val: 0.7039 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.36501264572143555\nEpoch: 0114 loss_train: 0.5337 acc_train: 0.8544 loss_val: 0.8919 acc_val: 0.7027 time: 0.0094s\nRanking optimizing... \nNow Average ERR@k =  0.3644733726978302\nEpoch: 0115 loss_train: 0.5489 acc_train: 0.8434 loss_val: 0.8936 acc_val: 0.6996 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.3648707866668701\nEpoch: 0116 loss_train: 0.5233 acc_train: 0.8519 loss_val: 0.8949 acc_val: 0.6996 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.36873963475227356\nEpoch: 0117 loss_train: 0.5304 acc_train: 0.8434 loss_val: 0.8961 acc_val: 0.6984 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.36693674325942993\nEpoch: 0118 loss_train: 0.5454 acc_train: 0.8519 loss_val: 0.8967 acc_val: 0.6984 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.36640581488609314\nEpoch: 0119 loss_train: 0.5194 acc_train: 0.8447 loss_val: 0.8972 acc_val: 0.6996 time: 0.0094s\nRanking optimizing... \nNow Average ERR@k =  0.36811137199401855\nEpoch: 0120 loss_train: 0.5077 acc_train: 0.8447 loss_val: 0.8975 acc_val: 0.7002 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.36310672760009766\nEpoch: 0121 loss_train: 0.5300 acc_train: 0.8362 loss_val: 0.8981 acc_val: 0.7015 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.3722820580005646\nEpoch: 0122 loss_train: 0.5029 acc_train: 0.8714 loss_val: 0.8985 acc_val: 0.7021 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.3652242124080658\nEpoch: 0123 loss_train: 0.5063 acc_train: 0.8495 loss_val: 0.8991 acc_val: 0.7021 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3678564429283142\nEpoch: 0124 loss_train: 0.5143 acc_train: 0.8459 loss_val: 0.8995 acc_val: 0.7039 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.37174952030181885\nEpoch: 0125 loss_train: 0.5024 acc_train: 0.8556 loss_val: 0.9004 acc_val: 0.7027 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.3728954493999481\nEpoch: 0126 loss_train: 0.4870 acc_train: 0.8641 loss_val: 0.9014 acc_val: 0.7008 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.36982330679893494\nEpoch: 0127 loss_train: 0.4902 acc_train: 0.8568 loss_val: 0.9026 acc_val: 0.7015 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.37580591440200806\nEpoch: 0128 loss_train: 0.4934 acc_train: 0.8701 loss_val: 0.9041 acc_val: 0.7008 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.37247976660728455\nEpoch: 0129 loss_train: 0.4886 acc_train: 0.8556 loss_val: 0.9056 acc_val: 0.7002 time: 0.0063s\nRanking optimizing... \nNow Average ERR@k =  0.36787259578704834\nEpoch: 0130 loss_train: 0.4849 acc_train: 0.8568 loss_val: 0.9070 acc_val: 0.7008 time: 0.0099s\nRanking optimizing... \nNow Average ERR@k =  0.3690653443336487\nEpoch: 0131 loss_train: 0.4878 acc_train: 0.8532 loss_val: 0.9086 acc_val: 0.7015 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.37473419308662415\nEpoch: 0132 loss_train: 0.4728 acc_train: 0.8592 loss_val: 0.9100 acc_val: 0.7002 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.3680358827114105\nEpoch: 0133 loss_train: 0.4920 acc_train: 0.8483 loss_val: 0.9113 acc_val: 0.6990 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.37459859251976013\nEpoch: 0134 loss_train: 0.4851 acc_train: 0.8459 loss_val: 0.9124 acc_val: 0.6984 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3770107924938202\nEpoch: 0135 loss_train: 0.4813 acc_train: 0.8544 loss_val: 0.9135 acc_val: 0.6972 time: 0.0085s\nRanking optimizing... \nNow Average ERR@k =  0.37441709637641907\nEpoch: 0136 loss_train: 0.4812 acc_train: 0.8410 loss_val: 0.9146 acc_val: 0.6972 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3734232485294342\nEpoch: 0137 loss_train: 0.4595 acc_train: 0.8689 loss_val: 0.9156 acc_val: 0.6966 time: 0.0067s\nRanking optimizing... \nNow Average ERR@k =  0.3750666677951813\nEpoch: 0138 loss_train: 0.4651 acc_train: 0.8556 loss_val: 0.9167 acc_val: 0.6960 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.37853631377220154\nEpoch: 0139 loss_train: 0.4769 acc_train: 0.8580 loss_val: 0.9179 acc_val: 0.6972 time: 0.0088s\nRanking optimizing... \nNow Average ERR@k =  0.3754759430885315\nEpoch: 0140 loss_train: 0.4643 acc_train: 0.8568 loss_val: 0.9189 acc_val: 0.6990 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.3720637261867523\nEpoch: 0141 loss_train: 0.4627 acc_train: 0.8641 loss_val: 0.9199 acc_val: 0.6990 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3767883777618408\nEpoch: 0142 loss_train: 0.4653 acc_train: 0.8701 loss_val: 0.9206 acc_val: 0.7008 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.37506216764450073\nEpoch: 0143 loss_train: 0.4639 acc_train: 0.8507 loss_val: 0.9216 acc_val: 0.6984 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.3758589029312134\nEpoch: 0144 loss_train: 0.4620 acc_train: 0.8641 loss_val: 0.9225 acc_val: 0.6972 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.38069790601730347\nEpoch: 0145 loss_train: 0.4472 acc_train: 0.8665 loss_val: 0.9235 acc_val: 0.6972 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3791695833206177\nEpoch: 0146 loss_train: 0.4569 acc_train: 0.8617 loss_val: 0.9245 acc_val: 0.6972 time: 0.0115s\nRanking optimizing... \nNow Average ERR@k =  0.37787023186683655\nEpoch: 0147 loss_train: 0.4497 acc_train: 0.8556 loss_val: 0.9255 acc_val: 0.6978 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3734402656555176\nEpoch: 0148 loss_train: 0.4492 acc_train: 0.8507 loss_val: 0.9266 acc_val: 0.6978 time: 0.0062s\nRanking optimizing... \nNow Average ERR@k =  0.3768487870693207\nEpoch: 0149 loss_train: 0.4583 acc_train: 0.8507 loss_val: 0.9281 acc_val: 0.6978 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.375989705324173\nEpoch: 0150 loss_train: 0.4417 acc_train: 0.8726 loss_val: 0.9296 acc_val: 0.6984 time: 0.0063s\nRanking optimizing... \nNow Average ERR@k =  0.3724510967731476\nEpoch: 0151 loss_train: 0.4373 acc_train: 0.8714 loss_val: 0.9313 acc_val: 0.6984 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.378213107585907\nEpoch: 0152 loss_train: 0.4422 acc_train: 0.8689 loss_val: 0.9330 acc_val: 0.6978 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.381244033575058\nEpoch: 0153 loss_train: 0.4281 acc_train: 0.8641 loss_val: 0.9350 acc_val: 0.6978 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.3750269114971161\nEpoch: 0154 loss_train: 0.4459 acc_train: 0.8750 loss_val: 0.9371 acc_val: 0.6978 time: 0.0106s\nRanking optimizing... \nNow Average ERR@k =  0.3815746307373047\nEpoch: 0155 loss_train: 0.4356 acc_train: 0.8617 loss_val: 0.9390 acc_val: 0.6972 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.3784085512161255\nEpoch: 0156 loss_train: 0.4332 acc_train: 0.8701 loss_val: 0.9405 acc_val: 0.6984 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.3753661513328552\nEpoch: 0157 loss_train: 0.4309 acc_train: 0.8677 loss_val: 0.9416 acc_val: 0.6990 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.37422171235084534\nEpoch: 0158 loss_train: 0.4345 acc_train: 0.8750 loss_val: 0.9426 acc_val: 0.6978 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.377130925655365\nEpoch: 0159 loss_train: 0.4411 acc_train: 0.8580 loss_val: 0.9434 acc_val: 0.6966 time: 0.0079s\nRanking optimizing... \nNow Average ERR@k =  0.3772459328174591\nEpoch: 0160 loss_train: 0.4209 acc_train: 0.8786 loss_val: 0.9446 acc_val: 0.6972 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3811953067779541\nEpoch: 0161 loss_train: 0.4230 acc_train: 0.8714 loss_val: 0.9459 acc_val: 0.6972 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.38015827536582947\nEpoch: 0162 loss_train: 0.4348 acc_train: 0.8677 loss_val: 0.9473 acc_val: 0.6966 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.38025492429733276\nEpoch: 0163 loss_train: 0.4432 acc_train: 0.8519 loss_val: 0.9487 acc_val: 0.6960 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.38001081347465515\nEpoch: 0164 loss_train: 0.4142 acc_train: 0.8774 loss_val: 0.9501 acc_val: 0.6954 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.38215234875679016\nEpoch: 0165 loss_train: 0.4305 acc_train: 0.8701 loss_val: 0.9517 acc_val: 0.6954 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.3875996768474579\nEpoch: 0166 loss_train: 0.4277 acc_train: 0.8592 loss_val: 0.9533 acc_val: 0.6960 time: 0.0119s\nRanking optimizing... \nNow Average ERR@k =  0.3801966607570648\nEpoch: 0167 loss_train: 0.4147 acc_train: 0.8701 loss_val: 0.9547 acc_val: 0.6966 time: 0.0110s\nRanking optimizing... \nNow Average ERR@k =  0.3844046890735626\nEpoch: 0168 loss_train: 0.4279 acc_train: 0.8653 loss_val: 0.9561 acc_val: 0.6972 time: 0.0089s\nRanking optimizing... \nNow Average ERR@k =  0.3818911015987396\nEpoch: 0169 loss_train: 0.4066 acc_train: 0.8726 loss_val: 0.9577 acc_val: 0.6960 time: 0.0080s\nRanking optimizing... \nNow Average ERR@k =  0.38290953636169434\nEpoch: 0170 loss_train: 0.4110 acc_train: 0.8738 loss_val: 0.9594 acc_val: 0.6966 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.38190779089927673\nEpoch: 0171 loss_train: 0.4164 acc_train: 0.8677 loss_val: 0.9612 acc_val: 0.6966 time: 0.0093s\nRanking optimizing... \nNow Average ERR@k =  0.38424187898635864\nEpoch: 0172 loss_train: 0.4216 acc_train: 0.8677 loss_val: 0.9632 acc_val: 0.6966 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.37878233194351196\nEpoch: 0173 loss_train: 0.4185 acc_train: 0.8799 loss_val: 0.9651 acc_val: 0.6954 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3886951208114624\nEpoch: 0174 loss_train: 0.4247 acc_train: 0.8677 loss_val: 0.9670 acc_val: 0.6948 time: 0.0141s\nRanking optimizing... \nNow Average ERR@k =  0.38563239574432373\nEpoch: 0175 loss_train: 0.4063 acc_train: 0.8823 loss_val: 0.9687 acc_val: 0.6942 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.38283494114875793\nEpoch: 0176 loss_train: 0.4132 acc_train: 0.8799 loss_val: 0.9707 acc_val: 0.6954 time: 0.0100s\nRanking optimizing... \nNow Average ERR@k =  0.37972787022590637\nEpoch: 0177 loss_train: 0.4255 acc_train: 0.8714 loss_val: 0.9726 acc_val: 0.6954 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.38499221205711365\nEpoch: 0178 loss_train: 0.3876 acc_train: 0.8944 loss_val: 0.9743 acc_val: 0.6954 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.3827068507671356\nEpoch: 0179 loss_train: 0.4047 acc_train: 0.8714 loss_val: 0.9760 acc_val: 0.6948 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.38244542479515076\nEpoch: 0180 loss_train: 0.3990 acc_train: 0.8738 loss_val: 0.9776 acc_val: 0.6936 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.38623228669166565\nEpoch: 0181 loss_train: 0.3977 acc_train: 0.8823 loss_val: 0.9792 acc_val: 0.6942 time: 0.0102s\nRanking optimizing... \nNow Average ERR@k =  0.38134995102882385\nEpoch: 0182 loss_train: 0.3940 acc_train: 0.8823 loss_val: 0.9807 acc_val: 0.6948 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.38517627120018005\nEpoch: 0183 loss_train: 0.3891 acc_train: 0.8811 loss_val: 0.9820 acc_val: 0.6930 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.3845822811126709\nEpoch: 0184 loss_train: 0.3989 acc_train: 0.8908 loss_val: 0.9836 acc_val: 0.6924 time: 0.0109s\nRanking optimizing... \nNow Average ERR@k =  0.38197076320648193\nEpoch: 0185 loss_train: 0.3966 acc_train: 0.8896 loss_val: 0.9852 acc_val: 0.6905 time: 0.0084s\nRanking optimizing... \nNow Average ERR@k =  0.38375866413116455\nEpoch: 0186 loss_train: 0.4238 acc_train: 0.8653 loss_val: 0.9869 acc_val: 0.6911 time: 0.0090s\nRanking optimizing... \nNow Average ERR@k =  0.38353201746940613\nEpoch: 0187 loss_train: 0.3843 acc_train: 0.8786 loss_val: 0.9885 acc_val: 0.6905 time: 0.0086s\nRanking optimizing... \nNow Average ERR@k =  0.38590481877326965\nEpoch: 0188 loss_train: 0.3986 acc_train: 0.8883 loss_val: 0.9897 acc_val: 0.6905 time: 0.0107s\nRanking optimizing... \nNow Average ERR@k =  0.3838954567909241\nEpoch: 0189 loss_train: 0.4053 acc_train: 0.8689 loss_val: 0.9910 acc_val: 0.6905 time: 0.0059s\nRanking optimizing... \nNow Average ERR@k =  0.3812010586261749\nEpoch: 0190 loss_train: 0.4007 acc_train: 0.8762 loss_val: 0.9926 acc_val: 0.6930 time: 0.0112s\nRanking optimizing... \nNow Average ERR@k =  0.38679039478302\nEpoch: 0191 loss_train: 0.3899 acc_train: 0.8835 loss_val: 0.9946 acc_val: 0.6905 time: 0.0092s\nRanking optimizing... \nNow Average ERR@k =  0.39004287123680115\nEpoch: 0192 loss_train: 0.3762 acc_train: 0.8896 loss_val: 0.9966 acc_val: 0.6917 time: 0.0108s\nRanking optimizing... \nNow Average ERR@k =  0.38549894094467163\nEpoch: 0193 loss_train: 0.3992 acc_train: 0.8762 loss_val: 0.9984 acc_val: 0.6911 time: 0.0083s\nRanking optimizing... \nNow Average ERR@k =  0.3893715739250183\nEpoch: 0194 loss_train: 0.3716 acc_train: 0.8847 loss_val: 1.0000 acc_val: 0.6881 time: 0.0093s\nRanking optimizing... \nNow Average ERR@k =  0.38747966289520264\nEpoch: 0195 loss_train: 0.3789 acc_train: 0.8835 loss_val: 1.0014 acc_val: 0.6899 time: 0.0081s\nRanking optimizing... \nNow Average ERR@k =  0.3847335875034332\nEpoch: 0196 loss_train: 0.3887 acc_train: 0.8762 loss_val: 1.0029 acc_val: 0.6899 time: 0.0095s\nRanking optimizing... \nNow Average ERR@k =  0.38470596075057983\nEpoch: 0197 loss_train: 0.3699 acc_train: 0.8908 loss_val: 1.0043 acc_val: 0.6887 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.3866402506828308\nEpoch: 0198 loss_train: 0.3833 acc_train: 0.8896 loss_val: 1.0062 acc_val: 0.6881 time: 0.0091s\nRanking optimizing... \nNow Average ERR@k =  0.385090172290802\nEpoch: 0199 loss_train: 0.3866 acc_train: 0.8871 loss_val: 1.0083 acc_val: 0.6875 time: 0.0082s\nRanking optimizing... \nNow Average ERR@k =  0.3822139501571655\nEpoch: 0200 loss_train: 0.3597 acc_train: 0.8981 loss_val: 1.0104 acc_val: 0.6881 time: 0.0099s\nRanking optimizing... \nNow Average ERR@k =  0.38621795177459717\nTest set results: loss= 1.0082 accuracy= 0.7005\n"], ["node classification", "structural", "ERR", "coauthor-cs", "SGC", "Command 'cd node\\ classification; time python REDRESS_structural_ERR.py --dataset coauthor-cs --model SGC' returned non-zero exit status 1."], ["node classification", "structural", "ERR", "coauthor-cs", "GCN", "Command 'cd node\\ classification; time python REDRESS_structural_ERR.py --dataset coauthor-cs --model GCN' returned non-zero exit status 1."], ["node classification", "structural", "ERR", "coauthor-phy", "SGC", "Command 'cd node\\ classification; time python REDRESS_structural_ERR.py --dataset coauthor-phy --model SGC' returned non-zero exit status 1."], ["node classification", "structural", "ERR", "coauthor-phy", "GCN", "Command 'cd node\\ classification; time python REDRESS_structural_ERR.py --dataset coauthor-phy --model GCN' returned non-zero exit status 1."]]