{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Based Approach for Individual Fairness in GNNs "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objective of this paper is to ensure individual fairness within graph neural networks while also preserving the performance of GNNs. Individual fairness refers to the notion of similar outcomes for individuals who share similar characteristics. To accomplish this, the research conducts experiments on two specific tasks: Node Classification and Link Prediction. These experiments are carried out using three different datasets, incorporating two backbone models, as well as two distinct similarity metrics and ranking metrics for each task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Individual Fairness? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, what does individual fairness mean for Graph Neural Networks (GNNs)? We can discuss two fairness paradigms from this standpoint, namely individual and group fairness. Group fairness pertains to whether the predictions of models are similar for similar members of different subgroups (e.g. Hispanic, Asian). On the other hand, individual fairness focuses on individuals rather than groups. In this context, models are expected to provide similar outcomes for similar individuals. In this paper, the authors prefer to adopt a ranking-based approach instead of a distance-based approach for the sake of fairness.\n",
    "\n",
    "In the distance-based approach, the main objective of fairness optimization is to ensure that the distances between two nodes in the input and output spaces remain as similar as possible. On the other hand, the ranking-based approach aims to maximize the similarity between rankings, which is determined by the distances between one node and other nodes in both the input and output spaces. In the ranking-based approach, each node is associated with two ranking lists. The first ranking list (S_G) is generated from the input space, while the second list (S_Y) is obtained from the model's prediction. The node with the closest distance to the target node holds the first rank in the ranking list. The ultimate goal, in order to achieve individual fairness, is to minimize the dissimilarity between these two ranking lists."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Similarity and Ranking Similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we need to calculate similarity matrices for the input and output spaces. Additionally, we need to employ a metric for comparing these similarity matrices. The authors of this paper utilized two similarity metrics to assess the similarities between two nodes. They employed cosine similarity to evaluate feature-based similarities, while Jaccard similarity was used for structural comparisons. In order to compare two distinct rankings, they adopted Expected Reciprocal Rank (ERR) and Cumulative Gain-based approach (NDCG). Furthermore, they focused on the first k elements within the ranking lists to mitigate algorithmic complexity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone Models and Their Performances "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REDRESS is a modular framework consisting of two main modules. The first module aims to maximize the usefulness of the backbone model, while the second module focuses on achieving fairness. At the end, the loss function incorporates two terms for these modules. Additionally, the contribution of the fairness module can be adjusted by setting the hyperparameter gamma (ùõæ). In this paper, Graph Convolutional Network (GCN) and Simplifying Graph Convolutional Network (SGC) are employed for the Node Classification task, while GCN and Variational Graph Auto-Encoders (GAE) are utilized for the Link Prediction task.\n",
    "\n",
    "To assess the performance of the backbone models, accuracy (ACC) is employed for Node Classification, and the area under the receiver operating characteristic curve (AUC) is used for Link Prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scale=0.5](tables/overview.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize three datasets for each downstream task. For the Node Classification task, we employ one citation network (ACM) and two co-authorship networks (Co-author-CS and Co-author-Phy). On the other hand, for the Link Prediction task, we utilize three social networks (BlogCatalog, Flickr, and Facebook).\n",
    "\n",
    "In the citation network, each node represents a paper, and the edges between nodes indicate the citation relationships between papers. In the co-authorship networks, each node represents an author, and the edges represent collaboration relationships between them.\n",
    "\n",
    "To calculate node attributes, we utilize the bag-of-words model, which involves analyzing the abstracts of the papers. For more detailed statistics regarding the datasets, please refer to the table below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scale=0.5](tables/dataset.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility and Our Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All datasets are accessible to the public, and the authors of the paper have already shared their repository. Additionally, they have provided detailed explanations for the sake of reproducibility. As a result, I have obtained similar scores to those mentioned in the paper, and I have not noticed any inconsistencies. I have successfully replicated some of the results. \n",
    "\n",
    "Instead of rerunning all 48 experiments, which would take approximately two days to complete due to running 24 trials for each task, I decided to include a subset of experiments for reporting regenerated results. The selection of which experiments to reproduce for reporting was based on factors such as diversity, dataset sizes, and the time required to complete the experiments.\n",
    "\n",
    "By considering diversity, I aimed to include experiments that cover a wide range of scenarios, ensuring a representative sample of the overall experimental space. This approach allows for capturing different aspects and variations present in the tasks.\n",
    "\n",
    "Additionally, dataset sizes played a role in the decision-making process. I considered the importance of including experiments that cover different dataset scales or distributions. By including a mix of large and small datasets, I could assess the generalizability and performance of the models across various data sizes.\n",
    "\n",
    "Lastly, the time required for experiments to converge and produce results was taken into account. Since running all 48 experiments would take a considerable amount of time, I prioritized selecting experiments that yielded results relatively quickly. This approach allowed for a more timely analysis and reporting of the findings.\n",
    "\n",
    "By considering these factors, I ensured that the subset of experiments chosen for reproduction and reporting would provide meaningful insights while optimizing the use of time and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import json \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_classification_setup = {\n",
    "    \"dataset\": [\"ACM\", \"coauthor-cs\", \"coauthor-phy\"],\n",
    "    \"model\": [\"SGC\", \"GCN\"],\n",
    "    \"node_similarity\": [\"feature\", \"structural\"],\n",
    "    \"ranking_similarity\": [\"NDCG\", \"ERR\"]\n",
    "}\n",
    "\n",
    "link_prediction_setup = {\n",
    "    \"dataset\": [\"BlogCatalog\", \"facebook\", \"Flickr\"],\n",
    "    \"model\": [\"GCN\", \"GAE\"],\n",
    "    \"node_similarity\": [\"feature\", \"structural\"],\n",
    "    \"ranking_similarity\": [\"NDCG\", \"ERR\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_parser(log, fair_pattern, utility_pattern):\n",
    "    fair = re.findall(fair_pattern, log[-1])\n",
    "    utility = re.findall(utility_pattern, log[-1])\n",
    "    if fair and utility:\n",
    "        return log[:-1] + [round(float(fair[0]), 2), round(float(utility[0]), 2)]\n",
    "    else:\n",
    "        return log[:-1] + [None, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"node classification_results.json\") as f:\n",
    "    nc_result = json.load(f)\n",
    "\n",
    "parsed_nc_result = [\n",
    "    log_parser(\n",
    "        experiment,\n",
    "        \"@k =  ([0-9.]+)\\nTest set results\",\n",
    "        \"accuracy= ([0-9.]+)\\n\"\n",
    "    )\n",
    "    for experiment in nc_result\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"link prediction_results.json\") as f:\n",
    "    lp_result = json.load(f)\n",
    "\n",
    "parsed_lp_result = [\n",
    "    log_parser(\n",
    "        experiment,\n",
    "        \"fair_after\\[([0-9.]+)\\]\",\n",
    "        \"auc_after\\[([0-9.]+)\\]\",\n",
    "    )\n",
    "    for experiment in (lp_result)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_for_df(parsed_result):\n",
    "    parsed_dict = defaultdict(list)\n",
    "    for r in parsed_result:\n",
    "        parsed_dict[\"Dataset\"].append(r[3])\n",
    "        parsed_dict[\"Backbone\"].append(r[4])\n",
    "        parsed_dict[\"Node Similarity\"].append(r[1])\n",
    "        parsed_dict[\"Ranking Similarity\"].append(r[2])\n",
    "        parsed_dict[\"Utility\"].append(r[6])\n",
    "        parsed_dict[\"Fairness\"].append(r[5])\n",
    "    return parsed_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node Classification Reproduced Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Node Similarity</th>\n",
       "      <th>Ranking Similarity</th>\n",
       "      <th>Utility</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACM</td>\n",
       "      <td>SGC</td>\n",
       "      <td>feature</td>\n",
       "      <td>NDCG</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACM</td>\n",
       "      <td>GCN</td>\n",
       "      <td>feature</td>\n",
       "      <td>NDCG</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coauthor-cs</td>\n",
       "      <td>SGC</td>\n",
       "      <td>feature</td>\n",
       "      <td>NDCG</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coauthor-cs</td>\n",
       "      <td>GCN</td>\n",
       "      <td>feature</td>\n",
       "      <td>NDCG</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACM</td>\n",
       "      <td>SGC</td>\n",
       "      <td>feature</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACM</td>\n",
       "      <td>GCN</td>\n",
       "      <td>feature</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coauthor-cs</td>\n",
       "      <td>SGC</td>\n",
       "      <td>feature</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coauthor-cs</td>\n",
       "      <td>GCN</td>\n",
       "      <td>feature</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ACM</td>\n",
       "      <td>SGC</td>\n",
       "      <td>structural</td>\n",
       "      <td>NDCG</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ACM</td>\n",
       "      <td>GCN</td>\n",
       "      <td>structural</td>\n",
       "      <td>NDCG</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACM</td>\n",
       "      <td>SGC</td>\n",
       "      <td>structural</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACM</td>\n",
       "      <td>GCN</td>\n",
       "      <td>structural</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Backbone Node Similarity Ranking Similarity  Utility  Fairness\n",
       "0           ACM      SGC         feature               NDCG     0.67      0.60\n",
       "1           ACM      GCN         feature               NDCG     0.70      0.31\n",
       "2   coauthor-cs      SGC         feature               NDCG     0.89      0.76\n",
       "3   coauthor-cs      GCN         feature               NDCG     0.92      0.47\n",
       "6           ACM      SGC         feature                ERR     0.66      0.83\n",
       "7           ACM      GCN         feature                ERR     0.70      0.76\n",
       "8   coauthor-cs      SGC         feature                ERR     0.91      0.92\n",
       "9   coauthor-cs      GCN         feature                ERR     0.92      0.79\n",
       "12          ACM      SGC      structural               NDCG     0.67      0.39\n",
       "13          ACM      GCN      structural               NDCG     0.68      0.25\n",
       "18          ACM      SGC      structural                ERR     0.68      0.49\n",
       "19          ACM      GCN      structural                ERR     0.70      0.39"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(get_dict_for_df(parsed_nc_result)).dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tables/nc_ndcg.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scale=0.5](tables/nc_err.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link Prediction Reproduced Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Backbone</th>\n",
       "      <th>Node Similarity</th>\n",
       "      <th>Ranking Similarity</th>\n",
       "      <th>Utility</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook</td>\n",
       "      <td>GCN</td>\n",
       "      <td>feature</td>\n",
       "      <td>NDCG</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook</td>\n",
       "      <td>GAE</td>\n",
       "      <td>feature</td>\n",
       "      <td>NDCG</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>facebook</td>\n",
       "      <td>GCN</td>\n",
       "      <td>feature</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>facebook</td>\n",
       "      <td>GAE</td>\n",
       "      <td>feature</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>facebook</td>\n",
       "      <td>GCN</td>\n",
       "      <td>structural</td>\n",
       "      <td>NDCG</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>facebook</td>\n",
       "      <td>GCN</td>\n",
       "      <td>structural</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>facebook</td>\n",
       "      <td>GAE</td>\n",
       "      <td>structural</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Backbone Node Similarity Ranking Similarity  Utility  Fairness\n",
       "2   facebook      GCN         feature               NDCG     0.96      0.29\n",
       "3   facebook      GAE         feature               NDCG     0.95      0.29\n",
       "8   facebook      GCN         feature                ERR     0.95      0.65\n",
       "9   facebook      GAE         feature                ERR     0.96      0.65\n",
       "14  facebook      GCN      structural               NDCG     0.93      0.31\n",
       "20  facebook      GCN      structural                ERR     0.93      0.44\n",
       "21  facebook      GAE      structural                ERR     0.93      0.45"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(get_dict_for_df(parsed_lp_result)).dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scale=0.5](tables/lp_ndcg.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scale=0.5](tables/lp_err.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Extension Idea "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am considering the creation of artificial nodes based on the concepts explored in the Computer Vision field. The concept revolves around generating new nodes by merging existing nodes from the training dataset. By taking into account the attributes of the nodes, including their relevant features, as well as the similarities observed among other nodes, my objective is to produce nodes that are located within close proximity to each individual node."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".redress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
